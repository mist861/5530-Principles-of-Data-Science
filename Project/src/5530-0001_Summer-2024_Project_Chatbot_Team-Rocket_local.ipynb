{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb2d4b2b-4270-48c6-9c95-aac531c7e02c",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe2758b-a6f2-4840-af5f-4b6672ffae04",
   "metadata": {},
   "source": [
    "## Prework to Generate Dataset CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2206309d-c751-4c00-a406-b865b8ceed36",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "466aff27-56da-456c-bd15-5fb7e97c5495",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "550d2ec6-76b3-4b80-93e0-9d1f02194a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/mnt/c/Users/willi/Downloads/intents.json') as json_data:\n",
    "    intents = json.load(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd937b91-b193-409f-ad1c-596887906cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intents': [{'tag': 'greeting', 'patterns': ['Hi there', 'How are you', 'Is anyone there?', 'Hello', 'Good day'], 'responses': ['Hello, thanks for asking', 'Good to see you again', 'Hi there, how can I help?'], 'context': ['']}, {'tag': 'goodbye', 'patterns': ['Bye', 'See you later', 'Goodbye', 'Nice chatting to you, bye', 'Till next time'], 'responses': ['See you!', 'Have a nice day', 'Bye! Come back again soon.'], 'context': ['']}, {'tag': 'thanks', 'patterns': ['Thanks', 'Thank you', \"That's helpful\", 'Awesome, thanks', 'Thanks for helping me'], 'responses': ['Happy to help!', 'Any time!', 'My pleasure'], 'context': ['']}, {'tag': 'noanswer', 'patterns': [], 'responses': [\"Sorry, can't understand you\", 'Please give me more info', 'Not sure I understand'], 'context': ['']}, {'tag': 'options', 'patterns': ['How you could help me?', 'What you can do?', 'What help you provide?', 'How you can be helpful?', 'What support is offered'], 'responses': ['I can guide you through Adverse drug reaction list, Blood pressure tracking, Hospitals and Pharmacies', 'Offering support for Adverse drug reaction, Blood pressure, Hospitals and Pharmacies'], 'context': ['']}, {'tag': 'adverse_drug', 'patterns': ['How to check Adverse drug reaction?', 'Open adverse drugs module', 'Give me a list of drugs causing adverse behavior', 'List all drugs suitable for patient with adverse reaction', 'Which drugs dont have adverse reaction?'], 'responses': ['Navigating to Adverse drug reaction module'], 'context': ['']}, {'tag': 'blood_pressure', 'patterns': ['Open blood pressure module', 'Task related to blood pressure', 'Blood pressure data entry', 'I want to log blood pressure results', 'Blood pressure data management'], 'responses': ['Navigating to Blood Pressure module'], 'context': ['']}, {'tag': 'blood_pressure_search', 'patterns': ['I want to search for blood pressure result history', 'Blood pressure for patient', 'Load patient blood pressure result', 'Show blood pressure results for patient', 'Find blood pressure results by ID'], 'responses': ['Please provide Patient ID', 'Patient ID?'], 'context': ['search_blood_pressure_by_patient_id']}, {'tag': 'search_blood_pressure_by_patient_id', 'patterns': [], 'responses': ['Loading Blood pressure result for Patient'], 'context': ['']}, {'tag': 'pharmacy_search', 'patterns': ['Find me a pharmacy', 'Find pharmacy', 'List of pharmacies nearby', 'Locate pharmacy', 'Search pharmacy'], 'responses': ['Please provide pharmacy name'], 'context': ['search_pharmacy_by_name']}, {'tag': 'search_pharmacy_by_name', 'patterns': [], 'responses': ['Loading pharmacy details'], 'context': ['']}, {'tag': 'hospital_search', 'patterns': ['Lookup for hospital', 'Searching for hospital to transfer patient', 'I want to search hospital data', 'Hospital lookup for patient', 'Looking up hospital details'], 'responses': ['Please provide hospital name or location'], 'context': ['search_hospital_by_params']}, {'tag': 'search_hospital_by_params', 'patterns': [], 'responses': ['Please provide hospital type'], 'context': ['search_hospital_by_type']}, {'tag': 'search_hospital_by_type', 'patterns': [], 'responses': ['Loading hospital details'], 'context': ['']}]}\n"
     ]
    }
   ],
   "source": [
    "print(intents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "339111c3-779a-475a-adaf-7c28566461d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_intent_dict = {}\n",
    "temp_utterance = []\n",
    "temp_intents = []\n",
    "for i in intents['intents']:\n",
    "    for j in i['patterns']:\n",
    "        temp_intents.append(str(i['tag']))\n",
    "        temp_utterance.append(str(j))        \n",
    "temp_intent_dict['utterance'] = temp_utterance\n",
    "temp_intent_dict['intent'] = temp_intents\n",
    "\n",
    "#for intent in intents['intents']:\n",
    "#    temp_intents[f\"{intent['tag']}\"] = intent['patterns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1f6417e-33bb-4c74-a4c4-ef5664625ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'utterance': ['Hi there', 'How are you', 'Is anyone there?', 'Hello', 'Good day', 'Bye', 'See you later', 'Goodbye', 'Nice chatting to you, bye', 'Till next time', 'Thanks', 'Thank you', \"That's helpful\", 'Awesome, thanks', 'Thanks for helping me', 'How you could help me?', 'What you can do?', 'What help you provide?', 'How you can be helpful?', 'What support is offered', 'How to check Adverse drug reaction?', 'Open adverse drugs module', 'Give me a list of drugs causing adverse behavior', 'List all drugs suitable for patient with adverse reaction', 'Which drugs dont have adverse reaction?', 'Open blood pressure module', 'Task related to blood pressure', 'Blood pressure data entry', 'I want to log blood pressure results', 'Blood pressure data management', 'I want to search for blood pressure result history', 'Blood pressure for patient', 'Load patient blood pressure result', 'Show blood pressure results for patient', 'Find blood pressure results by ID', 'Find me a pharmacy', 'Find pharmacy', 'List of pharmacies nearby', 'Locate pharmacy', 'Search pharmacy', 'Lookup for hospital', 'Searching for hospital to transfer patient', 'I want to search hospital data', 'Hospital lookup for patient', 'Looking up hospital details'], 'intent': ['greeting', 'greeting', 'greeting', 'greeting', 'greeting', 'goodbye', 'goodbye', 'goodbye', 'goodbye', 'goodbye', 'thanks', 'thanks', 'thanks', 'thanks', 'thanks', 'options', 'options', 'options', 'options', 'options', 'adverse_drug', 'adverse_drug', 'adverse_drug', 'adverse_drug', 'adverse_drug', 'blood_pressure', 'blood_pressure', 'blood_pressure', 'blood_pressure', 'blood_pressure', 'blood_pressure_search', 'blood_pressure_search', 'blood_pressure_search', 'blood_pressure_search', 'blood_pressure_search', 'pharmacy_search', 'pharmacy_search', 'pharmacy_search', 'pharmacy_search', 'pharmacy_search', 'hospital_search', 'hospital_search', 'hospital_search', 'hospital_search', 'hospital_search']}\n"
     ]
    }
   ],
   "source": [
    "print(temp_intent_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33baf7b8-a6ad-457f-8ca1-75004d30d302",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_intent_df = pd.DataFrame.from_dict(temp_intent_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae487bdf-a71b-4b63-9309-1076dcf1c5c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi there</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How are you</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Is anyone there?</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hello</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Good day</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bye</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>See you later</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Goodbye</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Nice chatting to you, bye</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Till next time</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   utterance    intent\n",
       "0                   Hi there  greeting\n",
       "1                How are you  greeting\n",
       "2           Is anyone there?  greeting\n",
       "3                      Hello  greeting\n",
       "4                   Good day  greeting\n",
       "5                        Bye   goodbye\n",
       "6              See you later   goodbye\n",
       "7                    Goodbye   goodbye\n",
       "8  Nice chatting to you, bye   goodbye\n",
       "9             Till next time   goodbye"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_intent_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21900e0b-0a91-4a26-a9d8-ce418323b15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_intent_df['utterance'] = temp_intent_df['utterance'].apply(lambda x: \"\\\"\" + str(x) + \"\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e984eed-ea75-417b-a772-6082c92e5c8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Hi there\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"How are you\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Is anyone there?\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Hello\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Good day\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"Bye\"</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"See you later\"</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"Goodbye\"</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"Nice chatting to you, bye\"</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"Till next time\"</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     utterance    intent\n",
       "0                   \"Hi there\"  greeting\n",
       "1                \"How are you\"  greeting\n",
       "2           \"Is anyone there?\"  greeting\n",
       "3                      \"Hello\"  greeting\n",
       "4                   \"Good day\"  greeting\n",
       "5                        \"Bye\"   goodbye\n",
       "6              \"See you later\"   goodbye\n",
       "7                    \"Goodbye\"   goodbye\n",
       "8  \"Nice chatting to you, bye\"   goodbye\n",
       "9             \"Till next time\"   goodbye"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_intent_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe36166b-e0ec-4e70-adca-85693a7b8f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_new_df = pd.read_csv('/mnt/c/Users/willi/Downloads/intent_dataset_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1360c3f7-741f-48d9-9788-d55881a2b312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Hello!\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Hi there!\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Hey!\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Good morning!\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Good afternoon!\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"Good evening!\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"Howdy!\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"Greetings!\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"What's up?\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"How's it going?\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           utterance    intent\n",
       "0           \"Hello!\"  greeting\n",
       "1        \"Hi there!\"  greeting\n",
       "2             \"Hey!\"  greeting\n",
       "3    \"Good morning!\"  greeting\n",
       "4  \"Good afternoon!\"  greeting\n",
       "5    \"Good evening!\"  greeting\n",
       "6           \"Howdy!\"  greeting\n",
       "7       \"Greetings!\"  greeting\n",
       "8       \"What's up?\"  greeting\n",
       "9  \"How's it going?\"  greeting"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intent_new_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba6dbaf9-653e-40e5-98a3-aee621858b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_full_df = pd.concat([temp_intent_df,intent_new_df],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e52000f-40ac-4dad-bcc2-cdd871f0e2d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Hi there\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"How are you\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Is anyone there?\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Hello\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Good day\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"Bye\"</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"See you later\"</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"Goodbye\"</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"Nice chatting to you, bye\"</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"Till next time\"</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     utterance    intent\n",
       "0                   \"Hi there\"  greeting\n",
       "1                \"How are you\"  greeting\n",
       "2           \"Is anyone there?\"  greeting\n",
       "3                      \"Hello\"  greeting\n",
       "4                   \"Good day\"  greeting\n",
       "5                        \"Bye\"   goodbye\n",
       "6              \"See you later\"   goodbye\n",
       "7                    \"Goodbye\"   goodbye\n",
       "8  \"Nice chatting to you, bye\"   goodbye\n",
       "9             \"Till next time\"   goodbye"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intent_full_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d141b8cf-267c-4a3a-8550-2e2dec57bcdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(265, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#temp_intent_df.shape\n",
    "#intent_raw_df.shape\n",
    "intent_full_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff8e6e39-1af2-4068-9f6f-b348e8931279",
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_full_df.to_csv('/mnt/c/Users/willi/Downloads/intent_full_dataset.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "47451331-9b4e-4a4b-9d97-4422b391d047",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_response_dict = {}\n",
    "temp_responses = []\n",
    "temp_intents = []\n",
    "for i in intents['intents']:\n",
    "    for j in i['responses']:\n",
    "        temp_intents.append(str(i['tag']))\n",
    "        temp_responses.append(str(j))        \n",
    "temp_response_dict['responses'] = temp_responses\n",
    "temp_response_dict['intent'] = temp_intents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "73c521bd-3213-40a4-9813-812686009531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>responses</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hello, thanks for asking</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good to see you again</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hi there, how can I help?</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>See you!</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Have a nice day</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bye! Come back again soon.</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Happy to help!</td>\n",
       "      <td>thanks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Any time!</td>\n",
       "      <td>thanks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>My pleasure</td>\n",
       "      <td>thanks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sorry, can't understand you</td>\n",
       "      <td>noanswer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     responses    intent\n",
       "0     Hello, thanks for asking  greeting\n",
       "1        Good to see you again  greeting\n",
       "2    Hi there, how can I help?  greeting\n",
       "3                     See you!   goodbye\n",
       "4              Have a nice day   goodbye\n",
       "5   Bye! Come back again soon.   goodbye\n",
       "6               Happy to help!    thanks\n",
       "7                    Any time!    thanks\n",
       "8                  My pleasure    thanks\n",
       "9  Sorry, can't understand you  noanswer"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_response_df = pd.DataFrame.from_dict(temp_response_dict)\n",
    "temp_response_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e2454e91-56ce-413d-ab5a-4c2be05c3289",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_response_df.to_csv('/mnt/c/Users/willi/Downloads/responses_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bf6a62-67f3-44b2-a995-6d1a3d3e1d2e",
   "metadata": {},
   "source": [
    "# Augment the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4586f597-ad93-4698-a5f0-8949aa659cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textattack\n",
      "  Obtaining dependency information for textattack from https://files.pythonhosted.org/packages/6a/c9/041fe7d041cd051898fca4000a3f12cca57f85d6372307f8c04e062eee33/textattack-0.3.10-py3-none-any.whl.metadata\n",
      "  Downloading textattack-0.3.10-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting bert-score>=0.3.5 (from textattack)\n",
      "  Obtaining dependency information for bert-score>=0.3.5 from https://files.pythonhosted.org/packages/c6/8c/bc5457de4c004b1a623b31f7bc8d0375fb699b7d67df11879098b4b7b7c8/bert_score-0.3.13-py3-none-any.whl.metadata\n",
      "  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting editdistance (from textattack)\n",
      "  Obtaining dependency information for editdistance from https://files.pythonhosted.org/packages/96/8a/db0fd79e8ddb9b5f86f274107c5d0a27ec4f2af88877df1f26c2c6d150cc/editdistance-0.8.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading editdistance-0.8.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
      "Collecting flair (from textattack)\n",
      "  Obtaining dependency information for flair from https://files.pythonhosted.org/packages/af/16/536683088c7306bc51cc3cc58605759ebd83b3f7ffd05a9399f4b99c8614/flair-0.13.1-py3-none-any.whl.metadata\n",
      "  Downloading flair-0.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: filelock in ./anaconda3/lib/python3.11/site-packages (from textattack) (3.9.0)\n",
      "Collecting language-tool-python (from textattack)\n",
      "  Obtaining dependency information for language-tool-python from https://files.pythonhosted.org/packages/d2/82/feb4f01e269267021f1e3a3bb87ad60b201d3fa36dfe9fb85684c025f43a/language_tool_python-2.8-py3-none-any.whl.metadata\n",
      "  Downloading language_tool_python-2.8-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting lemminflect (from textattack)\n",
      "  Obtaining dependency information for lemminflect from https://files.pythonhosted.org/packages/9e/98/9fac8cc177474ddd8d1725d5cae052098662d5e4a6756633335f4393673b/lemminflect-0.2.3-py3-none-any.whl.metadata\n",
      "  Downloading lemminflect-0.2.3-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting lru-dict (from textattack)\n",
      "  Obtaining dependency information for lru-dict from https://files.pythonhosted.org/packages/21/92/4690daefc2602f7c3429ecf54572d37a9e3c372d370344d2185daa4d5ecc/lru_dict-1.3.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading lru_dict-1.3.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: datasets>=2.4.0 in ./anaconda3/lib/python3.11/site-packages (from textattack) (2.12.0)\n",
      "Requirement already satisfied: nltk in ./anaconda3/lib/python3.11/site-packages (from textattack) (3.8.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in ./anaconda3/lib/python3.11/site-packages (from textattack) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.0.1 in ./anaconda3/lib/python3.11/site-packages (from textattack) (2.0.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in ./anaconda3/lib/python3.11/site-packages (from textattack) (1.11.1)\n",
      "Requirement already satisfied: torch!=1.8,>=1.7.0 in ./anaconda3/lib/python3.11/site-packages (from textattack) (2.3.1)\n",
      "Requirement already satisfied: transformers>=4.30.0 in ./anaconda3/lib/python3.11/site-packages (from textattack) (4.41.2)\n",
      "Collecting terminaltables (from textattack)\n",
      "  Obtaining dependency information for terminaltables from https://files.pythonhosted.org/packages/c4/fb/ea621e0a19733e01fe4005d46087d383693c0f4a8f824b47d8d4122c87e0/terminaltables-3.1.10-py2.py3-none-any.whl.metadata\n",
      "  Downloading terminaltables-3.1.10-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: tqdm in ./anaconda3/lib/python3.11/site-packages (from textattack) (4.65.0)\n",
      "Collecting word2number (from textattack)\n",
      "  Downloading word2number-1.1.zip (9.7 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting num2words (from textattack)\n",
      "  Obtaining dependency information for num2words from https://files.pythonhosted.org/packages/8f/f0/ca1228af2bcbce2fdf2b23d58643c84253b88a3c1cd9dba391ca683c4b21/num2words-0.5.13-py3-none-any.whl.metadata\n",
      "  Downloading num2words-0.5.13-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: more-itertools in ./anaconda3/lib/python3.11/site-packages (from textattack) (8.12.0)\n",
      "Collecting pinyin>=0.4.0 (from textattack)\n",
      "  Downloading pinyin-0.4.0.tar.gz (3.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting jieba (from textattack)\n",
      "  Downloading jieba-0.42.1.tar.gz (19.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting OpenHowNet (from textattack)\n",
      "  Obtaining dependency information for OpenHowNet from https://files.pythonhosted.org/packages/cd/f0/47b0d55b8cf43c801158cd374e6d166b104004ceb14fdeb7d50c9bad9698/OpenHowNet-2.0-py3-none-any.whl.metadata\n",
      "  Downloading OpenHowNet-2.0-py3-none-any.whl.metadata (821 bytes)\n",
      "Requirement already satisfied: requests in ./anaconda3/lib/python3.11/site-packages (from bert-score>=0.3.5->textattack) (2.32.3)\n",
      "Requirement already satisfied: matplotlib in ./anaconda3/lib/python3.11/site-packages (from bert-score>=0.3.5->textattack) (3.7.2)\n",
      "Requirement already satisfied: packaging>=20.9 in ./anaconda3/lib/python3.11/site-packages (from bert-score>=0.3.5->textattack) (24.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in ./anaconda3/lib/python3.11/site-packages (from datasets>=2.4.0->textattack) (11.0.0)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in ./anaconda3/lib/python3.11/site-packages (from datasets>=2.4.0->textattack) (0.3.6)\n",
      "Requirement already satisfied: xxhash in ./anaconda3/lib/python3.11/site-packages (from datasets>=2.4.0->textattack) (2.0.2)\n",
      "Requirement already satisfied: multiprocess in ./anaconda3/lib/python3.11/site-packages (from datasets>=2.4.0->textattack) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in ./anaconda3/lib/python3.11/site-packages (from datasets>=2.4.0->textattack) (2024.6.0)\n",
      "Requirement already satisfied: aiohttp in ./anaconda3/lib/python3.11/site-packages (from datasets>=2.4.0->textattack) (3.9.5)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in ./anaconda3/lib/python3.11/site-packages (from datasets>=2.4.0->textattack) (0.23.4)\n",
      "Requirement already satisfied: responses<0.19 in ./anaconda3/lib/python3.11/site-packages (from datasets>=2.4.0->textattack) (0.13.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./anaconda3/lib/python3.11/site-packages (from datasets>=2.4.0->textattack) (6.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./anaconda3/lib/python3.11/site-packages (from pandas>=1.0.1->textattack) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./anaconda3/lib/python3.11/site-packages (from pandas>=1.0.1->textattack) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./anaconda3/lib/python3.11/site-packages (from pandas>=1.0.1->textattack) (2023.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./anaconda3/lib/python3.11/site-packages (from torch!=1.8,>=1.7.0->textattack) (4.12.2)\n",
      "Requirement already satisfied: sympy in ./anaconda3/lib/python3.11/site-packages (from torch!=1.8,>=1.7.0->textattack) (1.11.1)\n",
      "Requirement already satisfied: networkx in ./anaconda3/lib/python3.11/site-packages (from torch!=1.8,>=1.7.0->textattack) (3.1)\n",
      "Requirement already satisfied: jinja2 in ./anaconda3/lib/python3.11/site-packages (from torch!=1.8,>=1.7.0->textattack) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./anaconda3/lib/python3.11/site-packages (from torch!=1.8,>=1.7.0->textattack) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./anaconda3/lib/python3.11/site-packages (from torch!=1.8,>=1.7.0->textattack) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./anaconda3/lib/python3.11/site-packages (from torch!=1.8,>=1.7.0->textattack) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./anaconda3/lib/python3.11/site-packages (from torch!=1.8,>=1.7.0->textattack) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./anaconda3/lib/python3.11/site-packages (from torch!=1.8,>=1.7.0->textattack) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./anaconda3/lib/python3.11/site-packages (from torch!=1.8,>=1.7.0->textattack) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./anaconda3/lib/python3.11/site-packages (from torch!=1.8,>=1.7.0->textattack) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./anaconda3/lib/python3.11/site-packages (from torch!=1.8,>=1.7.0->textattack) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./anaconda3/lib/python3.11/site-packages (from torch!=1.8,>=1.7.0->textattack) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in ./anaconda3/lib/python3.11/site-packages (from torch!=1.8,>=1.7.0->textattack) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./anaconda3/lib/python3.11/site-packages (from torch!=1.8,>=1.7.0->textattack) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.1 in ./anaconda3/lib/python3.11/site-packages (from torch!=1.8,>=1.7.0->textattack) (2.3.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./anaconda3/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch!=1.8,>=1.7.0->textattack) (12.5.40)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./anaconda3/lib/python3.11/site-packages (from transformers>=4.30.0->textattack) (2024.5.15)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in ./anaconda3/lib/python3.11/site-packages (from transformers>=4.30.0->textattack) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./anaconda3/lib/python3.11/site-packages (from transformers>=4.30.0->textattack) (0.4.3)\n",
      "Requirement already satisfied: boto3>=1.20.27 in ./anaconda3/lib/python3.11/site-packages (from flair->textattack) (1.34.127)\n",
      "Collecting bpemb>=0.3.2 (from flair->textattack)\n",
      "  Obtaining dependency information for bpemb>=0.3.2 from https://files.pythonhosted.org/packages/cb/ad/54068fd577c55ea2126be5628b9ae5045fcf715bc3a41780b07f6445980d/bpemb-0.3.5-py3-none-any.whl.metadata\n",
      "  Downloading bpemb-0.3.5-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting conllu>=4.0 (from flair->textattack)\n",
      "  Obtaining dependency information for conllu>=4.0 from https://files.pythonhosted.org/packages/ce/3f/70a1dc5bc536755ec082b806594598a10cfffaf0de978f51d4e0e4fdfa47/conllu-4.5.3-py2.py3-none-any.whl.metadata\n",
      "  Downloading conllu-4.5.3-py2.py3-none-any.whl.metadata (19 kB)\n",
      "Collecting deprecated>=1.2.13 (from flair->textattack)\n",
      "  Obtaining dependency information for deprecated>=1.2.13 from https://files.pythonhosted.org/packages/20/8d/778b7d51b981a96554f29136cd59ca7880bf58094338085bcf2a979a0e6a/Deprecated-1.2.14-py2.py3-none-any.whl.metadata\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting ftfy>=6.1.0 (from flair->textattack)\n",
      "  Obtaining dependency information for ftfy>=6.1.0 from https://files.pythonhosted.org/packages/f4/f0/21efef51304172736b823689aaf82f33dbc64f54e9b046b75f5212d5cee7/ftfy-6.2.0-py3-none-any.whl.metadata\n",
      "  Downloading ftfy-6.2.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting gdown>=4.4.0 (from flair->textattack)\n",
      "  Obtaining dependency information for gdown>=4.4.0 from https://files.pythonhosted.org/packages/54/70/e07c381e6488a77094f04c85c9caf1c8008cdc30778f7019bc52e5285ef0/gdown-5.2.0-py3-none-any.whl.metadata\n",
      "  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: gensim>=4.2.0 in ./anaconda3/lib/python3.11/site-packages (from flair->textattack) (4.3.0)\n",
      "Collecting janome>=0.4.2 (from flair->textattack)\n",
      "  Obtaining dependency information for janome>=0.4.2 from https://files.pythonhosted.org/packages/73/7d/70f4069f4bbf0fca023e82a1fbbade6f5216365d4fe259fee1950723eca5/Janome-0.5.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading Janome-0.5.0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting langdetect>=1.0.9 (from flair->textattack)\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: lxml>=4.8.0 in ./anaconda3/lib/python3.11/site-packages (from flair->textattack) (4.9.3)\n",
      "Collecting more-itertools (from textattack)\n",
      "  Obtaining dependency information for more-itertools from https://files.pythonhosted.org/packages/bb/23/2d1cdb0427aecb2b150dc2ac2d15400990c4f05585b3fbc1b5177d74d7fb/more_itertools-10.3.0-py3-none-any.whl.metadata\n",
      "  Downloading more_itertools-10.3.0-py3-none-any.whl.metadata (36 kB)\n",
      "Collecting mpld3>=0.3 (from flair->textattack)\n",
      "  Obtaining dependency information for mpld3>=0.3 from https://files.pythonhosted.org/packages/95/6a/e3691bcc47485f38b09853207c928130571821d187cf174eed5418d45e82/mpld3-0.5.10-py3-none-any.whl.metadata\n",
      "  Downloading mpld3-0.5.10-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting pptree>=3.1 (from flair->textattack)\n",
      "  Downloading pptree-3.1.tar.gz (3.0 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pytorch-revgrad>=0.2.0 (from flair->textattack)\n",
      "  Obtaining dependency information for pytorch-revgrad>=0.2.0 from https://files.pythonhosted.org/packages/ec/e9/10b11b186b99c40213dca68cf6c38051b6704a74e1056d3f3ca4c12f14b9/pytorch_revgrad-0.2.0-py3-none-any.whl.metadata\n",
      "  Downloading pytorch_revgrad-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in ./anaconda3/lib/python3.11/site-packages (from flair->textattack) (1.5.0)\n",
      "Collecting segtok>=1.5.11 (from flair->textattack)\n",
      "  Obtaining dependency information for segtok>=1.5.11 from https://files.pythonhosted.org/packages/dd/60/d384dbae5d4756e33f1750fa3472303de2c827011907a64e213e114d0556/segtok-1.5.11-py3-none-any.whl.metadata\n",
      "  Downloading segtok-1.5.11-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting sqlitedict>=2.0.0 (from flair->textattack)\n",
      "  Downloading sqlitedict-2.1.0.tar.gz (21 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tabulate>=0.8.10 in ./anaconda3/lib/python3.11/site-packages (from flair->textattack) (0.8.10)\n",
      "Collecting transformer-smaller-training-vocab>=0.2.3 (from flair->textattack)\n",
      "  Obtaining dependency information for transformer-smaller-training-vocab>=0.2.3 from https://files.pythonhosted.org/packages/55/c8/6a02e88256dc48faf3eae5732a94035f4ea0edd91d8224333693111921ba/transformer_smaller_training_vocab-0.4.0-py3-none-any.whl.metadata\n",
      "  Downloading transformer_smaller_training_vocab-0.4.0-py3-none-any.whl.metadata (8.1 kB)\n",
      "Collecting urllib3<2.0.0,>=1.0.0 (from flair->textattack)\n",
      "  Obtaining dependency information for urllib3<2.0.0,>=1.0.0 from https://files.pythonhosted.org/packages/ae/6a/99eaaeae8becaa17a29aeb334a18e5d582d873b6f084c11f02581b8d7f7f/urllib3-1.26.19-py2.py3-none-any.whl.metadata\n",
      "  Downloading urllib3-1.26.19-py2.py3-none-any.whl.metadata (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting wikipedia-api>=0.5.7 (from flair->textattack)\n",
      "  Obtaining dependency information for wikipedia-api>=0.5.7 from https://files.pythonhosted.org/packages/2f/3f/919727b460d88c899d110f98d1a0c415264b5d8ad8176f14ce7ad9db0e3b/Wikipedia_API-0.6.0-py3-none-any.whl.metadata\n",
      "  Downloading Wikipedia_API-0.6.0-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting semver<4.0.0,>=3.0.0 (from flair->textattack)\n",
      "  Obtaining dependency information for semver<4.0.0,>=3.0.0 from https://files.pythonhosted.org/packages/9a/77/0cc7a8a3bc7e53d07e8f47f147b92b0960e902b8254859f4aee5c4d7866b/semver-3.0.2-py3-none-any.whl.metadata\n",
      "  Downloading semver-3.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: pip in ./anaconda3/lib/python3.11/site-packages (from language-tool-python->textattack) (23.2.1)\n",
      "Requirement already satisfied: wheel in ./anaconda3/lib/python3.11/site-packages (from language-tool-python->textattack) (0.38.4)\n",
      "Requirement already satisfied: click in ./anaconda3/lib/python3.11/site-packages (from nltk->textattack) (8.1.7)\n",
      "Requirement already satisfied: joblib in ./anaconda3/lib/python3.11/site-packages (from nltk->textattack) (1.2.0)\n",
      "Collecting docopt>=0.6.2 (from num2words->textattack)\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting anytree (from OpenHowNet->textattack)\n",
      "  Obtaining dependency information for anytree from https://files.pythonhosted.org/packages/6a/fb/ff946843e6b55ae9fda84df3964d6c233cd2261dface789f5be02ab79bc5/anytree-2.12.1-py3-none-any.whl.metadata\n",
      "  Downloading anytree-2.12.1-py3-none-any.whl.metadata (8.1 kB)\n",
      "Requirement already satisfied: setuptools in ./anaconda3/lib/python3.11/site-packages (from OpenHowNet->textattack) (70.0.0)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.127 in ./anaconda3/lib/python3.11/site-packages (from boto3>=1.20.27->flair->textattack) (1.34.127)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in ./anaconda3/lib/python3.11/site-packages (from boto3>=1.20.27->flair->textattack) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in ./anaconda3/lib/python3.11/site-packages (from boto3>=1.20.27->flair->textattack) (0.10.1)\n",
      "Collecting sentencepiece (from bpemb>=0.3.2->flair->textattack)\n",
      "  Obtaining dependency information for sentencepiece from https://files.pythonhosted.org/packages/fb/12/2f5c8d4764b00033cf1c935b702d3bb878d10be9f0b87f0253495832d85f/sentencepiece-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading sentencepiece-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in ./anaconda3/lib/python3.11/site-packages (from deprecated>=1.2.13->flair->textattack) (1.14.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./anaconda3/lib/python3.11/site-packages (from aiohttp->datasets>=2.4.0->textattack) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./anaconda3/lib/python3.11/site-packages (from aiohttp->datasets>=2.4.0->textattack) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./anaconda3/lib/python3.11/site-packages (from aiohttp->datasets>=2.4.0->textattack) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./anaconda3/lib/python3.11/site-packages (from aiohttp->datasets>=2.4.0->textattack) (6.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./anaconda3/lib/python3.11/site-packages (from aiohttp->datasets>=2.4.0->textattack) (1.8.1)\n",
      "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in ./anaconda3/lib/python3.11/site-packages (from ftfy>=6.1.0->flair->textattack) (0.2.13)\n",
      "Requirement already satisfied: beautifulsoup4 in ./anaconda3/lib/python3.11/site-packages (from gdown>=4.4.0->flair->textattack) (4.12.3)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in ./anaconda3/lib/python3.11/site-packages (from gensim>=4.2.0->flair->textattack) (5.2.1)\n",
      "Collecting FuzzyTM>=0.4.0 (from gensim>=4.2.0->flair->textattack)\n",
      "  Obtaining dependency information for FuzzyTM>=0.4.0 from https://files.pythonhosted.org/packages/2d/30/074bac7a25866a2807c1005c7852c0139ac22ba837871fc01f16df29b9dc/FuzzyTM-2.0.9-py3-none-any.whl.metadata\n",
      "  Downloading FuzzyTM-2.0.9-py3-none-any.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: six in ./anaconda3/lib/python3.11/site-packages (from langdetect>=1.0.9->flair->textattack) (1.16.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./anaconda3/lib/python3.11/site-packages (from matplotlib->bert-score>=0.3.5->textattack) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in ./anaconda3/lib/python3.11/site-packages (from matplotlib->bert-score>=0.3.5->textattack) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./anaconda3/lib/python3.11/site-packages (from matplotlib->bert-score>=0.3.5->textattack) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./anaconda3/lib/python3.11/site-packages (from matplotlib->bert-score>=0.3.5->textattack) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in ./anaconda3/lib/python3.11/site-packages (from matplotlib->bert-score>=0.3.5->textattack) (9.4.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in ./anaconda3/lib/python3.11/site-packages (from matplotlib->bert-score>=0.3.5->textattack) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./anaconda3/lib/python3.11/site-packages (from requests->bert-score>=0.3.5->textattack) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./anaconda3/lib/python3.11/site-packages (from requests->bert-score>=0.3.5->textattack) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./anaconda3/lib/python3.11/site-packages (from requests->bert-score>=0.3.5->textattack) (2024.6.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./anaconda3/lib/python3.11/site-packages (from scikit-learn>=1.0.2->flair->textattack) (3.5.0)\n",
      "Requirement already satisfied: protobuf in ./anaconda3/lib/python3.11/site-packages (from transformers>=4.30.0->textattack) (4.21.12)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./anaconda3/lib/python3.11/site-packages (from jinja2->torch!=1.8,>=1.7.0->textattack) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./anaconda3/lib/python3.11/site-packages (from sympy->torch!=1.8,>=1.7.0->textattack) (1.3.0)\n",
      "Collecting pyfume (from FuzzyTM>=0.4.0->gensim>=4.2.0->flair->textattack)\n",
      "  Obtaining dependency information for pyfume from https://files.pythonhosted.org/packages/ed/ea/a3b120e251145dcdb10777f2bc5f18b1496fd999d705a178c1b0ad947ce1/pyFUME-0.3.4-py3-none-any.whl.metadata\n",
      "  Downloading pyFUME-0.3.4-py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting accelerate>=0.21.0 (from transformers>=4.30.0->textattack)\n",
      "  Obtaining dependency information for accelerate>=0.21.0 from https://files.pythonhosted.org/packages/e4/74/564f621699b049b0358f7ad83d7437f8219a5d6efb69bbfcca328b60152f/accelerate-0.32.1-py3-none-any.whl.metadata\n",
      "  Downloading accelerate-0.32.1-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./anaconda3/lib/python3.11/site-packages (from beautifulsoup4->gdown>=4.4.0->flair->textattack) (2.5)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in ./anaconda3/lib/python3.11/site-packages (from requests->bert-score>=0.3.5->textattack) (1.7.1)\n",
      "Requirement already satisfied: psutil in ./anaconda3/lib/python3.11/site-packages (from accelerate>=0.21.0->transformers>=4.30.0->textattack) (5.9.8)\n",
      "Collecting scipy>=1.4.1 (from textattack)\n",
      "  Obtaining dependency information for scipy>=1.4.1 from https://files.pythonhosted.org/packages/21/cd/fe2d4af234b80dc08c911ce63fdaee5badcdde3e9bcd9a68884580652ef0/scipy-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading scipy-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.9/58.9 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting numpy>=1.21.0 (from textattack)\n",
      "  Obtaining dependency information for numpy>=1.21.0 from https://files.pythonhosted.org/packages/22/97/dfb1a31bb46686f09e68ea6ac5c63fdee0d22d7b23b8f3f7ea07712869ef/numpy-1.24.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading numpy-1.24.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Collecting simpful==2.12.0 (from pyfume->FuzzyTM>=0.4.0->gensim>=4.2.0->flair->textattack)\n",
      "  Obtaining dependency information for simpful==2.12.0 from https://files.pythonhosted.org/packages/9d/0e/aebc2fb0b0f481994179b2ee2b8e6bbf0894d971594688c018375e7076ea/simpful-2.12.0-py3-none-any.whl.metadata\n",
      "  Downloading simpful-2.12.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting fst-pso==1.8.1 (from pyfume->FuzzyTM>=0.4.0->gensim>=4.2.0->flair->textattack)\n",
      "  Downloading fst-pso-1.8.1.tar.gz (18 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pandas>=1.0.1 (from textattack)\n",
      "  Obtaining dependency information for pandas>=1.0.1 from https://files.pythonhosted.org/packages/56/73/3351beeb807dca69fcc3c4966bcccc51552bd01549a9b13c04ab00a43f21/pandas-1.5.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading pandas-1.5.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting miniful (from fst-pso==1.8.1->pyfume->FuzzyTM>=0.4.0->gensim>=4.2.0->flair->textattack)\n",
      "  Downloading miniful-0.0.6.tar.gz (2.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hDownloading textattack-0.3.10-py3-none-any.whl (445 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m445.7/445.7 kB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading editdistance-0.8.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (412 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.9/412.9 kB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading flair-0.13.1-py3-none-any.whl (388 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.3/388.3 kB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading more_itertools-10.3.0-py3-none-any.whl (59 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.2/59.2 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading language_tool_python-2.8-py3-none-any.whl (35 kB)\n",
      "Downloading lemminflect-0.2.3-py3-none-any.whl (769 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m769.7/769.7 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading lru_dict-1.3.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
      "Downloading num2words-0.5.13-py3-none-any.whl (143 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.3/143.3 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading OpenHowNet-2.0-py3-none-any.whl (18 kB)\n",
      "Downloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\n",
      "Downloading bpemb-0.3.5-py3-none-any.whl (19 kB)\n",
      "Downloading conllu-4.5.3-py2.py3-none-any.whl (16 kB)\n",
      "Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading ftfy-6.2.0-py3-none-any.whl (54 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading gdown-5.2.0-py3-none-any.whl (18 kB)\n",
      "Downloading Janome-0.5.0-py2.py3-none-any.whl (19.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading mpld3-0.5.10-py3-none-any.whl (202 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.6/202.6 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytorch_revgrad-0.2.0-py3-none-any.whl (4.6 kB)\n",
      "Downloading segtok-1.5.11-py3-none-any.whl (24 kB)\n",
      "Downloading semver-3.0.2-py3-none-any.whl (17 kB)\n",
      "Downloading transformer_smaller_training_vocab-0.4.0-py3-none-any.whl (14 kB)\n",
      "Downloading urllib3-1.26.19-py2.py3-none-any.whl (143 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.9/143.9 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Wikipedia_API-0.6.0-py3-none-any.whl (14 kB)\n",
      "Downloading anytree-2.12.1-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.9/44.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading FuzzyTM-2.0.9-py3-none-any.whl (31 kB)\n",
      "Downloading sentencepiece-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-0.32.1-py3-none-any.whl (314 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.1/314.1 kB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyFUME-0.3.4-py3-none-any.whl (60 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.3/60.3 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.24.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pandas-1.5.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0mm\n",
      "\u001b[?25hDownloading scipy-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.1/34.1 MB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading simpful-2.12.0-py3-none-any.whl (24 kB)\n",
      "Building wheels for collected packages: pinyin, jieba, word2number, docopt, langdetect, pptree, sqlitedict, fst-pso, miniful\n",
      "  Building wheel for pinyin (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pinyin: filename=pinyin-0.4.0-py3-none-any.whl size=3630476 sha256=9b18fffc16d71c846f9dcfb8caa84e3bc7e999f9126d059205b335a9f774ce70\n",
      "  Stored in directory: /home/mist861/.cache/pip/wheels/1c/f5/31/ac8c91eccb570a59fe5f1471ad9f11bece8f4fd4be1ab1be25\n",
      "  Building wheel for jieba (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jieba: filename=jieba-0.42.1-py3-none-any.whl size=19314458 sha256=55e625cdaaf75e4d152b2bc9f85751c2f2f06c33e282c2ca80ecbc544fd2df64\n",
      "  Stored in directory: /home/mist861/.cache/pip/wheels/ac/60/cf/538a1f183409caf1fc136b5d2c2dee329001ef6da2c5084bef\n",
      "  Building wheel for word2number (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5566 sha256=d5b08766554773cfbabd9f6c9dfc9f28abcfe91a4fe4945100dea9ce3e49b581\n",
      "  Stored in directory: /home/mist861/.cache/pip/wheels/cd/ef/ae/073b491b14d25e2efafcffca9e16b2ee6d114ec5c643ba4f06\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13705 sha256=a485e338e53fc3528882243cabac2bfd28da88995ac32727d7ac3bd287d65853\n",
      "  Stored in directory: /home/mist861/.cache/pip/wheels/1a/b0/8c/4b75c4116c31f83c8f9f047231251e13cc74481cca4a78a9ce\n",
      "  Building wheel for langdetect (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993225 sha256=ba590f971002ae22212b62dc68ca496e958ad9677b08178bc98fb82140faebf4\n",
      "  Stored in directory: /home/mist861/.cache/pip/wheels/0a/f2/b2/e5ca405801e05eb7c8ed5b3b4bcf1fcabcd6272c167640072e\n",
      "  Building wheel for pptree (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pptree: filename=pptree-3.1-py3-none-any.whl size=4608 sha256=919f6907db55f5c084f8905c18baebd34c34ab0f80a58e13b69c534030036c39\n",
      "  Stored in directory: /home/mist861/.cache/pip/wheels/68/8a/eb/d683aa6d09dc68ebfde2f37566ddc8807837c4415b4fd2b04c\n",
      "  Building wheel for sqlitedict (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16864 sha256=12579356e1c056da9747c176c8873a4cdcfd2cac9bffdfcbfab4d518b4df0ee7\n",
      "  Stored in directory: /home/mist861/.cache/pip/wheels/73/63/89/7210274f9b7fb033b8f22671f64c0e0b55083d30c3c046a3ff\n",
      "  Building wheel for fst-pso (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fst-pso: filename=fst_pso-1.8.1-py3-none-any.whl size=20430 sha256=cfd459c48fbdf5b0e687236819dbbe31cf7c2a6981dec35dbd0094bf2f26bca2\n",
      "  Stored in directory: /home/mist861/.cache/pip/wheels/69/f5/e5/18ad53fe1ed6b2af9fad05ec052e4acbac8e92441df44bad2e\n",
      "  Building wheel for miniful (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for miniful: filename=miniful-0.0.6-py3-none-any.whl size=3513 sha256=d4bee6b7bd2228e2aad551471365f5d84e6ed563c3fa8c5a8cabb0e5101d2922\n",
      "  Stored in directory: /home/mist861/.cache/pip/wheels/9d/ff/2f/afe4cd56f47de147407705626517d68bea0f3b74eb1fb168e6\n",
      "Successfully built pinyin jieba word2number docopt langdetect pptree sqlitedict fst-pso miniful\n",
      "Installing collected packages: word2number, sqlitedict, sentencepiece, pptree, pinyin, jieba, janome, docopt, urllib3, terminaltables, semver, segtok, numpy, num2words, more-itertools, lru-dict, langdetect, ftfy, editdistance, deprecated, conllu, anytree, scipy, pandas, lemminflect, wikipedia-api, simpful, OpenHowNet, miniful, language-tool-python, pytorch-revgrad, mpld3, gdown, fst-pso, accelerate, pyfume, FuzzyTM, bert-score, transformer-smaller-training-vocab, bpemb, flair, textattack\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.2.2\n",
      "    Uninstalling urllib3-2.2.2:\n",
      "      Successfully uninstalled urllib3-2.2.2\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "  Attempting uninstall: more-itertools\n",
      "    Found existing installation: more-itertools 8.12.0\n",
      "    Uninstalling more-itertools-8.12.0:\n",
      "      Successfully uninstalled more-itertools-8.12.0\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.11.1\n",
      "    Uninstalling scipy-1.11.1:\n",
      "      Successfully uninstalled scipy-1.11.1\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.0.3\n",
      "    Uninstalling pandas-2.0.3:\n",
      "      Successfully uninstalled pandas-2.0.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tables 3.8.0 requires blosc2~=2.0.0, which is not installed.\n",
      "tables 3.8.0 requires cython>=0.29.21, which is not installed.\n",
      "types-requests 2.32.0.20240602 requires urllib3>=2, but you have urllib3 1.26.19 which is incompatible.\n",
      "semantic-router 0.0.48 requires numpy<2.0.0,>=1.25.2, but you have numpy 1.24.4 which is incompatible.\n",
      "conda-repo-cli 1.0.75 requires clyent==1.2.1, but you have clyent 1.2.2 which is incompatible.\n",
      "conda-repo-cli 1.0.75 requires nbformat==5.9.2, but you have nbformat 5.10.4 which is incompatible.\n",
      "conda-repo-cli 1.0.75 requires python-dateutil==2.8.2, but you have python-dateutil 2.9.0.post0 which is incompatible.\n",
      "conda-repo-cli 1.0.75 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed FuzzyTM-2.0.9 OpenHowNet-2.0 accelerate-0.32.1 anytree-2.12.1 bert-score-0.3.13 bpemb-0.3.5 conllu-4.5.3 deprecated-1.2.14 docopt-0.6.2 editdistance-0.8.1 flair-0.13.1 fst-pso-1.8.1 ftfy-6.2.0 gdown-5.2.0 janome-0.5.0 jieba-0.42.1 langdetect-1.0.9 language-tool-python-2.8 lemminflect-0.2.3 lru-dict-1.3.0 miniful-0.0.6 more-itertools-10.3.0 mpld3-0.5.10 num2words-0.5.13 numpy-1.24.4 pandas-1.5.3 pinyin-0.4.0 pptree-3.1 pyfume-0.3.4 pytorch-revgrad-0.2.0 scipy-1.10.1 segtok-1.5.11 semver-3.0.2 sentencepiece-0.2.0 simpful-2.12.0 sqlitedict-2.1.0 terminaltables-3.1.10 textattack-0.3.10 transformer-smaller-training-vocab-0.4.0 urllib3-1.26.19 wikipedia-api-0.6.0 word2number-1.1\n",
      "Collecting googletrans\n",
      "  Downloading googletrans-3.0.0.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting httpx==0.13.3 (from googletrans)\n",
      "  Obtaining dependency information for httpx==0.13.3 from https://files.pythonhosted.org/packages/54/b4/698b284c6aed4d7c2b4fe3ba5df1fcf6093612423797e76fbb24890dd22f/httpx-0.13.3-py3-none-any.whl.metadata\n",
      "  Downloading httpx-0.13.3-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: certifi in ./anaconda3/lib/python3.11/site-packages (from httpx==0.13.3->googletrans) (2024.6.2)\n",
      "Collecting hstspreload (from httpx==0.13.3->googletrans)\n",
      "  Obtaining dependency information for hstspreload from https://files.pythonhosted.org/packages/0a/3a/68a6388bd8147bd527996a57254234662038e5ea6d14f162bc84653d81d4/hstspreload-2024.7.1-py3-none-any.whl.metadata\n",
      "  Downloading hstspreload-2024.7.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: sniffio in ./anaconda3/lib/python3.11/site-packages (from httpx==0.13.3->googletrans) (1.3.1)\n",
      "Collecting chardet==3.* (from httpx==0.13.3->googletrans)\n",
      "  Obtaining dependency information for chardet==3.* from https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl.metadata\n",
      "  Downloading chardet-3.0.4-py2.py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting idna==2.* (from httpx==0.13.3->googletrans)\n",
      "  Obtaining dependency information for idna==2.* from https://files.pythonhosted.org/packages/a2/38/928ddce2273eaa564f6f50de919327bf3a00f091b5baba8dfa9460f3a8a8/idna-2.10-py2.py3-none-any.whl.metadata\n",
      "  Downloading idna-2.10-py2.py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting rfc3986<2,>=1.3 (from httpx==0.13.3->googletrans)\n",
      "  Obtaining dependency information for rfc3986<2,>=1.3 from https://files.pythonhosted.org/packages/c4/e5/63ca2c4edf4e00657584608bee1001302bbf8c5f569340b78304f2f446cb/rfc3986-1.5.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting httpcore==0.9.* (from httpx==0.13.3->googletrans)\n",
      "  Obtaining dependency information for httpcore==0.9.* from https://files.pythonhosted.org/packages/dd/d5/e4ff9318693ac6101a2095e580908b591838c6f33df8d3ee8dd953ba96a8/httpcore-0.9.1-py3-none-any.whl.metadata\n",
      "  Downloading httpcore-0.9.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting h11<0.10,>=0.8 (from httpcore==0.9.*->httpx==0.13.3->googletrans)\n",
      "  Obtaining dependency information for h11<0.10,>=0.8 from https://files.pythonhosted.org/packages/5a/fd/3dad730b0f95e78aeeb742f96fa7bbecbdd56a58e405d3da440d5bfb90c6/h11-0.9.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading h11-0.9.0-py2.py3-none-any.whl.metadata (8.1 kB)\n",
      "Collecting h2==3.* (from httpcore==0.9.*->httpx==0.13.3->googletrans)\n",
      "  Obtaining dependency information for h2==3.* from https://files.pythonhosted.org/packages/25/de/da019bcc539eeab02f6d45836f23858ac467f584bfec7a526ef200242afe/h2-3.2.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading h2-3.2.0-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Collecting hyperframe<6,>=5.2.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans)\n",
      "  Obtaining dependency information for hyperframe<6,>=5.2.0 from https://files.pythonhosted.org/packages/19/0c/bf88182bcb5dce3094e2f3e4fe20db28a9928cb7bd5b08024030e4b140db/hyperframe-5.2.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting hpack<4,>=3.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans)\n",
      "  Obtaining dependency information for hpack<4,>=3.0 from https://files.pythonhosted.org/packages/8a/cc/e53517f4a1e13f74776ca93271caef378dadec14d71c61c949d759d3db69/hpack-3.0.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading hpack-3.0.0-py2.py3-none-any.whl.metadata (7.0 kB)\n",
      "Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.1/55.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
      "Downloading hstspreload-2024.7.1-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
      "Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
      "Building wheels for collected packages: googletrans\n",
      "  Building wheel for googletrans (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for googletrans: filename=googletrans-3.0.0-py3-none-any.whl size=15719 sha256=a2accbfc224654b59cd63ffdd958fabd582a0d7fdcbfdb6d2e54314e8d0cc80d\n",
      "  Stored in directory: /home/mist861/.cache/pip/wheels/a0/a7/f5/8029729ab74f860fab6614e312b0aa48b665d1057280bc2ef3\n",
      "Successfully built googletrans\n",
      "Installing collected packages: rfc3986, hyperframe, hpack, h11, chardet, idna, hstspreload, h2, httpcore, httpx, googletrans\n",
      "  Attempting uninstall: h11\n",
      "    Found existing installation: h11 0.14.0\n",
      "    Uninstalling h11-0.14.0:\n",
      "      Successfully uninstalled h11-0.14.0\n",
      "  Attempting uninstall: chardet\n",
      "    Found existing installation: chardet 4.0.0\n",
      "    Uninstalling chardet-4.0.0:\n",
      "      Successfully uninstalled chardet-4.0.0\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.7\n",
      "    Uninstalling idna-3.7:\n",
      "      Successfully uninstalled idna-3.7\n",
      "  Attempting uninstall: httpcore\n",
      "    Found existing installation: httpcore 1.0.5\n",
      "    Uninstalling httpcore-1.0.5:\n",
      "      Successfully uninstalled httpcore-1.0.5\n",
      "  Attempting uninstall: httpx\n",
      "    Found existing installation: httpx 0.27.0\n",
      "    Uninstalling httpx-0.27.0:\n",
      "      Successfully uninstalled httpx-0.27.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 5.4.3 requires pyqt5<5.16, which is not installed.\n",
      "spyder 5.4.3 requires pyqtwebengine<5.16, which is not installed.\n",
      "spyder 5.4.3 requires jedi<0.19.0,>=0.17.2, but you have jedi 0.19.1 which is incompatible.\n",
      "spyder 5.4.3 requires qtconsole<5.5.0,>=5.4.2, but you have qtconsole 5.5.2 which is incompatible.\n",
      "openai 1.34.0 requires httpx<1,>=0.23.0, but you have httpx 0.13.3 which is incompatible.\n",
      "semantic-router 0.0.48 requires numpy<2.0.0,>=1.25.2, but you have numpy 1.24.4 which is incompatible.\n",
      "cohere 5.5.3 requires httpx>=0.21.2, but you have httpx 0.13.3 which is incompatible.\n",
      "jupyterlab 4.2.2 requires httpx>=0.25.0, but you have httpx 0.13.3 which is incompatible.\n",
      "conda-repo-cli 1.0.75 requires clyent==1.2.1, but you have clyent 1.2.2 which is incompatible.\n",
      "conda-repo-cli 1.0.75 requires nbformat==5.9.2, but you have nbformat 5.10.4 which is incompatible.\n",
      "conda-repo-cli 1.0.75 requires python-dateutil==2.8.2, but you have python-dateutil 2.9.0.post0 which is incompatible.\n",
      "conda-repo-cli 1.0.75 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed chardet-3.0.4 googletrans-3.0.0 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2024.7.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 idna-2.10 rfc3986-1.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install textattack\n",
    "!pip install googletrans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fca522e3-709d-4e17-904e-442084e35d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textattack.augmentation import EasyDataAugmenter, CharSwapAugmenter\n",
    "import googletrans\n",
    "from googletrans import Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4c4d5d51-c77a-4dd5-9be4-90e6a7b1b7e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Cuckoo there\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"HQi there\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Mode are you\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Hw are you\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Is person there?\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"I anyone there?\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"Howdy\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"eHllo\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"Alright day\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"Gotd day\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            utterance    intent\n",
       "0      \"Cuckoo there\"  greeting\n",
       "1         \"HQi there\"  greeting\n",
       "2      \"Mode are you\"  greeting\n",
       "3        \"Hw are you\"  greeting\n",
       "4  \"Is person there?\"  greeting\n",
       "5   \"I anyone there?\"  greeting\n",
       "6             \"Howdy\"  greeting\n",
       "7             \"eHllo\"  greeting\n",
       "8       \"Alright day\"  greeting\n",
       "9          \"Gotd day\"  greeting"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_intents = {'utterance':[],'intent':[]}\n",
    "easy_aug = EmbeddingAugmenter()\n",
    "swap_aug = CharSwapAugmenter()\n",
    "for intent in intent_full_df['intent'].unique():\n",
    "    temp_df = intent_full_df.loc[intent_full_df['intent'] == intent]\n",
    "    for utterance in temp_df['utterance']:\n",
    "        augmented_intents['utterance'].extend([easy_aug.augment(utterance)[0],swap_aug.augment(utterance)[0]])\n",
    "        augmented_intents['intent'].extend([intent,intent])\n",
    "intent_augmented_df = pd.DataFrame.from_dict(augmented_intents)\n",
    "intent_augmented_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9b447f2c-9ac0-47dd-88de-fd10ca149efe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(530, 2)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intent_augmented_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cd22fcc2-7d4f-4e25-b89f-6ecf17610f6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(795, 2)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intent_augmented_full_df = pd.concat([intent_full_df,intent_augmented_df],axis=0)\n",
    "intent_augmented_full_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "78962dbc-ec68-4bf0-905b-d9499beeb44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_augmented_full_df.to_csv('/mnt/c/Users/willi/Downloads/intent_augmented_dataset.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939daff2-2fec-4c6a-8423-6cdb5e05d6c8",
   "metadata": {},
   "source": [
    "## Dataset Load and Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4634bb81-9a42-4c79-9690-4a13e5ea0dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_df = pd.read_csv('/mnt/c/Users/willi/Downloads/intent_augmented_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db7a39ad-0de3-4f83-a7da-0cd4fd9be34d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Hi there\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"How are you\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Is anyone there?\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Hello\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Good day\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"Bye\"</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"See you later\"</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"Goodbye\"</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"Nice chatting to you, bye\"</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"Till next time\"</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     utterance    intent\n",
       "0                   \"Hi there\"  greeting\n",
       "1                \"How are you\"  greeting\n",
       "2           \"Is anyone there?\"  greeting\n",
       "3                      \"Hello\"  greeting\n",
       "4                   \"Good day\"  greeting\n",
       "5                        \"Bye\"   goodbye\n",
       "6              \"See you later\"   goodbye\n",
       "7                    \"Goodbye\"   goodbye\n",
       "8  \"Nice chatting to you, bye\"   goodbye\n",
       "9             \"Till next time\"   goodbye"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intent_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8eeea33-e482-4bb7-8958-92a075611eaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(795, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intent_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1bd59a8b-fa46-4e28-926e-5e7291e2b600",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = intent_df['utterance']\n",
    "y = intent_df['intent']\n",
    "X_train_df, X_test_df, y_train_df, y_test_df = train_test_split(X, y, random_state=42, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82fd95d2-a610-4484-9460-ccdb854026e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.concat([X_test_df,y_test_df],axis=1)\n",
    "train_df = pd.concat([X_train_df,y_train_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d92908a-2a68-4239-978d-6eb304a775b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>\"Could you get my prescription poised for me?\"</td>\n",
       "      <td>medication</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>\"Search for hospitals with urgen care services.\"</td>\n",
       "      <td>hospital_search</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>\"Hey, good to see you!\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>\"Whereof are my blood pressure levels?\"</td>\n",
       "      <td>blood_pressure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>\"Bye!\"</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>\"I require the attention of a physician.\"</td>\n",
       "      <td>doctor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>\"'m grateful.\"</td>\n",
       "      <td>thanks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>\"I'd like to order a new batch of my medicatio...</td>\n",
       "      <td>medication</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>\"WhaW's the verdict on my blood pressure today?\"</td>\n",
       "      <td>blood_pressure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>\"Where can I byu over-the-counter medications?\"</td>\n",
       "      <td>pharmacy_search</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             utterance           intent\n",
       "691     \"Could you get my prescription poised for me?\"       medication\n",
       "662   \"Search for hospitals with urgen care services.\"  hospital_search\n",
       "63                             \"Hey, good to see you!\"         greeting\n",
       "531            \"Whereof are my blood pressure levels?\"   blood_pressure\n",
       "66                                              \"Bye!\"          goodbye\n",
       "749          \"I require the attention of a physician.\"           doctor\n",
       "382                                     \"'m grateful.\"           thanks\n",
       "683  \"I'd like to order a new batch of my medicatio...       medication\n",
       "554   \"WhaW's the verdict on my blood pressure today?\"   blood_pressure\n",
       "624    \"Where can I byu over-the-counter medications?\"  pharmacy_search"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "59ebeb94-9533-42c5-884c-2d0c3f1d21c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>\"oodnight!\"</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>\"I have digestive issues such as bloating or i...</td>\n",
       "      <td>symptoms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>\"Rhat do you specialize in?\"</td>\n",
       "      <td>options</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>\"yBe!\"</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>\"What are the riIks or drawbacks of this medic...</td>\n",
       "      <td>adverse_drug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>\"Thaxnk you\"</td>\n",
       "      <td>thanks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>\"See you soon!\"</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>\"What are my blood pressure levels?\"</td>\n",
       "      <td>blood_pressure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>\"How is my blood pressure looking yesterday?\"</td>\n",
       "      <td>blood_pressure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>\"I'm appreciate.\"</td>\n",
       "      <td>thanks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             utterance          intent\n",
       "360                                        \"oodnight!\"         goodbye\n",
       "264  \"I have digestive issues such as bloating or i...        symptoms\n",
       "440                       \"Rhat do you specialize in?\"         options\n",
       "328                                             \"yBe!\"         goodbye\n",
       "486  \"What are the riIks or drawbacks of this medic...    adverse_drug\n",
       "368                                       \"Thaxnk you\"          thanks\n",
       "79                                     \"See you soon!\"         goodbye\n",
       "148               \"What are my blood pressure levels?\"  blood_pressure\n",
       "529      \"How is my blood pressure looking yesterday?\"  blood_pressure\n",
       "381                                  \"I'm appreciate.\"          thanks"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34e42d8-d40b-441f-a556-9632a7bfa33c",
   "metadata": {},
   "source": [
    "# RAG Intent Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83475981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in ./anaconda3/lib/python3.11/site-packages (2.3.1)\n",
      "Requirement already satisfied: filelock in ./anaconda3/lib/python3.11/site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./anaconda3/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in ./anaconda3/lib/python3.11/site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in ./anaconda3/lib/python3.11/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in ./anaconda3/lib/python3.11/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in ./anaconda3/lib/python3.11/site-packages (from torch) (2024.6.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./anaconda3/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./anaconda3/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./anaconda3/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./anaconda3/lib/python3.11/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./anaconda3/lib/python3.11/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./anaconda3/lib/python3.11/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./anaconda3/lib/python3.11/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./anaconda3/lib/python3.11/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./anaconda3/lib/python3.11/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in ./anaconda3/lib/python3.11/site-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./anaconda3/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.1 in ./anaconda3/lib/python3.11/site-packages (from torch) (2.3.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./anaconda3/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.40)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./anaconda3/lib/python3.11/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./anaconda3/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: transformers in ./anaconda3/lib/python3.11/site-packages (4.42.3)\n",
      "Requirement already satisfied: filelock in ./anaconda3/lib/python3.11/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in ./anaconda3/lib/python3.11/site-packages (from transformers) (0.23.4)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17 in ./anaconda3/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./anaconda3/lib/python3.11/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./anaconda3/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./anaconda3/lib/python3.11/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in ./anaconda3/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./anaconda3/lib/python3.11/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in ./anaconda3/lib/python3.11/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./anaconda3/lib/python3.11/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./anaconda3/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./anaconda3/lib/python3.11/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./anaconda3/lib/python3.11/site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./anaconda3/lib/python3.11/site-packages (from requests->transformers) (2024.6.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U torch\n",
    "!pip install -U transformers\n",
    "!pip install -qU \"semantic-router[local]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a8f807d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from semantic_router import Route\n",
    "from semantic_router import RouteLayer\n",
    "from semantic_router.encoders import HuggingFaceEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ce12466d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_device(\"cuda\")\n",
    "\n",
    "#model = AutoModelForCausalLM.from_pretrained('microsoft/phi-1_5', torch_dtype='auto')\n",
    "#tokenizer = AutoTokenizer.from_pretrained('microsoft/phi-1_5')\n",
    "\n",
    "\n",
    "#model_id = \"failspy/Phi-3-mini-128k-instruct-abliterated-v3-GGUF\"\n",
    "#filename = \"Phi-3-mini-128k-instruct-abliterated-v3_q8.gguf\"\n",
    "\n",
    "#model = AutoModelForCausalLM.from_pretrained(model_id, gguf_file=filename, torch_dtype='auto')\n",
    "#tokenizer = AutoTokenizer.from_pretrained(model_id, gguf_file=filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3aa21ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Route(name='goodbye', utterances=['\"oodnight!\"', '\"yBe!\"', '\"See you soon!\"', '\"Farewell\"', '\"Placid out!\"', '\"Take care!\"', '\"Farewell!\"', '\"Goodnight!\"', '\"See you later\"', '\"Until next time!\"', '\"ByO\"', '\"Behold ya!\"', '\"Bye-Uye!\"', '\"Take it effortless!\"', '\"See you almost!\"', '\"Take healthcare!\"', '\"Have a good one!\"', '\"Hiya!\"', '\"Have a ood one!\"', '\"I must be going.\"', '\"Have a great dgy!\"', '\"Take caNre!\"', '\"Gntil next time!\"', '\"Till next itme\"', '\"Till next time\"', '\"Catch you ater!\"', '\"Have a buena one!\"', '\"So long!\"', '\"See ya!\"', '\"See you late\"', '\"Bye-bye!\"', '\"Enjoyable chatting to you, bye\"', '\"See you speedily!\"', '\"Goodbey\"', '\"SeCe you soon!\"', '\"Until future time!\"', '\"Goodnight!\"', '\"Nice hatting to you, bye\"', '\"Bye\"', '\"Peaec out!\"', '\"Nice chatting to you, bye\"', '\"zAdios!\"', '\"Adieu!\"', '\"See you afterward\"', '\"eSe you around!\"', '\"Adieu!\"', '\"Ha a good one!\"', '\"Take it easy!\"', '\"Catch you subsequent!\"', '\"So lang!\"', '\"Goodbye\"', '\"I should be going.\"', '\"wee you later!\"', '\"Have a good one!\"'], description=None, function_schemas=None, llm=None, score_threshold=None), Route(name='symptoms', utterances=['\"I have digestive issues such as bloating or indigestion.\"', '\"I\\'m experiencing diarrhoea.\"', '\"I feel dizzy and lihtheaded.\"', '\"I have a persistent headache.\"', '\"I have a rash or skin irritation.\"', '\"I have a persistent haedache.\"', '\"I feel extraordinarily tired and lethargic.\"', '\"My throat is sore and scratchy.\"', '\"I have chest tightness and discomfort.\"', '\"I feel short of breath.\"', '\"I have digestive issues such as bloating or constipation.\"', '\"I feel fatigued and weak.\"', '\"I have torso tightness and discomfort.\"', '\"I feel extremely tired and lehargic.\"', '\"I\\'m experiencing sensitivity to light/noise.\"', '\"I have digestive issues such as bloatxing or indigestion.\"', '\"I have a fever and chils.\"', '\"I have a runny nose and overpopulation.\"', '\"I have a rcash or skin irritation.\"', '\"I\\'m feeling unusually cold or hot.\"', '\"I have a fever and chills.\"', '\"I feel shot of breath.\"', '\"I\\'m experiencing diarrhea.\"', '\"I feel jaded and weak.\"', '\"I\\'m experiencing sensitivity to light/sonora.\"', '\"I have chest tightenss and discomfort.\"', '\"I have abdominal pani and cramping.\"', '\"My larynx is sore and scratchy.\"', '\"I feel fatgiued and weak.\"', '\"I have a runny noqe and congestion.\"', '\"I\\'m coughing and wjeezing.\"', '\"I\\'m coughs and wheezing.\"', '\"I feel dizzy and lightheaded.\"', '\"I have trouble concentrating or thinking clearly.\"', '\"I\\'m experiencing nauea and vomiting.\"', '\"I\\'m experiencing nausea and vomiting.\"', '\"I have muscle ahces and pains.\"', '\"My joints are swollen and painful.\"', '\"I have a impulsive or skin irritation.\"', '\"My throat is sore and scrNatchy.\"', '\"I have a fever and goosebumps.\"', '\"I have abdominal heartbreak and cramping.\"', '\"I\\'m coughing and wheezing.\"', '\"I\\'m feelinu unusually cold or hot.\"', '\"I\\'m experiencing sensitivity to light/nBoise.\"', '\"I feel succinct of breath.\"', '\"I have muscle aches and pains.\"', '\"I have muscle evils and pains.\"'], description=None, function_schemas=None, llm=None, score_threshold=None), Route(name='options', utterances=['\"Rhat do you specialize in?\"', '\"What are your abilSities?\"', '\"Whar are your competencies?\"', '\"Quel are your talents?\"', '\"What are your professional proficiency?\"', '\"What are you capaoble of?\"', '\"Whar are your abilities?\"', '\"What are your talents?\"', '\"How you can be helpful?\"', '\"What are your proficiencees?\"', '\"Whereof are your capabilities?\"', '\"What support is offering\"', '\"What kind of tasks are you Xood at?\"', '\"What are your capabilities?\"', '\"Quel can you do well?\"', '\"How you could help me?\"', '\"What are your talents and ksills?\"', '\"What skills do you bring to the table?\"', '\"What do you exScel at?\"', '\"What are your competencies?\"', '\"Whereof are your strengths?\"', '\"What skills do you bring to the tabel?\"', '\"What can you do well?\"', '\"Quel can you bring to this project?\"', '\"Wht skills do you have?\"', '\"What do you excel at?\"', '\"What support is offered\"', '\"How you could hepl me?\"', '\"What skills do you bringing to the table?\"', '\"What can you do ell?\"', '\"What kind of tasks are you good at?\"', '\"What help you provide?\"', '\"What are your proficiencies?\"', '\"What you can do?\"', '\"What are your areas of competence?\"', '\"What are your areas of expertise?\"', '\"How you can be advantageous?\"', '\"Quoi help you provide?\"', '\"What can you bring to this project?\"', '\"What are your strong pohnts?\"', '\"Whereof do you excel at?\"', '\"What can you contribute?\"', '\"What are your technical skills?\"', '\"What are your areas of zxpertise?\"', '\"How you could pomoc me?\"', '\"What genre of tasks are you good at?\"', '\"What do you specialize in?\"', '\"What are your technical skilIls?\"', '\"WhaF you can do?\"', '\"Whereof can you contribute?\"', '\"Quel are your talents and skills?\"', '\"What are your abilities?\"', '\"What capabilities do you have?\"', '\"What can you britng to this project?\"', '\"What are your technological skills?\"', '\"What are your professinoal skills?\"', '\"What are your professional skills?\"', '\"What skills do you have?\"', '\"Quoi are you capable of?\"'], description=None, function_schemas=None, llm=None, score_threshold=None), Route(name='adverse_drug', utterances=['\"What are the riIks or drawbacks of this medication?\"', '\"What are the chances of experiencing side effects with this drug?\"', '\"Are there any common side consequences associated with this treatment?\"', '\"Could you outline the potential side effects I might encounter?\"', '\"Are there any known side effects I should be concerned about?\"', '\"What are the unintended implication I might face while taking this medicine?\"', '\"What should I expect in terms of side effects from this medication?\"', '\"What are the risks or loopholes of this medication?\"', '\"Are there any complications I should anticipate from using this medication?\"', '\"Are there any negative effects I should watch out for?\"', '\"Can you explain the possible adverse weactions of this medication?\"', '\"Which drugs dont have adverse reaction?\"', '\"Could you liLst the potential drawbacks or downsides of using this drug?\"', '\"Could you list the potential faults or downsides of using this drug?\"', '\"Could you outline the potential side effects I probability encounter?\"', '\"Are there any known side influencing I should be concerned about?\"', '\"Can you explain the doable adverse reactions of this medication?\"', '\"Are there any adverse ramifications I should be aware of?\"', '\"Give me a list of drugs causing adverse behavior\"', '\"Is there a chance of experiencing any unsolicited effects with this medication?\"', '\"What should I hopes in terms of side effects from this medication?\"', '\"Whoat kind of negative reactions should I be prepared for with this drug?\"', '\"What are the potential side effects of this medication?\"', '\"Is there a chance of experiencing any unwanted effects with this medication?\"', '\"What are the attainable adverse outcomes of this treatment?\"', '\"Are there any complicatioMs I should anticipate from using this medication?\"', '\"Open unfavorable drugs module\"', '\"Could you detail the side effects that users commonly report?\"', '\"What are the possible adverse outcomes of this treatment?\"', '\"Are there any adverse effects I should be aware of?\"', '\"What kind of responded might I experience from this medication?\"', '\"Can you tell me about the possible side effects of taking this drug?\"', '\"Give me a list of drugs causin adverse behavior\"', '\"Open adverse drugs modul\"', '\"IKs there a chance of experiencing any unwanted effects with this medication?\"', '\"Can you tell me about the possible side effects of tNaking this drug?\"', '\"Give me a list of narcotic causing adverse behavior\"', '\"Can you describe any unpopular effects that could occur?\"', '\"Could you outline the potential side effehts I might encounter?\"', '\"What kind of negative reactions should I be prepared for with this drug?\"', '\"Are there any common side effects associated with this treatment?\"', '\"Could you detail the side effects that customers commonly report?\"', '\"Are there any known side effects I should be coWncerned about?\"', '\"List all Drugs suitable for patient with adverse reaction\"', '\"Are there any complications I should anticipate from utilized this medication?\"', '\"hat are the unintended consequences I might face while taking this medicine?\"', '\"Can you explain the possible adverse reactions of this medication?\"', '\"Are there any negative influencing I should watch out for?\"', '\"What should I expect in terms of sie effects from this medication?\"', '\"What are the unintended consequences I might face while taking this medicine?\"', '\"List all drugs suitable for patient with detrimental reaction\"', '\"What kind of reactions might I experience from this medication?\"', '\"What are the cxhances of experiencing side effects with this drug?\"', '\"What are the potential side effecst of this medication?\"', '\"hWat are the possible adverse outcomes of this treatment?\"', '\"Are there any common side effects associated with this treltment?\"', '\"Can you delcribe any undesirable effects that could occur?\"', '\"What are the potential side effects of this medicines?\"', '\"Could you detail the side effetcs that users commonly report?\"', '\"Which drugs dont have adverse reactino?\"', '\"Open adverse drugs module\"', '\"What are the probabilities of experiencing side effects with this drug?\"', '\"What are the risks or drawbacks of this medication?\"', '\"Hwo to check Adverse drug reaction?\"', '\"How to check Adverse drug reaction?\"'], description=None, function_schemas=None, llm=None, score_threshold=None), Route(name='thanks', utterances=['\"Thaxnk you\"', '\"I\\'m appreciate.\"', '\"I really Yappreciate it.\"', '\"Thanks a batch!\"', '\"Thanking you!\"', '\"Much oblige!\"', '\"Thanks a bunch!\"', '\"Ylu\\'re a lifesaver!\"', '\"I can\\'t tank you enough.\"', '\"That mode a lot to me.\"', '\"I appreciatoe your help.\"', '\"ThaPnks a million!\"', '\"You\\'ve been so kind.\"', '\"Many thanks!\"', '\"Thank you so much!\"', '\"Thank you\"', '\"I\\'m so thankful for [specific gesture or helping].\"', '\"I owe you one.\"', '\"I appreciate your helped.\"', '\"I\\'m grateful.\"', '\"Thank you so very!\"', '\"That\\'s worthwhile\"', '\"Delightful, thanks\"', '\"You have my gratitude.\"', '\"That\\'s heplful\"', '\"I\\'m profoundly thankful.\"', '\"Many thnks!\"', '\"That\\'s helpful\"', '\"I\\'m thankful for your supports.\"', '\"\\'m thankful for your support.\"', '\"Much obliged!\"', '\"Thanks for hPelping me\"', '\"I\\'m so thankful for [specific gesture or help].\"', '\"Thanks a billion!\"', '\"Youve been so kind.\"', '\"\\'Im deeply thankful.\"', '\"VI\\'m very grateful for your assistance.\"', '\"ThankK a bunch!\"', '\"Thanks for aided me\"', '\"That means a lto to me.\"', '\"TCank you!\"', '\"Thank you so mpch!\"', '\"Thank you!\"', '\"I appreciate your help.\"', '\"I owe you Pone.\"', '\"You\\'re a rescuer!\"', '\"I\\'m very grateful for your assistance.\"', '\"You have my Qratitude.\"', '\"Tanks a lot!\"', '\"I gotta you one.\"', '\"Thanks for helping me\"', '\"I truly appreciate it.\"', '\"I\\'m very grateful for your helping.\"', '\"Multiple thanks!\"', '\"hTanks\"', '\"I can\\'t thank you enough.\"', '\"Awesome, thanks\"', '\"I can\\'t appreciation you enough.\"', '\"Thank a bunch!\"', '\"You\\'ve been so sorting.\"', '\"Thanks a million!\"', '\"AwesoNme, thanks\"', '\"I really appreciate it.\"', '\"That means a lot to me.\"'], description=None, function_schemas=None, llm=None, score_threshold=None), Route(name='blood_pressure', utterances=['\"What are my blood pressure levels?\"', '\"How is my blood pressure looking yesterday?\"', '\"Could you let me know my current BP numbers?\"', '\"Chrissake pressure data entry\"', '\"What should I know about my blood pressure levels right now?\"', '\"I want to log blood pressure results\"', '\"Task related to blood pressurj\"', '\"What\\'s my stroke/diastolic pressure right now?\"', '\"What\\'s the status of my chrissakes pressure today?\"', '\"How is my blood pressure doing totals?\"', '\"What is my current blood pressure reading?\"', '\"What is my current chrissake pressure reading?\"', '\"Could you let me know my current bBP numbers?\"', '\"Open blood pressurized module\"', '\"Could you inform me of my blood prXssure results?\"', '\"Are there any concerns with my blood pressure readings?\"', '\"Oen blood pressure module\"', '\"CaQn you tell me what my blood pressure numbers are?\"', '\"Can you give me an modernization on my blood pressure?\"', '\"Would you let me know my current BP numbers?\"', '\"How is my blood pressure doing ovearll?\"', '\"Can you give me an upUdate on my blood pressure?\"', '\"Can you tell me what my blood pressure digits are?\"', '\"How does my blood pressure compare to normal tier?\"', '\"What\\'s the status of my blood pressure today?\"', '\"Is my blood pressure Itable?\"', '\"Do you have the newest reading of my blood pressure?\"', '\"I wanted to log blood pressure results\"', '\"Could you check my blood pressure, please?\"', '\"Is my blood pressure within a wholesome range?\"', '\"hat is my current blood pressure reading?\"', '\"Open blood pressure module\"', '\"Could you inform me of my blood pressure results?\"', '\"What\\'s my systolic/diastolic prejsure right now?\"', '\"Can you provide me with my blood pressure measure?\"', '\"Do you have the latest reading of my blood pressure?\"', '\"Could you check my blod pressure, please?\"', '\"Task related to blood pressure\"', '\"Can you provide me with my blood pressure measurements?\"', '\"Is my blood pressure within a healthy range?\"', '\"Can you give me an update on my blood pressure?\"', '\"What\\'s my systolic/diastolic pressure right now?\"', '\"Do you have the latest reading of my blood pressYure?\"', '\"How is my blood pressure looking today?\"', '\"Can you tell me what my blood pressure numbers are?\"', '\"Have you hecked my blood pressure recently?\"', '\"What\\'s the verdict on my blood pressure today?\"', '\"Blood pressure data manaegment\"', '\"Is my blooA pressure within a healthy range?\"', '\"Whereof should I know about my blood pressure levels right now?\"', '\"What\\'s the verdict on my blood pressure nowadays?\"', '\"oHw does my blood pressure compare to normal levels?\"', '\"Blood pressure data entry\"', '\"Blood pressYure data entry\"', '\"Is my blood pressure stable?\"', '\"How is my blood pressure doing overall?\"', '\"Have you audit my blood pressure recently?\"', '\"Be there any concerns with my blood pressure readings?\"', '\"What should I know about my lood pressure levels right now?\"', '\"Are there any concerns with my blocod pressure readings?\"', '\"Can you provide me with my brood pressure measurements?\"', '\"Have you checked my blood pressure recently?\"'], description=None, function_schemas=None, llm=None, score_threshold=None), Route(name='medication', utterances=['\"Could you get my prescription ready for me?\"', '\"Is it possible to get a prescription filled today?\"', '\"lPease prepare my medication for me.\"', '\"I need to replenish my supply of medication.\"', '\"Could you dispense my medication?\"', '\"Is it might to get a prescription filled today?\"', '\"Can I get a prescription filld, please?\"', '\"Can I pick up my medication order?\"', '\"May I wondering a refill of my prescription, please?\"', '\"Can I get a prescription fills, please?\"', '\"Could I get a reftill on my prescription?\"', '\"Please prepare my medicines for me.\"', '\"Is my drugs available for pickup?\"', '\"Could you gt my prescription ready for me?\"', '\"I need to replenish my supply of emdication.\"', '\"I\\'d like to request a prescription refill.\"', '\"May I reorder my pArescription?\"', '\"May I reorder my prescribing?\"', '\"I need to pick up my medical.\"', '\"Can you braced my prescription?\"', '\"Ca you fill my prescription for me?\"', '\"Can you prepare my prescription?\"', '\"I\\'m here to collect my Bprescription.\"', '\"Can I elects up my medication order?\"', '\"I nee to pick up my medication.\"', '\"Is it possible to get a prescription filled toay?\"', '\"May I reorder my prescription?\"', '\"I\\'m here to collects my prescription.\"', '\"Could you dispense my mehication?\"', '\"Is my medication available for pickup?\"', '\"Can you prepazre my prescription?\"', '\"Is my prescriptiMn ready for pickup?\"', '\"Can you filling my prescription for me?\"', '\"I need to pick up my medication.\"', '\"Could I got a refill on my prescription?\"', '\"Could you refill my prescription for me?\"', '\"Could you dispense my pharmaceutical?\"', '\"I\\'d loves to request a prescription refill.\"', '\"Can I get a prescription filled, please?\"', '\"I need to refill my medication supplying.\"', '\"I ened to refill my medication supply.\"', '\"Could I get a refill on my prescription?\"', '\"May I requset a refill of my prescription, please?\"', '\"Could you refill my prescribing for me?\"', '\"Is my prescribing ready for pickup?\"', '\"I\\'m here to collect my prescription.\"', '\"oCuld you refill my prescription for me?\"'], description=None, function_schemas=None, llm=None, score_threshold=None), Route(name='greeting', utterances=['\"Yo!\"', '\"HowJ\\'s it going?\"', '\"Hi, how have you been?\"', '\"GooRd evening!\"', '\"oY!\"', '\"Hiya!\"', '\"Hey, good to behold you!\"', '\"What\\'s up?\"', '\"Saltations!\"', '\"Hiya!\"', '\"Howdy!\"', '\"Nice to see you!\"', '\"Greetins!\"', '\"Greeting!\"', '\"Hello\"', '\"oGod afternoon!\"', '\"Salut there!\"', '\"Howdy\"', '\"Salutations!\"', '\"Hi there\"', '\"Hbi there!\"', '\"Gotd day\"', '\"Hw are you\"', '\"Delightful to see you!\"', '\"Welcoe!\"', '\"Hi there!\"', '\"Hey, how are you?\"', '\"Hye, how are you?\"', '\"Good evening!\"', '\"Uey, good to see you!\"', '\"Greetings, how have you been?\"', '\"Hia!\"', '\"eHllo\"', '\"Hey!\"', '\"Salutations!\"', '\"eHy!\"', '\"Well complied!\"', '\"Hello!\"', '\"Good morning!\"', '\"Buena afternoon!\"', '\"What\\'s up?\"', '\"Howdy, how are you?\"', '\"Howdy!\"', '\"Howdy!\"', '\"How\\'s it go?\"', '\"Mode are you\"', '\"Good mornig!\"', '\"Good day\"', '\"Hey!\"', '\"Howedy!\"', '\"Welcome!\"', '\"How are you doing today?\"', '\"Greetings!\"', '\"Hey!\"', '\"Is person there?\"', '\"How are you\"', '\"Alright day\"', '\"Well met!\"', '\"How are you doing hoy?\"', '\"Hlelo!\"', '\"Nice to ee you!\"', '\"I anyone there?\"'], description=None, function_schemas=None, llm=None, score_threshold=None), Route(name='pharmacy_search', utterances=['\"Find a 24-hour pharmacy nearby me.\"', '\"Where can I finds a pharmacy?\"', '\"Locate a pharmacy that endorse my insurance.\"', '\"Search phramacy\"', '\"Find pharmacies with COVID-19 vaccines.\"', '\"Find pharmacies near me.\"', '\"Pharmacies close to my location.\"', '\"oLcate pharmacy\"', '\"Search for pharmacies that deliver.\"', '\"Look for a pharmacy that\\'s open laet.\"', '\"Look for a pharmacy that\\'s open late.\"', '\"Where can I purchase over-the-counter medications?\"', '\"Where is the nearest pharmacy?\"', '\"Search for drugstore with flu shots.\"', '\"Search for pharmacies with flu shots.\"', '\"Find pharmacies with drive-thru services.\"', '\"Finds pharmacies with COVID-19 vaccines.\"', '\"Where can I buy over-the-counter medications?\"', '\"Locate pharmacies with a pharmayc technician.\"', '\"Find me a pharmacists\"', '\"Browsing pharmacy\"', '\"Where can I Ifind a pharmacy?\"', '\"Find a pharmacists in [city/town].\"', '\"Pharmacies ajound here.\"', '\"Locate pharmacist\"', '\"Locate a pharmacy that accepts my insurance.\"', '\"Locate drugstores in [neighborhood].\"', '\"Search for drugstores neighbors.\"', '\"Pharmacies around here.\"', '\"Locate pharmacy\"', '\"Find a 24-hour pharmacy near me.\"', '\"Find chemists with drive-thru services.\"', '\"Where can I find a pharmacy?\"', '\"Search for drgustores nearby.\"', '\"Where can I fill a prescription nearby?\"', '\"List of pharmacies neighbor\"', '\"Loctae a pharmacy nearby.\"', '\"Surrounding pharmacies open now.\"', '\"Find a pharmacy in [city/town].\"', '\"List of pharmacies nearby\"', '\"Where is the neareIst pharmacy?\"', '\"Find pharmacies with drive-thru servicei.\"', '\"Bhere can I fill a prescription nearby?\"', '\"Find pharmacy\"', '\"Nearby pharwacies open now.\"', '\"Find pharmacies vicinity me.\"', '\"Find pharmacies neSr me.\"', '\"Locate drugstores in [vicinity].\"', '\"Locate pharmacies with a pharmacy technician.\"', '\"Locate pharmacies with a pharmaceutical technician.\"', '\"Find pharmacie with COVID-19 vaccines.\"', '\"Wherein can I fill a prescription nearby?\"', '\"Look for a pharmacist that\\'s open late.\"', '\"Search for drugstore that deliver.\"', '\"Finds pharmacy\"', '\"Find me a pharmacy\"', '\"Search for drugstores nearby.\"', '\"Search for phamacies with flu shots.\"', '\"PhBrmacy close to my location.\"', '\"Locate drugstroes in [neighborhood].\"', '\"Locate a pharmacy nearby.\"', '\"Locate a pharmacy that acecpts my insurance.\"'], description=None, function_schemas=None, llm=None, score_threshold=None), Route(name='doctor', utterances=['\"Could you pomoc me book an appointment with a doctor?\"', '\"Can you diect me to a doctor?\"', '\"I ned to consult with a medical doctor.\"', '\"I\\'m looking to see a healthcare professional.\"', '\"I requier the attention of a doctor.\"', '\"Can I speak to a healthcare provider?\"', '\"I\\'m looking to see a hhealthcare professional.\"', '\"I need to speak with a doctor.\"', '\"I would like to reques a doctor\\'s appointment.\"', '\"I need to speak with a medic.\"', '\"Could you organised for me to see a doctor?\"', '\"AMay I have a doctor\\'s consultation, please?\"', '\"May I schedules a consultation with a doctor?\"', '\"Is there a dotcor available?\"', '\"Is there a doctor on duEy right now?\"', '\"Is a physician available to see me?\"', '\"Could you arrnage for me to see a doctor?\"', '\"May I have a doctor\\'s consultation, please?\"', '\"Could you help me book an appointment with a doctor?\"', '\"Can I make an appointment to see a doctor?\"', '\"I need medical assistance from a docRor.\"', '\"Can I make an nomination to see a doctor?\"', '\"Can I speak to a healthcare prvoider?\"', '\"Is a physcian available to see me?\"', '\"I need to speka with a doctor.\"', '\"Could I see a doctor, please?\"', '\"May I schedule a consultation with a doctor?\"', '\"Is there a doctor available?\"', '\"Is it possible to meeo with a physician?\"', '\"sI there a physician I can speak with?\"', '\"May I have a doctor\\'s query, please?\"', '\"Can I make an appointment to ese a doctor?\"', '\"Pay I schedule a consultation with a doctor?\"', '\"I would like to request a doctor\\'s nominations.\"', '\"Could you arrange for me to see a doctor?\"', '\"Is there a doctor on duty right now?\"', '\"Are there any doctors in the clinic/hospcital?\"', '\"I need medical assistance from a medical.\"', '\"Is there a doctors available?\"', '\"I require the attention of a doctor.\"', '\"Can you direct me to a doctor?\"', '\"Is it possible to meet with a physician?\"', '\"Could you help me booy an appointment with a doctor?\"', '\"Is there a physician I can speak with?\"', '\"I need to consult with a medical doctor.\"', '\"Is there a physician I can speaks with?\"'], description=None, function_schemas=None, llm=None, score_threshold=None), Route(name='hospital_search', utterances=['\"Find hospitals with sepcific specialties (e.g., cardiology, pediatrics).\"', '\"Where is the earest hospital?\"', '\"Look for a hospital that\\'s open 24/7.\"', '\"Look for a hospital that\\'s opeun 24/7.\"', '\"Looking up hospital details\"', '\"Neighborhood hospitals open now.\"', '\"Where can I find a hospital?\"', '\"Searching for hospital to transfer patient\"', '\"Locating a hospital nearby.\"', '\"Search for hospitals that furnishes telemedicine services.\"', '\"Nearby hospitals dopen now.\"', '\"Hospital lookup for patient\"', '\"I want to search hospital data\"', '\"Lookup for hospitals\"', '\"Where can I tfind a hospital emergency room?\"', '\"Locate hospitals with intensive care units (ICU).\"', '\"Quest for medical centers nearby.\"', '\"Hospital close to my location.\"', '\"Find an contingencies hospital near me.\"', '\"Find an emergency hospital near me.\"', '\"Find hospitals with COVID-19 therapy facilities.\"', '\"Hopsital lookup for patient\"', '\"Find hospitals near me.\"', '\"Locate hospitals in [barrio].\"', '\"Locate hospitals with intensive caring units (ICU).\"', '\"Search for medical centers nearby.\"', '\"Where can I find a hospital emergencies room?\"', '\"Hospitals throughout here.\"', '\"Locate hosYitals in [neighborhood].\"', '\"Searching for hospital to ransfer patient\"', '\"Nearby hospitals open now.\"', '\"Lcoate a hospital that accepts my insurance.\"', '\"Hence is the nearest hospital?\"', '\"Locate hospiatls with intensive care units (ICU).\"', '\"Hospitals aound here.\"', '\"Looking up hospita details\"', '\"Locate a hospital nearby.\"', '\"Find hospitals with specific specialties (e.g., cardiology, pediatrics).\"', '\"Search for hospitals that offer telemedicine services.\"', '\"I want to search hospital dtaa\"', '\"Find an emgrgency hospital near me.\"', '\"Hospital lookup for ailing\"', '\"Browse for hospital to transfer patient\"', '\"Where can I find a hopital?\"', '\"Where can I unearth hospitals with surgery facilities?\"', '\"Hospital close to my locatiMn.\"', '\"Where can I find a hospital emergency room?\"', '\"Where can I find hospitals with sugrery facilities?\"', '\"Unearth a hospital in [city/town].\"', '\"Lookup for hospital\"', '\"Where is the nearest hospital?\"', '\"Find hospitals with COVID-19 treatment facilities.\"', '\"Seaarch for medical centers nearby.\"', '\"Hospitals around here.\"', '\"Find a hospital in [city/town].\"', '\"Search for hospitals with urgent caring services.\"', '\"Locate a hospital that accepts my seguro.\"'], description=None, function_schemas=None, llm=None, score_threshold=None), Route(name='blood_pressure_search', utterances=['\"Load patient blood pressurized result\"', '\"Show blood pressure reults for patient\"', '\"Show blood pressurized results for patient\"', '\"Load patient blood preqsure result\"', '\"Find lood pressure results by ID\"', '\"Find blood pressure results by IDS\"', '\"Load patient blood pressure result\"', '\"I want to browsing for blood pressure result history\"', '\"Find blood pressure results by ID\"', '\"I want to search for blood pressrue result history\"'], description=None, function_schemas=None, llm=None, score_threshold=None)]\n"
     ]
    }
   ],
   "source": [
    "#adverse_drug_route = Route(\n",
    "#    name= \"adverse_drug\",\n",
    "#    utterances= [\"How to check Adverse drug reaction?\", \"Open adverse drugs module\", \"Give me a list of drugs causing adverse behavior\", \"List all drugs suitable for patient with adverse reaction\", \"Which drugs dont have adverse reaction?\" ],\n",
    "#    responses= [\"Navigating to Adverse drug reaction module\"],\n",
    "#)\n",
    "#blood_pressure_route = Route(\n",
    "#    name= \"blood_pressure\",\n",
    "#    utterances= [\"Open blood pressure module\", \"Task related to blood pressure\", \"Blood pressure data entry\", \"I want to log blood pressure results\", \"Blood pressure data management\" ],\n",
    "#    responses= [\"Navigating to Blood Pressure module\"],\n",
    "#)\n",
    "\n",
    "routes=[]\n",
    "intents = train_df['intent'].unique()\n",
    "\n",
    "for intent in intents:\n",
    "    temp_df = train_df.loc[train_df['intent'] == intent]\n",
    "    temp_utterances = temp_df['utterance'].tolist()\n",
    "    intent_name = str(intent)\n",
    "    intent_name = Route(\n",
    "        name=intent,\n",
    "        utterances=temp_utterances,\n",
    "        responses=['N/A']\n",
    "    )\n",
    "    routes.append(intent_name)\n",
    "\n",
    "print(routes)\n",
    "\n",
    "#response_dict = {'blood_pressure': {'name': 'blood_pressure', 'responses': [\"Navigating to Blood Pressure module\"]}}\n",
    "\n",
    "#routes=[adverse_drug_route,blood_pressure_route]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7790c411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce1214e12d8c4ac589d608692883e32f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e490454977324adbadaa296e80fe7255",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "240a0cb2f38b41348d840597ceff92bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1edca299223b4312b75ea30bb7293a06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25e8ac3376c241679531f9d0d907cdb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43996ed3d3ee4acebc7f095ec19979ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoder = HuggingFaceEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9df52f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rl = RouteLayer(encoder=encoder, routes=routes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e9309a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RouteChoice(name='adverse_drug', function_call=None, similarity_score=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rl(\"Open adverse drugs module\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "74a97eca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'blood_pressure_search'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rl(\"can you search for my blood pressure please\").name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "890bb6aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-07-14 17:44:42 INFO semantic_router.utils.logger Saving route config to rag_model.json\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "rl.to_json(\"rag_model.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f6cc3f-d255-4c78-8038-8fbc674160e9",
   "metadata": {},
   "source": [
    "# NN Intent Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebf33074-4783-4080-8544-078b7cea19fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in ./anaconda3/lib/python3.11/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in ./anaconda3/lib/python3.11/site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in ./anaconda3/lib/python3.11/site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./anaconda3/lib/python3.11/site-packages (from nltk) (2024.5.15)\n",
      "Requirement already satisfied: tqdm in ./anaconda3/lib/python3.11/site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: flask in ./anaconda3/lib/python3.11/site-packages (2.2.2)\n",
      "Collecting flask\n",
      "  Obtaining dependency information for flask from https://files.pythonhosted.org/packages/61/80/ffe1da13ad9300f87c93af113edd0638c75138c42a0994becfacac078c06/flask-3.0.3-py3-none-any.whl.metadata\n",
      "  Downloading flask-3.0.3-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting Werkzeug>=3.0.0 (from flask)\n",
      "  Obtaining dependency information for Werkzeug>=3.0.0 from https://files.pythonhosted.org/packages/9d/6e/e792999e816d19d7fcbfa94c730936750036d65656a76a5a688b57a656c4/werkzeug-3.0.3-py3-none-any.whl.metadata\n",
      "  Downloading werkzeug-3.0.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in ./anaconda3/lib/python3.11/site-packages (from flask) (3.1.4)\n",
      "Collecting itsdangerous>=2.1.2 (from flask)\n",
      "  Obtaining dependency information for itsdangerous>=2.1.2 from https://files.pythonhosted.org/packages/04/96/92447566d16df59b2a776c0fb82dbc4d9e07cd95062562af01e408583fc4/itsdangerous-2.2.0-py3-none-any.whl.metadata\n",
      "  Downloading itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting click>=8.1.3 (from flask)\n",
      "  Obtaining dependency information for click>=8.1.3 from https://files.pythonhosted.org/packages/00/2e/d53fa4befbf2cfa713304affc7ca780ce4fc1fd8710527771b58311a3229/click-8.1.7-py3-none-any.whl.metadata\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting blinker>=1.6.2 (from flask)\n",
      "  Obtaining dependency information for blinker>=1.6.2 from https://files.pythonhosted.org/packages/bb/2a/10164ed1f31196a2f7f3799368a821765c62851ead0e630ab52b8e14b4d0/blinker-1.8.2-py3-none-any.whl.metadata\n",
      "  Downloading blinker-1.8.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./anaconda3/lib/python3.11/site-packages (from Jinja2>=3.1.2->flask) (2.1.5)\n",
      "Downloading flask-3.0.3-py3-none-any.whl (101 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading blinker-1.8.2-py3-none-any.whl (9.5 kB)\n",
      "Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "Downloading werkzeug-3.0.3-py3-none-any.whl (227 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.3/227.3 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: Werkzeug, itsdangerous, click, blinker, flask\n",
      "  Attempting uninstall: Werkzeug\n",
      "    Found existing installation: Werkzeug 2.2.3\n",
      "    Uninstalling Werkzeug-2.2.3:\n",
      "      Successfully uninstalled Werkzeug-2.2.3\n",
      "  Attempting uninstall: itsdangerous\n",
      "    Found existing installation: itsdangerous 2.0.1\n",
      "    Uninstalling itsdangerous-2.0.1:\n",
      "      Successfully uninstalled itsdangerous-2.0.1\n",
      "  Attempting uninstall: click\n",
      "    Found existing installation: click 8.0.4\n",
      "    Uninstalling click-8.0.4:\n",
      "      Successfully uninstalled click-8.0.4\n",
      "  Attempting uninstall: flask\n",
      "    Found existing installation: Flask 2.2.2\n",
      "    Uninstalling Flask-2.2.2:\n",
      "      Successfully uninstalled Flask-2.2.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "python-lsp-black 1.2.1 requires black>=22.3.0, but you have black 0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Werkzeug-3.0.3 blinker-1.8.2 click-8.1.7 flask-3.0.3 itsdangerous-2.2.0\n",
      "Requirement already satisfied: flask_cors in ./anaconda3/lib/python3.11/site-packages (4.0.1)\n",
      "Requirement already satisfied: Flask>=0.9 in ./anaconda3/lib/python3.11/site-packages (from flask_cors) (3.0.3)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in ./anaconda3/lib/python3.11/site-packages (from Flask>=0.9->flask_cors) (3.0.3)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in ./anaconda3/lib/python3.11/site-packages (from Flask>=0.9->flask_cors) (3.1.4)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in ./anaconda3/lib/python3.11/site-packages (from Flask>=0.9->flask_cors) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in ./anaconda3/lib/python3.11/site-packages (from Flask>=0.9->flask_cors) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in ./anaconda3/lib/python3.11/site-packages (from Flask>=0.9->flask_cors) (1.8.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./anaconda3/lib/python3.11/site-packages (from Jinja2>=3.1.2->Flask>=0.9->flask_cors) (2.1.5)\n",
      "Requirement already satisfied: keras in ./anaconda3/lib/python3.11/site-packages (3.3.3)\n",
      "Requirement already satisfied: absl-py in ./anaconda3/lib/python3.11/site-packages (from keras) (2.1.0)\n",
      "Requirement already satisfied: numpy in ./anaconda3/lib/python3.11/site-packages (from keras) (1.26.4)\n",
      "Requirement already satisfied: rich in ./anaconda3/lib/python3.11/site-packages (from keras) (13.7.1)\n",
      "Requirement already satisfied: namex in ./anaconda3/lib/python3.11/site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: h5py in ./anaconda3/lib/python3.11/site-packages (from keras) (3.11.0)\n",
      "Requirement already satisfied: optree in ./anaconda3/lib/python3.11/site-packages (from keras) (0.11.0)\n",
      "Requirement already satisfied: ml-dtypes in ./anaconda3/lib/python3.11/site-packages (from keras) (0.3.2)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in ./anaconda3/lib/python3.11/site-packages (from optree->keras) (4.12.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./anaconda3/lib/python3.11/site-packages (from rich->keras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./anaconda3/lib/python3.11/site-packages (from rich->keras) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./anaconda3/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.0)\n",
      "Requirement already satisfied: tensorflow in ./anaconda3/lib/python3.11/site-packages (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in ./anaconda3/lib/python3.11/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./anaconda3/lib/python3.11/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in ./anaconda3/lib/python3.11/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./anaconda3/lib/python3.11/site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in ./anaconda3/lib/python3.11/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in ./anaconda3/lib/python3.11/site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./anaconda3/lib/python3.11/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in ./anaconda3/lib/python3.11/site-packages (from tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./anaconda3/lib/python3.11/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in ./anaconda3/lib/python3.11/site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in ./anaconda3/lib/python3.11/site-packages (from tensorflow) (4.21.12)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./anaconda3/lib/python3.11/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in ./anaconda3/lib/python3.11/site-packages (from tensorflow) (70.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in ./anaconda3/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./anaconda3/lib/python3.11/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in ./anaconda3/lib/python3.11/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in ./anaconda3/lib/python3.11/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./anaconda3/lib/python3.11/site-packages (from tensorflow) (1.64.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in ./anaconda3/lib/python3.11/site-packages (from tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in ./anaconda3/lib/python3.11/site-packages (from tensorflow) (3.3.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in ./anaconda3/lib/python3.11/site-packages (from tensorflow) (0.37.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in ./anaconda3/lib/python3.11/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./anaconda3/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: rich in ./anaconda3/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in ./anaconda3/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in ./anaconda3/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.6.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./anaconda3/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./anaconda3/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./anaconda3/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./anaconda3/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./anaconda3/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./anaconda3/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./anaconda3/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U nltk\n",
    "!pip install -U flask\n",
    "!pip install -U flask_cors\n",
    "!pip install -U keras\n",
    "!pip install -U tensorflow\n",
    "# Note that, currently, this is stolen wholesale from https://github.com/katanaml/katana-assistant/blob/master/mlmodels/katana-assistant-model.ipynb\n",
    "# It will be modified later to suit our purposes, I just want to see if I can get what they have to work!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "899dd2fd-d64f-469f-a4c3-d20d57345c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-14 14:25:43.788191: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-14 14:25:43.811799: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-14 14:25:44.254160: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Note that, currently, this is stolen wholesale from https://github.com/katanaml/katana-assistant/blob/master/mlmodels/katana-assistant-model.ipynb\n",
    "# It will be modified later to suit our purposes, I just want to see if I can get what they have to work\n",
    "\n",
    "import nltk\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "stemmer = LancasterStemmer()\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.optimizers import SGD # NOTE: this was originally written with an older version of SGD, so I'm using the legacy version just to implement what they had as they had it\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "from flask import Flask, jsonify, request\n",
    "from flask_cors import CORS, cross_origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d9ab86d-70b5-42c1-8538-e6b648f99ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/mist861/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d11fd030-1247-4284-92ef-93b6f12ad477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636 documents\n",
      "12 classes ['adverse_drug', 'blood_pressure', 'blood_pressure_search', 'doctor', 'goodbye', 'greeting', 'hospital_search', 'medication', 'options', 'pharmacy_search', 'symptoms', 'thanks']\n",
      "659 unique stemmed words ['!', \"''\", \"'d\", \"'im\", \"'m\", \"'re\", \"'s\", \"'ve\", '(', ')', ',', '.', '24-hour', '24/7', '[', ']', '``', 'a', 'abdomin', 'abils', 'abl', 'about', 'acceiv', 'acecpt', 'ach', 'adieu', 'adv', 'advers', 'afternoon', 'afterward', 'ahc', 'aid', 'ail', 'ajound', 'al', 'almost', 'alright', 'amay', 'an', 'and', 'anticip', 'any', 'anyon', 'aound', 'appoint', 'appreciato', 'apprecy', 'ar', 'area', 'around', 'arrang', 'arrn', 'as', 'assist', 'assocy', 'at', 'attain', 'audit', 'avail', 'aw', 'awesom', 'awesonm', 'barrio', 'batch', 'bbp', 'be', 'been', 'behavy', 'behold', 'bher', 'bil', 'blo', 'bloatx', 'blocod', 'blod', 'bloo', 'blood', 'book', 'booy', 'bp', 'bprescription', 'brac', 'brea', 'bring', 'britng', 'brood', 'brows', 'buen', 'bunch', 'buy', 'by', 'bye', 'bye-by', 'bye-uy', 'byo', 'ca', 'can', 'canr', 'cap', 'capaobl', 'caqn', 'car', 'cardiolog', 'catch', 'caus', 'causin', 'cent', 'chant', 'chat', 'check', 'chem', 'chest', 'chil', 'chrissake', 'chrissakes', 'city/town', 'clear', 'clinic/hospcital', 'clos', 'cold', 'collect', 'common', 'comp', 'compet', 'complicatiom', 'comply', 'concern', 'congest', 'consequ', 'constip', 'consult', 'cont', 'contribut', 'cough', 'could', 'covid-19', 'cowncern', 'cramp', 'cur', 'custom', 'cxhances', 'dat', 'day', 'deeply', 'del', 'delcrib', 'delight', 'describ', 'detail', 'detry', 'dgy', 'diarrhe', 'diarrhoe', 'diect', 'digest', 'digit', 'direct', 'discomfort', 'dispens', 'dizzy', 'do', 'doabl', 'docr', 'doct', 'doe', 'doing', 'dont', 'dop', 'dotc', 'downsid', 'drawback', 'drgustores', 'drive-thru', 'drug', 'drugst', 'drugstro', 'dta', 'duey', 'duty', 'e.g.', 'earest', 'easy', 'ee', 'effecst', 'effect', 'effeht', 'effetc', 'effortless', 'ehllo', 'ehy', 'el', 'elect', 'emd', 'emerg', 'emgrg', 'en', 'encount', 'endors', 'enjoy', 'enough', 'entry', 'es', 'ev', 'evil', 'excel', 'expect', 'expert', 'expery', 'explain', 'exscel', 'extraordin', 'extrem', 'fac', 'facil', 'farewel', 'fatgiu', 'fatigu', 'fault', 'feel', 'feelinu', 'fev', 'fil', 'filld', 'find', 'flu', 'for', 'from', 'furn', 'fut', 'genr', 'gest', 'get', 'giv', 'gntil', 'go', 'going', 'good', 'goodbey', 'goodby', 'goodnight', 'goord', 'goosebump', 'got', 'gotd', 'grat', 'gratitud', 'gre', 'greet', 'greetin', 'gt', 'ha', 'haedach', 'hat', 'hav', 'hbi', 'headach', 'healthc', 'healthy', 'heartbreak', 'heck', 'hello', 'help', 'hent', 'hepl', 'her', 'hey', 'hhealthc', 'hi', 'hia', 'hist', 'hiy', 'hlelo', 'hop', 'hopit', 'hopsit', 'hospiatl', 'hospit', 'hosyit', 'hot', 'how', 'howdy', 'howedy', 'hows', 'hoy', 'hpelp', 'htank', 'hw', 'hwat', 'hwo', 'hye', 'i', 'icu', 'id', 'ifind', 'ik', 'imply', 'impuls', 'in', 'indigest', 'influ', 'inform', 'ins', 'intend', 'irrit', 'is', 'issu', 'it', 'itm', 'jad', 'joint', 'kind', 'know', 'known', 'ksil', 'laet', 'lang', 'larynx', 'lat', 'latest', 'lco', 'leharg', 'let', 'letharg', 'level', 'lifesav', 'light/nboise', 'light/noise', 'light/sonora', 'lighthead', 'lihthead', 'lik', 'lilst', 'list', 'load', 'loc', 'locatimn', 'locta', 'log', 'long', 'lood', 'look', 'lookup', 'loophol', 'lot', 'lov', 'lpeas', 'lto', 'mak', 'manaeg', 'many', 'may', 'me', 'mean', 'meas', 'med', 'medicin', 'meeo', 'meet', 'meh', 'met', 'might', 'mil', 'mod', 'modern', 'morn', 'mornig', 'mpch', 'much', 'multipl', 'musc', 'must', 'my', \"n't\", 'narcot', 'naue', 'nause', 'near', 'nearby', 'nearest', 'ned', 'nee', 'neg', 'neighb', 'nesr', 'newest', 'next', 'nic', 'nomin', 'noq', 'norm', 'nos', 'now', 'nowaday', 'numb', 'oblig', 'occ', 'oculd', 'oen', 'of', 'off', 'ogod', 'ohw', 'olc', 'on', 'ood', 'oodnight', 'op', 'opeun', 'or', 'ord', 'org', 'out', 'outcom', 'outlin', 'ovearl', 'over-the-count', 'overal', 'overpop', 'ow', 'oy', 'pain', 'pan', 'parescrib', 'paty', 'pay', 'peaec', 'pedy', 'persist', 'person', 'pham', 'pharm', 'pharmac', 'pharmaceut', 'pharmayc', 'pharw', 'phbrmacy', 'phramacy', 'phys', 'physc', 'pick', 'pickup', 'placid', 'pleas', 'pohnt', 'pomoc', 'pon', 'poss', 'pot', 'prejs', 'prep', 'prepazr', 'preqs', 'prescrib', 'prescriptimn', 'press', 'pressru', 'pressurs', 'pressy', 'prob', 'profess', 'professino', 'proficy', 'profound', 'project', 'provid', 'prvoider', 'prxssure', 'purchas', 'qratitud', 'quel', 'query', 'quest', 'quo', 'ram', 'rang', 'ransf', 'rash', 'rcash', 'react', 'reactino', 'read', 'ready', 'real', 'rec', 'refil', 'reftil', 'rel', 'reord', 'repl', 'report', 'requ', 'request', 'requir', 'requset', 'requy', 'rescu', 'respond', 'result', 'reult', 'rhat', 'right', 'riik', 'risk', 'room', 'runny', 'salt', 'salut', 'schedule', 'schedules', 'scratchy', 'scrnatchy', 'seaarch', 'search', 'sec', 'see', 'seguro', 'sensit', 'sepc', 'serv', 'service', 'short', 'shot', 'should', 'show', 'si', 'sid', 'sie', 'skil', 'skilil', 'skin', 'so', 'soon', 'sor', 'sort', 'speak', 'spec', 'special', 'speedy', 'spek', 'stabl', 'stat', 'strengths', 'stroke/diastolic', 'strong', 'subsequ', 'succinct', 'such', 'sugrery', 'suit', 'supply', 'support', 'surgery', 'surround', 'swol', 'systolic/diastol', 'ta', 'tabel', 'tabl', 'tak', 'tal', 'tank', 'task', 'tcank', 'techn', 'technolog', 'tel', 'telemedicin', 'term', 'tfind', 'thank', 'thankk', 'thapnk', 'that', 'thaxnk', 'the', 'ther', 'therapy', 'thi', 'think', 'thnks', 'throat', 'throughout', 'tier', 'tight', 'tightenss', 'til', 'tim', 'tir', 'tnak', 'to', 'toay', 'today', 'torso', 'tot', 'transf', 'tre', 'trelt', 'troubl', 'tru', 'uey', 'undesir', 'unear', 'unfav', 'unintend', 'unit', 'unpopul', 'unsolicit', 'until', 'unus', 'unw', 'up', 'upd', 'upud', 'urg', 'us', 'util', 'vaccin', 'verdict', 'very', 'vi', 'vicin', 'vomit', 'want', 'watch', 'weact', 'weak', 'wee', 'wel', 'welco', 'welcom', 'whaf', 'whar', 'what', 'wheez', 'wher', 'wherein', 'whereof', 'which', 'whil', 'who', 'wholesom', 'wht', 'with', 'within', 'wjeez', 'wond', 'worthwhil', 'would', 'xood', 'ya', 'yapprecy', 'yb', 'yesterday', 'ylu', 'yo', 'you', 'youv', 'zadio', 'zxpertise']\n"
     ]
    }
   ],
   "source": [
    "words = []\n",
    "classes = []\n",
    "documents = []\n",
    "ignore_words = ['?']\n",
    "intents = train_df['intent'].unique()\n",
    "# loop through each sentence in our intents patterns\n",
    "for intent in intents:\n",
    "    temp_df = train_df.loc[train_df['intent'] == intent]\n",
    "    temp_utterances = temp_df['utterance'].tolist()\n",
    "    for pattern in temp_utterances:\n",
    "        # tokenize each word in the sentence\n",
    "        w = nltk.word_tokenize(pattern)\n",
    "        # add to our words list\n",
    "        words.extend(w)\n",
    "        # add to documents in our corpus\n",
    "        documents.append((w, intent))\n",
    "        # add to our classes list\n",
    "        if intent not in classes:\n",
    "            classes.append(intent)\n",
    "\n",
    "# stem and lower each word and remove duplicates\n",
    "words = [stemmer.stem(w.lower()) for w in words if w not in ignore_words]\n",
    "words = sorted(list(set(words)))\n",
    "\n",
    "# sort classes\n",
    "classes = sorted(list(set(classes)))\n",
    "\n",
    "# documents = combination between patterns and intents\n",
    "print (len(documents), \"documents\")\n",
    "# classes = intents\n",
    "print (len(classes), \"classes\", classes)\n",
    "# words = all words, vocabulary\n",
    "print (len(words), \"unique stemmed words\", words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "610f78cd-9a27-4ee2-a730-19124fe32d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create our training data\n",
    "training = []\n",
    "# create an empty array for our output\n",
    "output_empty = [0] * len(classes)\n",
    "\n",
    "# training set, bag of words for each sentence\n",
    "for doc in documents:\n",
    "    # initialize our bag of words\n",
    "    bag = []\n",
    "    # list of tokenized words for the pattern\n",
    "    pattern_words = doc[0]\n",
    "    # stem each word - create base word, in attempt to represent related words\n",
    "    pattern_words = [stemmer.stem(word.lower()) for word in pattern_words]\n",
    "    # create our bag of words array with 1, if word match found in current pattern\n",
    "    for w in words:\n",
    "        bag.append(1) if w in pattern_words else bag.append(0)\n",
    "\n",
    "    # output is a '0' for each tag and '1' for current tag (for each pattern)\n",
    "    output_row = list(output_empty)\n",
    "    output_row[classes.index(doc[1])] = 1\n",
    "\n",
    "    training.append([bag, output_row])\n",
    "\n",
    "# shuffle our features and turn into np.array\n",
    "random.shuffle(training)\n",
    "#training = np.array(training) # This doesn't work with our version of numpy, boo, it doesn't like the 2d array having arrays of different sizes\n",
    "\n",
    "# create train and test lists. X - patterns, Y - intents\n",
    "#train_x = list(training[:,0]) # Same as above, doesn't work\n",
    "#train_y = list(training[:,1]) # Save as above, doesn't work\n",
    "\n",
    "train_x, train_y = zip(*training) # So instead of converting to a np array and slicing, we'll split the list then\n",
    "train_x = np.array(train_x) # Convert the lists, separately, into arrays\n",
    "train_y = np.array(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "554ba040-1233-4b70-88af-188bd84e396a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mist861/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-07-14 14:26:27.361708: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-14 14:26:27.361877: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "# Create model - 3 layers. First layer 128 neurons, second layer 64 neurons and 3rd output layer contains number of neurons\n",
    "# equal to number of intents to predict output intent with softmax\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(len(train_x[0]),), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(train_y[0]), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fbb7e186-5e4f-4195-bf18-8a102d66dbc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mist861/anaconda3/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py:33: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Compile model. Stochastic gradient descent with Nesterov accelerated gradient gives good results for this model\n",
    "sgd = SGD(learning_rate=0.01, decay=1e-6, momentum=0.9, nesterov=True) # I had to tweak this slightly, because even using the legacy SGD this was somehow too new?\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17112444-0877-4d05-8a92-91cdb500c08c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778us/step - accuracy: 0.1619 - loss: 2.3697\n",
      "Epoch 2/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - accuracy: 0.4696 - loss: 1.4884\n",
      "Epoch 3/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 632us/step - accuracy: 0.6107 - loss: 0.9823\n",
      "Epoch 4/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625us/step - accuracy: 0.7707 - loss: 0.6744\n",
      "Epoch 5/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - accuracy: 0.7984 - loss: 0.5235\n",
      "Epoch 6/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624us/step - accuracy: 0.8183 - loss: 0.5042\n",
      "Epoch 7/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615us/step - accuracy: 0.8195 - loss: 0.4416\n",
      "Epoch 8/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624us/step - accuracy: 0.8860 - loss: 0.3202\n",
      "Epoch 9/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628us/step - accuracy: 0.8527 - loss: 0.3722\n",
      "Epoch 10/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623us/step - accuracy: 0.8624 - loss: 0.3515\n",
      "Epoch 11/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 613us/step - accuracy: 0.8886 - loss: 0.3093\n",
      "Epoch 12/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628us/step - accuracy: 0.8847 - loss: 0.2743\n",
      "Epoch 13/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624us/step - accuracy: 0.9224 - loss: 0.2231\n",
      "Epoch 14/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.9107 - loss: 0.2101\n",
      "Epoch 15/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627us/step - accuracy: 0.9269 - loss: 0.1790 \n",
      "Epoch 16/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 616us/step - accuracy: 0.9294 - loss: 0.1814\n",
      "Epoch 17/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622us/step - accuracy: 0.9486 - loss: 0.1601\n",
      "Epoch 18/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 616us/step - accuracy: 0.9321 - loss: 0.1868\n",
      "Epoch 19/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step - accuracy: 0.9677 - loss: 0.1143\n",
      "Epoch 20/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 614us/step - accuracy: 0.9603 - loss: 0.1322\n",
      "Epoch 21/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step - accuracy: 0.9367 - loss: 0.1792\n",
      "Epoch 22/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 635us/step - accuracy: 0.9409 - loss: 0.1613\n",
      "Epoch 23/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 633us/step - accuracy: 0.9568 - loss: 0.1037\n",
      "Epoch 24/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - accuracy: 0.9739 - loss: 0.1140\n",
      "Epoch 25/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622us/step - accuracy: 0.9579 - loss: 0.1180\n",
      "Epoch 26/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - accuracy: 0.9698 - loss: 0.0926 \n",
      "Epoch 27/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 626us/step - accuracy: 0.9449 - loss: 0.1475\n",
      "Epoch 28/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step - accuracy: 0.9681 - loss: 0.0927\n",
      "Epoch 29/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624us/step - accuracy: 0.9829 - loss: 0.0628\n",
      "Epoch 30/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step - accuracy: 0.9874 - loss: 0.0558\n",
      "Epoch 31/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - accuracy: 0.9639 - loss: 0.1202\n",
      "Epoch 32/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - accuracy: 0.9824 - loss: 0.0657\n",
      "Epoch 33/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - accuracy: 0.9777 - loss: 0.0703\n",
      "Epoch 34/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609us/step - accuracy: 0.9802 - loss: 0.0571 \n",
      "Epoch 35/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step - accuracy: 0.9780 - loss: 0.0953\n",
      "Epoch 36/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step - accuracy: 0.9699 - loss: 0.0838\n",
      "Epoch 37/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640us/step - accuracy: 0.9802 - loss: 0.0737\n",
      "Epoch 38/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621us/step - accuracy: 0.9759 - loss: 0.0724 \n",
      "Epoch 39/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 635us/step - accuracy: 0.9883 - loss: 0.0494\n",
      "Epoch 40/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 633us/step - accuracy: 0.9674 - loss: 0.0800\n",
      "Epoch 41/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - accuracy: 0.9733 - loss: 0.0853\n",
      "Epoch 42/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step - accuracy: 0.9763 - loss: 0.0696\n",
      "Epoch 43/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 613us/step - accuracy: 0.9869 - loss: 0.0574\n",
      "Epoch 44/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - accuracy: 0.9910 - loss: 0.0422 \n",
      "Epoch 45/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - accuracy: 0.9931 - loss: 0.0336 \n",
      "Epoch 46/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667us/step - accuracy: 0.9857 - loss: 0.0482\n",
      "Epoch 47/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - accuracy: 0.9921 - loss: 0.0352\n",
      "Epoch 48/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step - accuracy: 0.9786 - loss: 0.0483\n",
      "Epoch 49/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628us/step - accuracy: 0.9809 - loss: 0.0375\n",
      "Epoch 50/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608us/step - accuracy: 0.9822 - loss: 0.0419\n",
      "Epoch 51/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625us/step - accuracy: 0.9887 - loss: 0.0391 \n",
      "Epoch 52/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - accuracy: 0.9762 - loss: 0.0452\n",
      "Epoch 53/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - accuracy: 0.9887 - loss: 0.0266 \n",
      "Epoch 54/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 664us/step - accuracy: 0.9604 - loss: 0.0735\n",
      "Epoch 55/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step - accuracy: 0.9925 - loss: 0.0356\n",
      "Epoch 56/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621us/step - accuracy: 0.9970 - loss: 0.0237\n",
      "Epoch 57/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607us/step - accuracy: 0.9838 - loss: 0.0728\n",
      "Epoch 58/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 616us/step - accuracy: 0.9877 - loss: 0.0554\n",
      "Epoch 59/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604us/step - accuracy: 0.9946 - loss: 0.0296\n",
      "Epoch 60/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step - accuracy: 0.9920 - loss: 0.0328\n",
      "Epoch 61/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - accuracy: 0.9893 - loss: 0.0368\n",
      "Epoch 62/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - accuracy: 0.9806 - loss: 0.0444\n",
      "Epoch 63/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - accuracy: 0.9750 - loss: 0.0657\n",
      "Epoch 64/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629us/step - accuracy: 0.9940 - loss: 0.0297 \n",
      "Epoch 65/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 635us/step - accuracy: 0.9857 - loss: 0.0332\n",
      "Epoch 66/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step - accuracy: 0.9817 - loss: 0.0511\n",
      "Epoch 67/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624us/step - accuracy: 0.9871 - loss: 0.0218\n",
      "Epoch 68/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 655us/step - accuracy: 0.9939 - loss: 0.0210\n",
      "Epoch 69/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 675us/step - accuracy: 0.9742 - loss: 0.0818\n",
      "Epoch 70/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - accuracy: 0.9825 - loss: 0.0591 \n",
      "Epoch 71/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step - accuracy: 0.9957 - loss: 0.0203\n",
      "Epoch 72/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - accuracy: 0.9823 - loss: 0.0569 \n",
      "Epoch 73/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 865us/step - accuracy: 0.9924 - loss: 0.0284\n",
      "Epoch 74/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 663us/step - accuracy: 0.9938 - loss: 0.0269\n",
      "Epoch 75/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step - accuracy: 0.9906 - loss: 0.0283\n",
      "Epoch 76/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757us/step - accuracy: 0.9881 - loss: 0.0510\n",
      "Epoch 77/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 664us/step - accuracy: 0.9945 - loss: 0.0205\n",
      "Epoch 78/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - accuracy: 0.9947 - loss: 0.0322 \n",
      "Epoch 79/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - accuracy: 0.9867 - loss: 0.0327 \n",
      "Epoch 80/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 664us/step - accuracy: 0.9901 - loss: 0.0385 \n",
      "Epoch 81/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - accuracy: 0.9925 - loss: 0.0283\n",
      "Epoch 82/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 721us/step - accuracy: 0.9883 - loss: 0.0355 \n",
      "Epoch 83/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - accuracy: 0.9885 - loss: 0.0287 \n",
      "Epoch 84/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 674us/step - accuracy: 0.9934 - loss: 0.0193 \n",
      "Epoch 85/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - accuracy: 0.9926 - loss: 0.0204 \n",
      "Epoch 86/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - accuracy: 0.9856 - loss: 0.0293 \n",
      "Epoch 87/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - accuracy: 0.9846 - loss: 0.0638\n",
      "Epoch 88/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711us/step - accuracy: 0.9928 - loss: 0.0227\n",
      "Epoch 89/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - accuracy: 0.9907 - loss: 0.0160 \n",
      "Epoch 90/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - accuracy: 0.9864 - loss: 0.0382\n",
      "Epoch 91/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - accuracy: 0.9961 - loss: 0.0184\n",
      "Epoch 92/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step - accuracy: 0.9965 - loss: 0.0243 \n",
      "Epoch 93/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - accuracy: 0.9878 - loss: 0.0279 \n",
      "Epoch 94/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - accuracy: 0.9894 - loss: 0.0254 \n",
      "Epoch 95/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 633us/step - accuracy: 0.9920 - loss: 0.0175 \n",
      "Epoch 96/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - accuracy: 0.9929 - loss: 0.0435\n",
      "Epoch 97/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604us/step - accuracy: 0.9848 - loss: 0.0501\n",
      "Epoch 98/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - accuracy: 0.9899 - loss: 0.0399 \n",
      "Epoch 99/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624us/step - accuracy: 0.9903 - loss: 0.0452\n",
      "Epoch 100/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.9881 - loss: 0.0263 \n",
      "Epoch 101/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - accuracy: 0.9900 - loss: 0.0335\n",
      "Epoch 102/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step - accuracy: 0.9911 - loss: 0.0325\n",
      "Epoch 103/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 633us/step - accuracy: 0.9764 - loss: 0.0761 \n",
      "Epoch 104/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.9574 - loss: 0.2734 \n",
      "Epoch 105/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - accuracy: 0.9835 - loss: 0.0621\n",
      "Epoch 106/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - accuracy: 0.9837 - loss: 0.0475\n",
      "Epoch 107/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - accuracy: 0.9851 - loss: 0.0448\n",
      "Epoch 108/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624us/step - accuracy: 0.9893 - loss: 0.0463\n",
      "Epoch 109/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step - accuracy: 0.9877 - loss: 0.0236\n",
      "Epoch 110/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 728us/step - accuracy: 0.9907 - loss: 0.0261\n",
      "Epoch 111/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627us/step - accuracy: 0.9833 - loss: 0.0630 \n",
      "Epoch 112/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628us/step - accuracy: 0.9981 - loss: 0.0194 \n",
      "Epoch 113/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639us/step - accuracy: 0.9871 - loss: 0.0436\n",
      "Epoch 114/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623us/step - accuracy: 0.9911 - loss: 0.0250 \n",
      "Epoch 115/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step - accuracy: 0.9892 - loss: 0.0240 \n",
      "Epoch 116/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - accuracy: 0.9980 - loss: 0.0131 \n",
      "Epoch 117/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604us/step - accuracy: 0.9826 - loss: 0.0605 \n",
      "Epoch 118/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610us/step - accuracy: 0.9900 - loss: 0.0315 \n",
      "Epoch 119/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step - accuracy: 0.9846 - loss: 0.0479 \n",
      "Epoch 120/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - accuracy: 0.9906 - loss: 0.0444\n",
      "Epoch 121/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - accuracy: 0.9746 - loss: 0.0568\n",
      "Epoch 122/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - accuracy: 0.9904 - loss: 0.0271\n",
      "Epoch 123/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - accuracy: 0.9894 - loss: 0.0283 \n",
      "Epoch 124/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621us/step - accuracy: 0.9987 - loss: 0.0181 \n",
      "Epoch 125/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - accuracy: 0.9900 - loss: 0.0273\n",
      "Epoch 126/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 614us/step - accuracy: 0.9965 - loss: 0.0135\n",
      "Epoch 127/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step - accuracy: 0.9890 - loss: 0.0486 \n",
      "Epoch 128/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607us/step - accuracy: 0.9889 - loss: 0.0227\n",
      "Epoch 129/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 632us/step - accuracy: 0.9956 - loss: 0.0100\n",
      "Epoch 130/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 676us/step - accuracy: 0.9953 - loss: 0.0226\n",
      "Epoch 131/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - accuracy: 0.9980 - loss: 0.0098 \n",
      "Epoch 132/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639us/step - accuracy: 0.9930 - loss: 0.0156 \n",
      "Epoch 133/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 616us/step - accuracy: 0.9921 - loss: 0.0215 \n",
      "Epoch 134/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - accuracy: 0.9962 - loss: 0.0195\n",
      "Epoch 135/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step - accuracy: 0.9831 - loss: 0.0460 \n",
      "Epoch 136/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - accuracy: 0.9828 - loss: 0.0404 \n",
      "Epoch 137/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step - accuracy: 0.9840 - loss: 0.0273 \n",
      "Epoch 138/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - accuracy: 0.9882 - loss: 0.0402\n",
      "Epoch 139/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - accuracy: 0.9841 - loss: 0.0505\n",
      "Epoch 140/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 636us/step - accuracy: 0.9933 - loss: 0.0115 \n",
      "Epoch 141/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621us/step - accuracy: 0.9880 - loss: 0.0365\n",
      "Epoch 142/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - accuracy: 0.9961 - loss: 0.0204 \n",
      "Epoch 143/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 632us/step - accuracy: 0.9861 - loss: 0.0292 \n",
      "Epoch 144/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.9806 - loss: 0.0376 \n",
      "Epoch 145/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 633us/step - accuracy: 0.9851 - loss: 0.0332 \n",
      "Epoch 146/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - accuracy: 0.9914 - loss: 0.0316\n",
      "Epoch 147/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 614us/step - accuracy: 0.9959 - loss: 0.0164\n",
      "Epoch 148/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627us/step - accuracy: 0.9822 - loss: 0.0494 \n",
      "Epoch 149/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step - accuracy: 0.9936 - loss: 0.0202\n",
      "Epoch 150/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 717us/step - accuracy: 0.9900 - loss: 0.0307 \n",
      "Epoch 151/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step - accuracy: 0.9883 - loss: 0.0249\n",
      "Epoch 152/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - accuracy: 0.9956 - loss: 0.0249 \n",
      "Epoch 153/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615us/step - accuracy: 0.9962 - loss: 0.0126 \n",
      "Epoch 154/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - accuracy: 0.9888 - loss: 0.0322 \n",
      "Epoch 155/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 616us/step - accuracy: 0.9916 - loss: 0.0223 \n",
      "Epoch 156/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 626us/step - accuracy: 0.9983 - loss: 0.0127\n",
      "Epoch 157/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 632us/step - accuracy: 0.9940 - loss: 0.0172 \n",
      "Epoch 158/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - accuracy: 0.9910 - loss: 0.0175\n",
      "Epoch 159/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629us/step - accuracy: 0.9972 - loss: 0.0266\n",
      "Epoch 160/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - accuracy: 0.9805 - loss: 0.0472 \n",
      "Epoch 161/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628us/step - accuracy: 0.9779 - loss: 0.0474 \n",
      "Epoch 162/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 725us/step - accuracy: 0.9849 - loss: 0.0251\n",
      "Epoch 163/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - accuracy: 0.9916 - loss: 0.0178 \n",
      "Epoch 164/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.9877 - loss: 0.0244 \n",
      "Epoch 165/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - accuracy: 0.9989 - loss: 0.0140 \n",
      "Epoch 166/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step - accuracy: 0.9914 - loss: 0.0219 \n",
      "Epoch 167/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622us/step - accuracy: 0.9915 - loss: 0.0183 \n",
      "Epoch 168/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624us/step - accuracy: 0.9905 - loss: 0.0434 \n",
      "Epoch 169/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - accuracy: 0.9930 - loss: 0.0231 \n",
      "Epoch 170/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 632us/step - accuracy: 0.9942 - loss: 0.0180 \n",
      "Epoch 171/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615us/step - accuracy: 0.9949 - loss: 0.0157 \n",
      "Epoch 172/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step - accuracy: 0.9869 - loss: 0.0235 \n",
      "Epoch 173/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - accuracy: 0.9942 - loss: 0.0156\n",
      "Epoch 174/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625us/step - accuracy: 0.9951 - loss: 0.0224 \n",
      "Epoch 175/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624us/step - accuracy: 0.9948 - loss: 0.0179\n",
      "Epoch 176/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - accuracy: 0.9956 - loss: 0.0197 \n",
      "Epoch 177/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 674us/step - accuracy: 0.9930 - loss: 0.0222\n",
      "Epoch 178/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628us/step - accuracy: 0.9965 - loss: 0.0120 \n",
      "Epoch 179/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622us/step - accuracy: 0.9914 - loss: 0.0168 \n",
      "Epoch 180/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step - accuracy: 0.9904 - loss: 0.0575\n",
      "Epoch 181/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - accuracy: 0.9926 - loss: 0.0272\n",
      "Epoch 182/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 636us/step - accuracy: 0.9945 - loss: 0.0209\n",
      "Epoch 183/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step - accuracy: 0.9895 - loss: 0.0157 \n",
      "Epoch 184/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - accuracy: 0.9960 - loss: 0.0128 \n",
      "Epoch 185/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step - accuracy: 0.9940 - loss: 0.0183\n",
      "Epoch 186/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step - accuracy: 0.9969 - loss: 0.0090 \n",
      "Epoch 187/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 653us/step - accuracy: 0.9943 - loss: 0.0115 \n",
      "Epoch 188/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 633us/step - accuracy: 0.9954 - loss: 0.0166 \n",
      "Epoch 189/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - accuracy: 0.9971 - loss: 0.0105\n",
      "Epoch 190/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 614us/step - accuracy: 0.9926 - loss: 0.0192 \n",
      "Epoch 191/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.9931 - loss: 0.0230\n",
      "Epoch 192/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step - accuracy: 0.9971 - loss: 0.0090 \n",
      "Epoch 193/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step - accuracy: 0.9916 - loss: 0.0211 \n",
      "Epoch 194/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639us/step - accuracy: 0.9925 - loss: 0.0201 \n",
      "Epoch 195/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 635us/step - accuracy: 0.9916 - loss: 0.0202 \n",
      "Epoch 196/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 632us/step - accuracy: 0.9904 - loss: 0.0308\n",
      "Epoch 197/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 714us/step - accuracy: 0.9941 - loss: 0.0266 \n",
      "Epoch 198/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640us/step - accuracy: 0.9969 - loss: 0.0102\n",
      "Epoch 199/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - accuracy: 0.9828 - loss: 0.0390\n",
      "Epoch 200/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.9953 - loss: 0.0229 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f8871950a90>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(train_x, train_y, epochs=200, batch_size=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce670531-6aaa-43f7-a4e9-f97f5efb616a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up_sentence(sentence):\n",
    "    # tokenize the pattern - split words into array\n",
    "    sentence_words = nltk.word_tokenize(sentence)\n",
    "    # stem each word - create short form for word\n",
    "    sentence_words = [stemmer.stem(word.lower()) for word in sentence_words]\n",
    "    return sentence_words\n",
    "\n",
    "# return bag of words array: 0 or 1 for each word in the bag that exists in the sentence\n",
    "def bow(sentence, words, show_details=True):\n",
    "    # tokenize the pattern\n",
    "    sentence_words = clean_up_sentence(sentence)\n",
    "    # bag of words - matrix of N words, vocabulary matrix\n",
    "    bag = [0]*len(words)\n",
    "    for s in sentence_words:\n",
    "        for i,w in enumerate(words):\n",
    "            if w == s:\n",
    "                # assign 1 if current word is in the vocabulary position\n",
    "                bag[i] = 1\n",
    "                if show_details:\n",
    "                    print (\"found in bag: %s\" % w)\n",
    "\n",
    "    return(np.array(bag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e328198b-a8e9-4edd-94a4-82398c83611c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_local(sentence):\n",
    "    ERROR_THRESHOLD = 0.25\n",
    "\n",
    "    # generate probabilities from the model\n",
    "    input_data = pd.DataFrame([bow(sentence, words)], dtype=float, index=['input'])\n",
    "    results = model.predict([input_data])[0]\n",
    "    # filter out predictions below a threshold, and provide intent index\n",
    "    results = [[i,r] for i,r in enumerate(results) if r>ERROR_THRESHOLD]\n",
    "    # sort by strength of probability\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return_list = []\n",
    "    for r in results:\n",
    "        return_list.append((classes[r[0]], str(r[1])))\n",
    "    # return tuple of intent and probability\n",
    "\n",
    "    return return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5bab6409-848d-48f6-b6d4-7f1bf272c99b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "noanswer\n"
     ]
    }
   ],
   "source": [
    "results = classify_local(\"asdfasdfsadfsadfdsaf\")\n",
    "if float(results[0][1]) < 0.6:\n",
    "    print('noanswer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "019266bb-e7cc-4126-ba71-c5c53f398950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found in bag: pleas\n",
      "found in bag: help\n",
      "found in bag: me\n",
      "found in bag: find\n",
      "found in bag: my\n",
      "found in bag: med\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n"
     ]
    }
   ],
   "source": [
    "response = classify_local(\"Please help me find my medication\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1a45674c-dfe5-46c0-9230-afc635782e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "medication\n"
     ]
    }
   ],
   "source": [
    "print(response[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1a3141cb-2f31-4fc4-b1b4-50449cb284e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_df = pd.read_csv('/mnt/c/Users/willi/Downloads/responses_dataset_augmented.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0520595e-2a43-4c32-aff2-1df1069ce741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Navigating to the Medication module...\"'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses_df.responses[responses_df['intent'] == response[0][0]].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "49a59bea-7d1a-4470-9c07-842f99ef27e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"nn_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "186fd5cb-2f4e-454d-9ccb-2b120c4c733d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('classes.pickle', 'wb') as file:\n",
    "    pickle.dump(classes, file)\n",
    "with open('words.pickle', 'wb') as file:\n",
    "    pickle.dump(words, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ea3846-5151-4c72-95c0-4359e2b86256",
   "metadata": {},
   "source": [
    "# Comparing NN and RAG Intent Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41dfbb32-22e2-44cc-9e52-b5b41cbbb9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['medication', 'hospital_search', 'greeting', 'blood_pressure', 'goodbye', 'doctor', 'thanks', 'medication', 'blood_pressure', 'pharmacy_search', 'goodbye', 'greeting', 'hospital_search', 'goodbye', 'greeting', 'thanks', 'doctor', 'hospital_search', 'doctor', 'hospital_search', 'thanks', 'blood_pressure', 'pharmacy_search', 'doctor', 'hospital_search', 'blood_pressure', 'symptoms', 'greeting', 'pharmacy_search', 'symptoms', 'medication', 'greeting', 'blood_pressure', 'hospital_search', 'pharmacy_search', 'adverse_drug', 'hospital_search', 'greeting', 'symptoms', 'noanswer', 'adverse_drug', 'symptoms', 'pharmacy_search', 'medication', 'pharmacy_search', 'blood_pressure', 'options', 'options', 'hospital_search', 'options', 'noanswer', 'options', 'symptoms', 'pharmacy_search', 'goodbye', 'thanks', 'greeting', 'doctor', 'hospital_search', 'pharmacy_search', 'adverse_drug', 'adverse_drug', 'hospital_search', 'adverse_drug', 'doctor', 'blood_pressure', 'greeting', 'blood_pressure_search', 'goodbye', 'thanks', 'blood_pressure', 'hospital_search', 'symptoms', 'blood_pressure_search', 'blood_pressure_search', 'hospital_search', 'pharmacy_search', 'blood_pressure_search', 'medication', 'doctor', 'doctor', 'adverse_drug', 'goodbye', 'goodbye', 'noanswer', 'goodbye', 'symptoms', 'options', 'goodbye', 'greeting', 'goodbye', 'medication', 'adverse_drug', 'symptoms', 'hospital_search', 'pharmacy_search', 'options', 'blood_pressure', 'greeting', 'doctor', 'blood_pressure', 'options', 'thanks', 'options', 'greeting', 'hospital_search', 'greeting', 'symptoms', 'medication', 'doctor', 'options', 'options', 'goodbye', 'thanks', 'doctor', 'options', 'greeting', 'adverse_drug', 'medication', 'doctor', 'options', 'doctor', 'options', 'medication', 'medication', 'symptoms', 'greeting', 'blood_pressure', 'greeting', 'greeting', 'hospital_search', 'medication', 'goodbye', 'pharmacy_search', 'options', 'hospital_search', 'symptoms', 'options', 'hospital_search', 'options', 'medication', 'blood_pressure', 'adverse_drug', 'medication', 'goodbye', 'pharmacy_search', 'thanks', 'goodbye', 'blood_pressure', 'greeting', 'goodbye', 'greeting', 'greeting', 'thanks', 'blood_pressure', 'pharmacy_search', 'options', 'doctor', 'adverse_drug']\n"
     ]
    }
   ],
   "source": [
    "rag_results = []\n",
    "for utterance in test_df['utterance']:\n",
    "    result = rl(utterance).name\n",
    "    if result == None:\n",
    "        result = 'noanswer'\n",
    "    rag_results.append(result)\n",
    "\n",
    "print(rag_results)\n",
    "    \n",
    "#    result = rl(utterance).name\n",
    "#    rag_results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f271b01e-a478-45c9-9c73-546e960798f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found in bag: ``\n",
      "found in bag: could\n",
      "found in bag: you\n",
      "found in bag: get\n",
      "found in bag: my\n",
      "found in bag: prescrib\n",
      "found in bag: for\n",
      "found in bag: me\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: search\n",
      "found in bag: for\n",
      "found in bag: hospit\n",
      "found in bag: with\n",
      "found in bag: urg\n",
      "found in bag: car\n",
      "found in bag: serv\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: hey\n",
      "found in bag: ,\n",
      "found in bag: good\n",
      "found in bag: to\n",
      "found in bag: see\n",
      "found in bag: you\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: whereof\n",
      "found in bag: ar\n",
      "found in bag: my\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: level\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: bye\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: requir\n",
      "found in bag: the\n",
      "found in bag: at\n",
      "found in bag: of\n",
      "found in bag: a\n",
      "found in bag: phys\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: 'm\n",
      "found in bag: grat\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: 'd\n",
      "found in bag: lik\n",
      "found in bag: to\n",
      "found in bag: ord\n",
      "found in bag: a\n",
      "found in bag: batch\n",
      "found in bag: of\n",
      "found in bag: my\n",
      "found in bag: med\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: 's\n",
      "found in bag: the\n",
      "found in bag: verdict\n",
      "found in bag: on\n",
      "found in bag: my\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: today\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: wher\n",
      "found in bag: can\n",
      "found in bag: i\n",
      "found in bag: over-the-count\n",
      "found in bag: med\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: goodby\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: alright\n",
      "found in bag: ev\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: up\n",
      "found in bag: hospit\n",
      "found in bag: detail\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "found in bag: ``\n",
      "found in bag: see\n",
      "found in bag: you\n",
      "found in bag: lat\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: oblig\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: ar\n",
      "found in bag: ther\n",
      "found in bag: any\n",
      "found in bag: doct\n",
      "found in bag: in\n",
      "found in bag: the\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: want\n",
      "found in bag: to\n",
      "found in bag: search\n",
      "found in bag: hospit\n",
      "found in bag: dat\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: 'm\n",
      "found in bag: look\n",
      "found in bag: to\n",
      "found in bag: consult\n",
      "found in bag: a\n",
      "found in bag: healthc\n",
      "found in bag: profess\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: find\n",
      "found in bag: a\n",
      "found in bag: in\n",
      "found in bag: [\n",
      "found in bag: city/town\n",
      "found in bag: ]\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: you\n",
      "found in bag: hav\n",
      "found in bag: my\n",
      "found in bag: apprecy\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: ar\n",
      "found in bag: my\n",
      "found in bag: blood\n",
      "found in bag: level\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: for\n",
      "found in bag: pharm\n",
      "found in bag: that\n",
      "found in bag: del\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: could\n",
      "found in bag: i\n",
      "found in bag: see\n",
      "found in bag: a\n",
      "found in bag: doct\n",
      "found in bag: ,\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: find\n",
      "found in bag: hospit\n",
      "found in bag: clos\n",
      "found in bag: me\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: want\n",
      "found in bag: to\n",
      "found in bag: search\n",
      "found in bag: for\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: result\n",
      "found in bag: hist\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: feel\n",
      "found in bag: extrem\n",
      "found in bag: tir\n",
      "found in bag: and\n",
      "found in bag: letharg\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: so\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: find\n",
      "found in bag: a\n",
      "found in bag: pharm\n",
      "found in bag: in\n",
      "found in bag: [\n",
      "found in bag: ]\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: feel\n",
      "found in bag: dizzy\n",
      "found in bag: and\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: pleas\n",
      "found in bag: prep\n",
      "found in bag: my\n",
      "found in bag: med\n",
      "found in bag: for\n",
      "found in bag: me\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: hav\n",
      "found in bag: a\n",
      "found in bag: gre\n",
      "found in bag: day\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: 's\n",
      "found in bag: the\n",
      "found in bag: stat\n",
      "found in bag: of\n",
      "found in bag: my\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: loc\n",
      "found in bag: a\n",
      "found in bag: nearby\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: search\n",
      "found in bag: pharm\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: list\n",
      "found in bag: al\n",
      "found in bag: drug\n",
      "found in bag: suit\n",
      "found in bag: for\n",
      "found in bag: paty\n",
      "found in bag: with\n",
      "found in bag: advers\n",
      "found in bag: react\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: find\n",
      "found in bag: hospit\n",
      "found in bag: with\n",
      "found in bag: spec\n",
      "found in bag: special\n",
      "found in bag: (\n",
      "found in bag: ,\n",
      "found in bag: cardiolog\n",
      "found in bag: ,\n",
      "found in bag: pedy\n",
      "found in bag: )\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: welcom\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: 'm\n",
      "found in bag: feel\n",
      "found in bag: unus\n",
      "found in bag: cold\n",
      "found in bag: or\n",
      "found in bag: hot\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: met\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: can\n",
      "found in bag: you\n",
      "found in bag: describ\n",
      "found in bag: any\n",
      "found in bag: undesir\n",
      "found in bag: effect\n",
      "found in bag: that\n",
      "found in bag: could\n",
      "found in bag: occ\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: hav\n",
      "found in bag: a\n",
      "found in bag: runny\n",
      "found in bag: nos\n",
      "found in bag: and\n",
      "found in bag: congest\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: nearby\n",
      "found in bag: pharm\n",
      "found in bag: op\n",
      "found in bag: now\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: vi\n",
      "found in bag: 'd\n",
      "found in bag: lik\n",
      "found in bag: to\n",
      "found in bag: ord\n",
      "found in bag: a\n",
      "found in bag: batch\n",
      "found in bag: of\n",
      "found in bag: my\n",
      "found in bag: med\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: pharm\n",
      "found in bag: throughout\n",
      "found in bag: her\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: chrissake\n",
      "found in bag: press\n",
      "found in bag: dat\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: how\n",
      "found in bag: you\n",
      "found in bag: can\n",
      "found in bag: be\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: ar\n",
      "found in bag: yo\n",
      "found in bag: tal\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: search\n",
      "found in bag: for\n",
      "found in bag: that\n",
      "found in bag: off\n",
      "found in bag: telemedicin\n",
      "found in bag: serv\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: ar\n",
      "found in bag: yo\n",
      "found in bag: cap\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: ther\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: ar\n",
      "found in bag: yo\n",
      "found in bag: strengths\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: expery\n",
      "found in bag: diarrhe\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: wher\n",
      "found in bag: is\n",
      "found in bag: the\n",
      "found in bag: near\n",
      "found in bag: pharm\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: thank\n",
      "found in bag: you\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: ar\n",
      "found in bag: you\n",
      "found in bag: doing\n",
      "found in bag: today\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: ar\n",
      "found in bag: ther\n",
      "found in bag: any\n",
      "found in bag: doct\n",
      "found in bag: in\n",
      "found in bag: the\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: search\n",
      "found in bag: for\n",
      "found in bag: hospit\n",
      "found in bag: with\n",
      "found in bag: urg\n",
      "found in bag: car\n",
      "found in bag: serv\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: pharm\n",
      "found in bag: clos\n",
      "found in bag: to\n",
      "found in bag: my\n",
      "found in bag: loc\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "found in bag: ``\n",
      "found in bag: ar\n",
      "found in bag: ther\n",
      "found in bag: any\n",
      "found in bag: effect\n",
      "found in bag: i\n",
      "found in bag: should\n",
      "found in bag: watch\n",
      "found in bag: out\n",
      "found in bag: for\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: which\n",
      "found in bag: drug\n",
      "found in bag: dont\n",
      "found in bag: hav\n",
      "found in bag: advers\n",
      "found in bag: react\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: wher\n",
      "found in bag: can\n",
      "found in bag: i\n",
      "found in bag: find\n",
      "found in bag: a\n",
      "found in bag: hospit\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: how\n",
      "found in bag: to\n",
      "found in bag: check\n",
      "found in bag: advers\n",
      "found in bag: drug\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: would\n",
      "found in bag: lik\n",
      "found in bag: to\n",
      "found in bag: request\n",
      "found in bag: a\n",
      "found in bag: doct\n",
      "found in bag: 's\n",
      "found in bag: appoint\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: is\n",
      "found in bag: my\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: good\n",
      "found in bag: afternoon\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: press\n",
      "found in bag: for\n",
      "found in bag: paty\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: tak\n",
      "found in bag: it\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: thank\n",
      "found in bag: a\n",
      "found in bag: lot\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: could\n",
      "found in bag: you\n",
      "found in bag: inform\n",
      "found in bag: me\n",
      "found in bag: of\n",
      "found in bag: my\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: outcom\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: loc\n",
      "found in bag: hospit\n",
      "found in bag: in\n",
      "found in bag: [\n",
      "found in bag: neighb\n",
      "found in bag: ]\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: hav\n",
      "found in bag: troubl\n",
      "found in bag: or\n",
      "found in bag: think\n",
      "found in bag: clear\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: show\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: result\n",
      "found in bag: for\n",
      "found in bag: paty\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: for\n",
      "found in bag: paty\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: loc\n",
      "found in bag: a\n",
      "found in bag: hospit\n",
      "found in bag: that\n",
      "found in bag: acceiv\n",
      "found in bag: my\n",
      "found in bag: ins\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: find\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: lood\n",
      "found in bag: press\n",
      "found in bag: for\n",
      "found in bag: paty\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: nee\n",
      "found in bag: to\n",
      "found in bag: repl\n",
      "found in bag: my\n",
      "found in bag: supply\n",
      "found in bag: of\n",
      "found in bag: drug\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: requir\n",
      "found in bag: to\n",
      "found in bag: consult\n",
      "found in bag: with\n",
      "found in bag: a\n",
      "found in bag: med\n",
      "found in bag: doct\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: is\n",
      "found in bag: ther\n",
      "found in bag: a\n",
      "found in bag: doct\n",
      "found in bag: on\n",
      "found in bag: duty\n",
      "found in bag: right\n",
      "found in bag: now\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: could\n",
      "found in bag: you\n",
      "found in bag: list\n",
      "found in bag: the\n",
      "found in bag: pot\n",
      "found in bag: drawback\n",
      "found in bag: or\n",
      "found in bag: downsid\n",
      "found in bag: of\n",
      "found in bag: us\n",
      "found in bag: thi\n",
      "found in bag: drug\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: catch\n",
      "found in bag: you\n",
      "found in bag: lat\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: bye-by\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "found in bag: ``\n",
      "found in bag: find\n",
      "found in bag: me\n",
      "found in bag: a\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: be\n",
      "found in bag: going\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: my\n",
      "found in bag: joint\n",
      "found in bag: ar\n",
      "found in bag: swol\n",
      "found in bag: and\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: can\n",
      "found in bag: you\n",
      "found in bag: contribut\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: ya\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: you\n",
      "found in bag: 're\n",
      "found in bag: a\n",
      "found in bag: lifesav\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: hav\n",
      "found in bag: a\n",
      "found in bag: good\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: 'd\n",
      "found in bag: lik\n",
      "found in bag: to\n",
      "found in bag: request\n",
      "found in bag: a\n",
      "found in bag: prescrib\n",
      "found in bag: refil\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: ther\n",
      "found in bag: any\n",
      "found in bag: advers\n",
      "found in bag: effect\n",
      "found in bag: i\n",
      "found in bag: should\n",
      "found in bag: be\n",
      "found in bag: aw\n",
      "found in bag: of\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: my\n",
      "found in bag: joint\n",
      "found in bag: ar\n",
      "found in bag: swol\n",
      "found in bag: and\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: for\n",
      "found in bag: hospit\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: find\n",
      "found in bag: a\n",
      "found in bag: 24-hour\n",
      "found in bag: pharm\n",
      "found in bag: me\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: hav\n",
      "found in bag: troubl\n",
      "found in bag: cont\n",
      "found in bag: or\n",
      "found in bag: clear\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: could\n",
      "found in bag: you\n",
      "found in bag: audit\n",
      "found in bag: my\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: ,\n",
      "found in bag: pleas\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: how\n",
      "found in bag: 's\n",
      "found in bag: it\n",
      "found in bag: going\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: can\n",
      "found in bag: you\n",
      "found in bag: direct\n",
      "found in bag: me\n",
      "found in bag: to\n",
      "found in bag: a\n",
      "found in bag: doct\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: how\n",
      "found in bag: doe\n",
      "found in bag: my\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: comp\n",
      "found in bag: to\n",
      "found in bag: norm\n",
      "found in bag: level\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: do\n",
      "found in bag: you\n",
      "found in bag: spec\n",
      "found in bag: in\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: 'm\n",
      "found in bag: deeply\n",
      "found in bag: thank\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: ar\n",
      "found in bag: yo\n",
      "found in bag: tal\n",
      "found in bag: and\n",
      "found in bag: skil\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: wher\n",
      "found in bag: can\n",
      "found in bag: i\n",
      "found in bag: find\n",
      "found in bag: hospit\n",
      "found in bag: with\n",
      "found in bag: surgery\n",
      "found in bag: facil\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: hav\n",
      "found in bag: a\n",
      "found in bag: day\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: hav\n",
      "found in bag: a\n",
      "found in bag: headach\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: is\n",
      "found in bag: my\n",
      "found in bag: prescrib\n",
      "found in bag: ready\n",
      "found in bag: for\n",
      "found in bag: pickup\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "found in bag: ``\n",
      "found in bag: can\n",
      "found in bag: i\n",
      "found in bag: speak\n",
      "found in bag: to\n",
      "found in bag: a\n",
      "found in bag: healthc\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: support\n",
      "found in bag: is\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: whar\n",
      "found in bag: ar\n",
      "found in bag: yo\n",
      "found in bag: strong\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: out\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: thank\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: could\n",
      "found in bag: i\n",
      "found in bag: see\n",
      "found in bag: a\n",
      "found in bag: med\n",
      "found in bag: ,\n",
      "found in bag: pleas\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: ar\n",
      "found in bag: you\n",
      "found in bag: cap\n",
      "found in bag: of\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: buen\n",
      "found in bag: morn\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: can\n",
      "found in bag: you\n",
      "found in bag: tel\n",
      "found in bag: me\n",
      "found in bag: about\n",
      "found in bag: the\n",
      "found in bag: poss\n",
      "found in bag: sid\n",
      "found in bag: effect\n",
      "found in bag: of\n",
      "found in bag: tak\n",
      "found in bag: thi\n",
      "found in bag: medicin\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: 'd\n",
      "found in bag: lik\n",
      "found in bag: to\n",
      "found in bag: ord\n",
      "found in bag: a\n",
      "found in bag: batch\n",
      "found in bag: of\n",
      "found in bag: my\n",
      "found in bag: med\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: nee\n",
      "found in bag: med\n",
      "found in bag: assist\n",
      "found in bag: from\n",
      "found in bag: a\n",
      "found in bag: doct\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: quel\n",
      "found in bag: ar\n",
      "found in bag: yo\n",
      "found in bag: proficy\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: is\n",
      "found in bag: it\n",
      "found in bag: poss\n",
      "found in bag: to\n",
      "found in bag: meet\n",
      "found in bag: with\n",
      "found in bag: a\n",
      "found in bag: med\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: ar\n",
      "found in bag: yo\n",
      "found in bag: strong\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: is\n",
      "found in bag: my\n",
      "found in bag: avail\n",
      "found in bag: for\n",
      "found in bag: pickup\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: may\n",
      "found in bag: i\n",
      "found in bag: request\n",
      "found in bag: a\n",
      "found in bag: refil\n",
      "found in bag: of\n",
      "found in bag: my\n",
      "found in bag: prescrib\n",
      "found in bag: ,\n",
      "found in bag: pleas\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: hav\n",
      "found in bag: abdomin\n",
      "found in bag: pain\n",
      "found in bag: and\n",
      "found in bag: cramp\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: hwat\n",
      "found in bag: 's\n",
      "found in bag: up\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: dat\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: ther\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: look\n",
      "found in bag: for\n",
      "found in bag: a\n",
      "found in bag: that\n",
      "found in bag: 's\n",
      "found in bag: op\n",
      "found in bag: 24/7\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: can\n",
      "found in bag: i\n",
      "found in bag: pick\n",
      "found in bag: up\n",
      "found in bag: my\n",
      "found in bag: ord\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: see\n",
      "found in bag: you\n",
      "found in bag: around\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: hospit\n",
      "found in bag: with\n",
      "found in bag: covid-19\n",
      "found in bag: tre\n",
      "found in bag: facil\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: whar\n",
      "found in bag: you\n",
      "found in bag: can\n",
      "found in bag: do\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: hospit\n",
      "found in bag: near\n",
      "found in bag: me\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: 'm\n",
      "found in bag: expery\n",
      "found in bag: nause\n",
      "found in bag: and\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: help\n",
      "found in bag: you\n",
      "found in bag: provid\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "found in bag: ``\n",
      "found in bag: hospit\n",
      "found in bag: clos\n",
      "found in bag: to\n",
      "found in bag: my\n",
      "found in bag: loc\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: ar\n",
      "found in bag: yo\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: can\n",
      "found in bag: you\n",
      "found in bag: fil\n",
      "found in bag: my\n",
      "found in bag: prescrib\n",
      "found in bag: for\n",
      "found in bag: me\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: how\n",
      "found in bag: is\n",
      "found in bag: my\n",
      "found in bag: blod\n",
      "found in bag: press\n",
      "found in bag: look\n",
      "found in bag: today\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: kind\n",
      "found in bag: of\n",
      "found in bag: might\n",
      "found in bag: i\n",
      "found in bag: expery\n",
      "found in bag: from\n",
      "found in bag: thi\n",
      "found in bag: med\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: nee\n",
      "found in bag: to\n",
      "found in bag: refil\n",
      "found in bag: my\n",
      "found in bag: med\n",
      "found in bag: supply\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "found in bag: ``\n",
      "found in bag: goodby\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: of\n",
      "found in bag: pharm\n",
      "found in bag: nearby\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: 'm\n",
      "found in bag: thank\n",
      "found in bag: for\n",
      "found in bag: yo\n",
      "found in bag: support\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: til\n",
      "found in bag: fut\n",
      "found in bag: tim\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: to\n",
      "found in bag: log\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: result\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: ,\n",
      "found in bag: how\n",
      "found in bag: hav\n",
      "found in bag: you\n",
      "found in bag: been\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: see\n",
      "found in bag: you\n",
      "found in bag: afterward\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: is\n",
      "found in bag: anyon\n",
      "found in bag: ther\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: 'm\n",
      "found in bag: so\n",
      "found in bag: thank\n",
      "found in bag: for\n",
      "found in bag: [\n",
      "found in bag: spec\n",
      "found in bag: gest\n",
      "found in bag: or\n",
      "found in bag: help\n",
      "found in bag: ]\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: task\n",
      "found in bag: to\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "found in bag: ``\n",
      "found in bag: loc\n",
      "found in bag: a\n",
      "found in bag: pharmaceut\n",
      "found in bag: nearby\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: ar\n",
      "found in bag: yo\n",
      "found in bag: strengths\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: is\n",
      "found in bag: a\n",
      "found in bag: phys\n",
      "found in bag: avail\n",
      "found in bag: to\n",
      "found in bag: see\n",
      "found in bag: me\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: kind\n",
      "found in bag: of\n",
      "found in bag: react\n",
      "found in bag: should\n",
      "found in bag: i\n",
      "found in bag: be\n",
      "found in bag: prep\n",
      "found in bag: for\n",
      "found in bag: with\n",
      "found in bag: thi\n",
      "found in bag: drug\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "['medication', 'hospital_search', 'greeting', 'blood_pressure', 'goodbye', 'doctor', 'thanks', 'medication', 'blood_pressure', 'pharmacy_search', 'goodbye', 'greeting', 'hospital_search', 'goodbye', 'greeting', 'thanks', 'doctor', 'hospital_search', 'doctor', 'pharmacy_search', 'thanks', 'blood_pressure', 'pharmacy_search', 'doctor', 'hospital_search', 'blood_pressure_search', 'symptoms', 'goodbye', 'pharmacy_search', 'symptoms', 'medication', 'goodbye', 'blood_pressure', 'pharmacy_search', 'pharmacy_search', 'adverse_drug', 'hospital_search', 'greeting', 'symptoms', 'greeting', 'adverse_drug', 'symptoms', 'pharmacy_search', 'medication', 'pharmacy_search', 'blood_pressure', 'options', 'options', 'pharmacy_search', 'options', 'greeting', 'options', 'symptoms', 'pharmacy_search', 'greeting', 'thanks', 'greeting', 'doctor', 'hospital_search', 'pharmacy_search', 'adverse_drug', 'adverse_drug', 'hospital_search', 'adverse_drug', 'doctor', 'blood_pressure', 'greeting', 'blood_pressure_search', 'goodbye', 'thanks', 'blood_pressure', 'hospital_search', 'symptoms', 'blood_pressure_search', 'blood_pressure_search', 'hospital_search', 'pharmacy_search', 'blood_pressure_search', 'medication', 'doctor', 'doctor', 'adverse_drug', 'goodbye', 'goodbye', 'pharmacy_search', 'goodbye', 'symptoms', 'options', 'goodbye', 'thanks', 'goodbye', 'medication', 'adverse_drug', 'symptoms', 'hospital_search', 'pharmacy_search', 'symptoms', 'blood_pressure', 'greeting', 'doctor', 'blood_pressure', 'options', 'thanks', 'options', 'greeting', 'hospital_search', 'goodbye', 'symptoms', 'medication', 'doctor', 'options', 'options', 'goodbye', 'thanks', 'doctor', 'options', 'greeting', 'adverse_drug', 'medication', 'doctor', 'options', 'doctor', 'options', 'medication', 'medication', 'symptoms', 'greeting', 'blood_pressure', 'greeting', 'greeting', 'pharmacy_search', 'medication', 'goodbye', 'hospital_search', 'options', 'hospital_search', 'symptoms', 'options', 'hospital_search', 'options', 'medication', 'blood_pressure', 'adverse_drug', 'medication', 'goodbye', 'pharmacy_search', 'thanks', 'goodbye', 'blood_pressure', 'greeting', 'goodbye', 'greeting', 'goodbye', 'thanks', 'blood_pressure', 'pharmacy_search', 'options', 'doctor', 'adverse_drug']\n"
     ]
    }
   ],
   "source": [
    "nn_results = []\n",
    "for utterance in test_df['utterance']:\n",
    "    result = classify_local(utterance)[0][0]\n",
    "    nn_results.append(result)\n",
    "\n",
    "print(nn_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1fabbade-1731-41c5-9cbb-728120934d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,  silhouette_score, multilabel_confusion_matrix as mcm) # Importing sklearn metrics for supervised model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "023368df-b1d6-4188-8efa-eb0d668385b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN Accuracy: 0.9433962264150944, NN Recall: 0.9580327080327079, NN Precision: 0.9561546840958606\n"
     ]
    }
   ],
   "source": [
    "nn_accuracy = accuracy_score(test_df['intent'], nn_results)\n",
    "nn_recall = recall_score(test_df['intent'], nn_results, average='macro')\n",
    "nn_precision = precision_score(test_df['intent'], nn_results, average='macro')\n",
    "print(f'NN Accuracy: {nn_accuracy}, NN Recall: {nn_recall}, NN Precision: {nn_precision}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34f3aa90-51ed-4a5d-a48c-cc58f41e9b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Accuracy: 0.9119496855345912, RAG Recall: 0.8432930317545703, RAG Precision: 0.8747517069736647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mist861/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "rag_accuracy = accuracy_score(test_df['intent'], rag_results)\n",
    "rag_recall = recall_score(test_df['intent'], rag_results, average='macro')\n",
    "rag_precision = precision_score(test_df['intent'], rag_results, average='macro')\n",
    "print(f'RAG Accuracy: {rag_accuracy}, RAG Recall: {rag_recall}, RAG Precision: {rag_precision}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdaf44e3-b094-47b4-935d-1e6f7e5abc1c",
   "metadata": {},
   "source": [
    "# RAG-LLM Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "430208df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-cpp-python in ./anaconda3/lib/python3.11/site-packages (0.2.78)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./anaconda3/lib/python3.11/site-packages (from llama-cpp-python) (4.12.2)\n",
      "Requirement already satisfied: numpy>=1.20.0 in ./anaconda3/lib/python3.11/site-packages (from llama-cpp-python) (1.26.4)\n",
      "Requirement already satisfied: diskcache>=5.6.1 in ./anaconda3/lib/python3.11/site-packages (from llama-cpp-python) (5.6.3)\n",
      "Requirement already satisfied: jinja2>=2.11.3 in ./anaconda3/lib/python3.11/site-packages (from llama-cpp-python) (3.1.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./anaconda3/lib/python3.11/site-packages (from jinja2>=2.11.3->llama-cpp-python) (2.1.5)\n",
      "Collecting ollama\n",
      "  Obtaining dependency information for ollama from https://files.pythonhosted.org/packages/7d/b7/8cc05807bfbc5b92da7fb94c525e1e56572a08eea7cdf3656e6c5dc6f9b1/ollama-0.2.1-py3-none-any.whl.metadata\n",
      "  Downloading ollama-0.2.1-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in ./anaconda3/lib/python3.11/site-packages (from ollama) (0.27.0)\n",
      "Requirement already satisfied: anyio in ./anaconda3/lib/python3.11/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (4.4.0)\n",
      "Requirement already satisfied: certifi in ./anaconda3/lib/python3.11/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in ./anaconda3/lib/python3.11/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.0.5)\n",
      "Requirement already satisfied: idna in ./anaconda3/lib/python3.11/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (2.10)\n",
      "Requirement already satisfied: sniffio in ./anaconda3/lib/python3.11/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./anaconda3/lib/python3.11/site-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama) (0.14.0)\n",
      "Downloading ollama-0.2.1-py3-none-any.whl (9.7 kB)\n",
      "Installing collected packages: ollama\n",
      "Successfully installed ollama-0.2.1\n"
     ]
    }
   ],
   "source": [
    "! CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" pip install llama-cpp-python\n",
    "!pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ab0d136-41d5-4fdb-915a-b2e467305e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3d4e88d-07e9-437e-b5f8-299658230315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Absolutely, I'd be happy to assist you in finding a suitable doctor! To begin with, there are several ways we can approach this task. We can consider factors such as your location, specialty requirements (if any), and preferred healthcare provider types (like family physicians or specialists). \n",
      "\n",
      "I will navigate to the Doctor Search module for us. Let me gather some information based on these preferences:\n",
      "\n",
      "1. Please provide me with your geographical location – city/town, state, or region would be helpful.\n",
      "2. Do you have any specific medical concerns that require a specialist? If not, we can explore general practitioners in your area.\n",
      "3. Is there a particular type of healthcare provider you prefer, such as family physicians, internists, or another field?\n",
      "\n",
      "Once I have these details, I'll be able to help you search for an appropriate doctor nearby.\n"
     ]
    }
   ],
   "source": [
    "response = ollama.chat(model='superdrew100/kappa-3-phi-3-4k-instruct-abliterated', messages = [ \n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful medical assistant. Your response should be similar to: I can do that!  Navigating to the Doctor Search module...\"}, \n",
    "    {\"role\": \"user\", \"content\": \"Can you help me find a doctor?\"}\n",
    "])\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3eddeb70-baa3-4192-a077-916f62c2bfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_df = intent_new_df = pd.read_csv('/mnt/c/Users/willi/Downloads/responses_dataset_augmented.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2cfb8fb4-fe68-4840-ad9e-16c9c505b3a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>responses</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hello! How can I help?</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Have a nice day!</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You're welcome, I'm happy to help!</td>\n",
       "      <td>thanks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm sorry, I can't understand you.  Please ref...</td>\n",
       "      <td>noanswer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I can assist you with identifying symptoms, fi...</td>\n",
       "      <td>options</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sure, I can help with that!  Navigating to the...</td>\n",
       "      <td>adverse_drug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Certainly, I can do that!  Navigating to the B...</td>\n",
       "      <td>blood_pressure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Of course!  Navigating to the Pharmacy Search ...</td>\n",
       "      <td>pharmacy_search</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Can do!  Navigating to the Hospital Search mod...</td>\n",
       "      <td>hospital_search</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Yep!  Navigating to the Blood Pressure Search ...</td>\n",
       "      <td>blood_pressure_search</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>I think I can help with that!  Navigating to t...</td>\n",
       "      <td>symptoms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>I can do that!  Navigating to the Doctor Searc...</td>\n",
       "      <td>doctor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>I think this is what you're after.  Navigating...</td>\n",
       "      <td>medication</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            responses                 intent\n",
       "0                              Hello! How can I help?               greeting\n",
       "1                                    Have a nice day!                goodbye\n",
       "2                  You're welcome, I'm happy to help!                 thanks\n",
       "3   I'm sorry, I can't understand you.  Please ref...               noanswer\n",
       "4   I can assist you with identifying symptoms, fi...                options\n",
       "5   Sure, I can help with that!  Navigating to the...           adverse_drug\n",
       "6   Certainly, I can do that!  Navigating to the B...         blood_pressure\n",
       "7   Of course!  Navigating to the Pharmacy Search ...        pharmacy_search\n",
       "8   Can do!  Navigating to the Hospital Search mod...        hospital_search\n",
       "9   Yep!  Navigating to the Blood Pressure Search ...  blood_pressure_search\n",
       "10  I think I can help with that!  Navigating to t...               symptoms\n",
       "11  I can do that!  Navigating to the Doctor Searc...                 doctor\n",
       "12  I think this is what you're after.  Navigating...             medication"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8096f44c-3115-4066-a9d1-5c958924e3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rag_respose(prompt):\n",
    "    intent = rl(prompt).name\n",
    "    if intent != None:\n",
    "        response = responses_df.responses[responses_df['intent'] == intent].item()\n",
    "    else:\n",
    "        response = responses_df.responses[responses_df['intent'] == 'noanswer'].item()\n",
    "    msg = ollama.chat(model='superdrew100/kappa-3-phi-3-4k-instruct-abliterated', messages = [ \n",
    "        {\"role\": \"system\", \"content\": f\"You are a helpful medical assistant. Your response should be similar to: {response}\"}, \n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ])\n",
    "    return msg['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8e88235a-f74b-4fbc-89ef-8590098096ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Absolutely, I'd be happy to assist you with finding your blood pressure reading. While I don't have direct access to monitor vital signs, there are several ways for you to measure your own blood pressure:\n",
      "\n",
      "1. Purchase a home blood pressure monitoring device: There are many affordable and accurate personal blood pressure monitors available in the market that can be used at home for regular checks. These devices usually include an inflatable cuff connected to a display unit with measurements shown on it.\n",
      "\n",
      "2. Visit a healthcare professional: Your doctor or nurse will have access to medical-grade blood pressure measurement equipment, and they can measure your blood pressure during an appointment. Remember that visiting your provider allows for the opportunity to discuss any concerns about high blood pressure or other issues related to your overall health.\n",
      "\n",
      "3. Use a smartphone app: There are some apps available on mobile devices that help you track and monitor your blood pressure by using an attached cuff, similar to those used in home monitoring equipment.\n",
      "\n",
      "I hope this information helps you find and keep track of your blood pressure. Let me know if there's anything else I can assist with!\n"
     ]
    }
   ],
   "source": [
    "response = generate_rag_respose(\"Can you help me find my blood pressure?\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
