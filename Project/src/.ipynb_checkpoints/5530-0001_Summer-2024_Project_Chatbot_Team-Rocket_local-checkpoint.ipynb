{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb2d4b2b-4270-48c6-9c95-aac531c7e02c",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe2758b-a6f2-4840-af5f-4b6672ffae04",
   "metadata": {},
   "source": [
    "## Prework to Generate Dataset CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "466aff27-56da-456c-bd15-5fb7e97c5495",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json # For reading the original intents.json\n",
    "import csv # For reading/writing csv files\n",
    "import pandas as pd # For creating/modifying/writing pandas dataframes\n",
    "import pickle # For pickling files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "550d2ec6-76b3-4b80-93e0-9d1f02194a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data_raw/intents.json') as json_data: # Load the intents json\n",
    "    intents = json.load(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd937b91-b193-409f-ad1c-596887906cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intents': [{'tag': 'greeting', 'patterns': ['Hi there', 'How are you', 'Is anyone there?', 'Hello', 'Good day'], 'responses': ['Hello, thanks for asking', 'Good to see you again', 'Hi there, how can I help?'], 'context': ['']}, {'tag': 'goodbye', 'patterns': ['Bye', 'See you later', 'Goodbye', 'Nice chatting to you, bye', 'Till next time'], 'responses': ['See you!', 'Have a nice day', 'Bye! Come back again soon.'], 'context': ['']}, {'tag': 'thanks', 'patterns': ['Thanks', 'Thank you', \"That's helpful\", 'Awesome, thanks', 'Thanks for helping me'], 'responses': ['Happy to help!', 'Any time!', 'My pleasure'], 'context': ['']}, {'tag': 'noanswer', 'patterns': [], 'responses': [\"Sorry, can't understand you\", 'Please give me more info', 'Not sure I understand'], 'context': ['']}, {'tag': 'options', 'patterns': ['How you could help me?', 'What you can do?', 'What help you provide?', 'How you can be helpful?', 'What support is offered'], 'responses': ['I can guide you through Adverse drug reaction list, Blood pressure tracking, Hospitals and Pharmacies', 'Offering support for Adverse drug reaction, Blood pressure, Hospitals and Pharmacies'], 'context': ['']}, {'tag': 'adverse_drug', 'patterns': ['How to check Adverse drug reaction?', 'Open adverse drugs module', 'Give me a list of drugs causing adverse behavior', 'List all drugs suitable for patient with adverse reaction', 'Which drugs dont have adverse reaction?'], 'responses': ['Navigating to Adverse drug reaction module'], 'context': ['']}, {'tag': 'blood_pressure', 'patterns': ['Open blood pressure module', 'Task related to blood pressure', 'Blood pressure data entry', 'I want to log blood pressure results', 'Blood pressure data management'], 'responses': ['Navigating to Blood Pressure module'], 'context': ['']}, {'tag': 'blood_pressure_search', 'patterns': ['I want to search for blood pressure result history', 'Blood pressure for patient', 'Load patient blood pressure result', 'Show blood pressure results for patient', 'Find blood pressure results by ID'], 'responses': ['Please provide Patient ID', 'Patient ID?'], 'context': ['search_blood_pressure_by_patient_id']}, {'tag': 'search_blood_pressure_by_patient_id', 'patterns': [], 'responses': ['Loading Blood pressure result for Patient'], 'context': ['']}, {'tag': 'pharmacy_search', 'patterns': ['Find me a pharmacy', 'Find pharmacy', 'List of pharmacies nearby', 'Locate pharmacy', 'Search pharmacy'], 'responses': ['Please provide pharmacy name'], 'context': ['search_pharmacy_by_name']}, {'tag': 'search_pharmacy_by_name', 'patterns': [], 'responses': ['Loading pharmacy details'], 'context': ['']}, {'tag': 'hospital_search', 'patterns': ['Lookup for hospital', 'Searching for hospital to transfer patient', 'I want to search hospital data', 'Hospital lookup for patient', 'Looking up hospital details'], 'responses': ['Please provide hospital name or location'], 'context': ['search_hospital_by_params']}, {'tag': 'search_hospital_by_params', 'patterns': [], 'responses': ['Please provide hospital type'], 'context': ['search_hospital_by_type']}, {'tag': 'search_hospital_by_type', 'patterns': [], 'responses': ['Loading hospital details'], 'context': ['']}]}\n"
     ]
    }
   ],
   "source": [
    "print(intents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "339111c3-779a-475a-adaf-7c28566461d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the intents and utterances in intents.json into a dict\n",
    "\n",
    "temp_intent_dict = {}\n",
    "temp_utterance = []\n",
    "temp_intents = []\n",
    "for i in intents['intents']:\n",
    "    for j in i['patterns']:\n",
    "        temp_intents.append(str(i['tag']))\n",
    "        temp_utterance.append(str(j))        \n",
    "temp_intent_dict['utterance'] = temp_utterance\n",
    "temp_intent_dict['intent'] = temp_intents\n",
    "\n",
    "#for intent in intents['intents']:\n",
    "#    temp_intents[f\"{intent['tag']}\"] = intent['patterns']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649bbed9-e1a0-4b31-b421-eaf12fa6214b",
   "metadata": {},
   "source": [
    "**NOTE:** Due to how the above only reads in intents that have utterances/patterns, some intents from the original dataset were removed, including:\n",
    "\n",
    "* noanswer\n",
    "* search_blood_pressure_by_patient_id\n",
    "* search_pharmacy_by_name\n",
    "* search_hospital_by_params\n",
    "* search_hospital_by_type\n",
    "\n",
    "Which we believe to be acceptable, as they are close enough to existing intents as to be redundant. Additionally, because no utterances are given, we would have to make up what these intents meant anyways.\n",
    "\n",
    "However, please also note that \"noanswer\" is reused later in the final product, as the fallback response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1f6417e-33bb-4c74-a4c4-ef5664625ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'utterance': ['Hi there', 'How are you', 'Is anyone there?', 'Hello', 'Good day', 'Bye', 'See you later', 'Goodbye', 'Nice chatting to you, bye', 'Till next time', 'Thanks', 'Thank you', \"That's helpful\", 'Awesome, thanks', 'Thanks for helping me', 'How you could help me?', 'What you can do?', 'What help you provide?', 'How you can be helpful?', 'What support is offered', 'How to check Adverse drug reaction?', 'Open adverse drugs module', 'Give me a list of drugs causing adverse behavior', 'List all drugs suitable for patient with adverse reaction', 'Which drugs dont have adverse reaction?', 'Open blood pressure module', 'Task related to blood pressure', 'Blood pressure data entry', 'I want to log blood pressure results', 'Blood pressure data management', 'I want to search for blood pressure result history', 'Blood pressure for patient', 'Load patient blood pressure result', 'Show blood pressure results for patient', 'Find blood pressure results by ID', 'Find me a pharmacy', 'Find pharmacy', 'List of pharmacies nearby', 'Locate pharmacy', 'Search pharmacy', 'Lookup for hospital', 'Searching for hospital to transfer patient', 'I want to search hospital data', 'Hospital lookup for patient', 'Looking up hospital details'], 'intent': ['greeting', 'greeting', 'greeting', 'greeting', 'greeting', 'goodbye', 'goodbye', 'goodbye', 'goodbye', 'goodbye', 'thanks', 'thanks', 'thanks', 'thanks', 'thanks', 'options', 'options', 'options', 'options', 'options', 'adverse_drug', 'adverse_drug', 'adverse_drug', 'adverse_drug', 'adverse_drug', 'blood_pressure', 'blood_pressure', 'blood_pressure', 'blood_pressure', 'blood_pressure', 'blood_pressure_search', 'blood_pressure_search', 'blood_pressure_search', 'blood_pressure_search', 'blood_pressure_search', 'pharmacy_search', 'pharmacy_search', 'pharmacy_search', 'pharmacy_search', 'pharmacy_search', 'hospital_search', 'hospital_search', 'hospital_search', 'hospital_search', 'hospital_search']}\n"
     ]
    }
   ],
   "source": [
    "print(temp_intent_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33baf7b8-a6ad-457f-8ca1-75004d30d302",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_intent_df = pd.DataFrame.from_dict(temp_intent_dict) # Convert the dict into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae487bdf-a71b-4b63-9309-1076dcf1c5c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi there</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How are you</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Is anyone there?</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hello</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Good day</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bye</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>See you later</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Goodbye</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Nice chatting to you, bye</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Till next time</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   utterance    intent\n",
       "0                   Hi there  greeting\n",
       "1                How are you  greeting\n",
       "2           Is anyone there?  greeting\n",
       "3                      Hello  greeting\n",
       "4                   Good day  greeting\n",
       "5                        Bye   goodbye\n",
       "6              See you later   goodbye\n",
       "7                    Goodbye   goodbye\n",
       "8  Nice chatting to you, bye   goodbye\n",
       "9             Till next time   goodbye"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_intent_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21900e0b-0a91-4a26-a9d8-ce418323b15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_intent_df['utterance'] = temp_intent_df['utterance'].apply(lambda x: \"\\\"\" + str(x) + \"\\\"\") # Add quoates around the utterances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e984eed-ea75-417b-a772-6082c92e5c8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Hi there\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"How are you\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Is anyone there?\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Hello\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Good day\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"Bye\"</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"See you later\"</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"Goodbye\"</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"Nice chatting to you, bye\"</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"Till next time\"</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     utterance    intent\n",
       "0                   \"Hi there\"  greeting\n",
       "1                \"How are you\"  greeting\n",
       "2           \"Is anyone there?\"  greeting\n",
       "3                      \"Hello\"  greeting\n",
       "4                   \"Good day\"  greeting\n",
       "5                        \"Bye\"   goodbye\n",
       "6              \"See you later\"   goodbye\n",
       "7                    \"Goodbye\"   goodbye\n",
       "8  \"Nice chatting to you, bye\"   goodbye\n",
       "9             \"Till next time\"   goodbye"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_intent_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe36166b-e0ec-4e70-adca-85693a7b8f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_new_df = pd.read_csv('../data_raw/intent_dataset_new.csv') # Load the new, generated set of intents (from asking ChatGPT for examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1360c3f7-741f-48d9-9788-d55881a2b312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Hello!\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Hi there!\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Hey!\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Good morning!\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Good afternoon!\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"Good evening!\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"Howdy!\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"Greetings!\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"What's up?\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"How's it going?\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           utterance    intent\n",
       "0           \"Hello!\"  greeting\n",
       "1        \"Hi there!\"  greeting\n",
       "2             \"Hey!\"  greeting\n",
       "3    \"Good morning!\"  greeting\n",
       "4  \"Good afternoon!\"  greeting\n",
       "5    \"Good evening!\"  greeting\n",
       "6           \"Howdy!\"  greeting\n",
       "7       \"Greetings!\"  greeting\n",
       "8       \"What's up?\"  greeting\n",
       "9  \"How's it going?\"  greeting"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intent_new_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba6dbaf9-653e-40e5-98a3-aee621858b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_full_df = pd.concat([temp_intent_df,intent_new_df],axis=0) # Combine the old and new intents dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e52000f-40ac-4dad-bcc2-cdd871f0e2d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Hi there\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"How are you\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Is anyone there?\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Hello\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Good day\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"Bye\"</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"See you later\"</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"Goodbye\"</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"Nice chatting to you, bye\"</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"Till next time\"</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     utterance    intent\n",
       "0                   \"Hi there\"  greeting\n",
       "1                \"How are you\"  greeting\n",
       "2           \"Is anyone there?\"  greeting\n",
       "3                      \"Hello\"  greeting\n",
       "4                   \"Good day\"  greeting\n",
       "5                        \"Bye\"   goodbye\n",
       "6              \"See you later\"   goodbye\n",
       "7                    \"Goodbye\"   goodbye\n",
       "8  \"Nice chatting to you, bye\"   goodbye\n",
       "9             \"Till next time\"   goodbye"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intent_full_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d141b8cf-267c-4a3a-8550-2e2dec57bcdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(265, 2)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#temp_intent_df.shape\n",
    "#intent_raw_df.shape\n",
    "intent_full_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff8e6e39-1af2-4068-9f6f-b348e8931279",
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_full_df.to_csv('../data_augmented/intent_full_dataset.csv',index=False) # Write the full, \"original\" intents dataframes to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "47451331-9b4e-4a4b-9d97-4422b391d047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Like above, but this time the responses with their intents\n",
    "\n",
    "temp_response_dict = {}\n",
    "temp_responses = []\n",
    "temp_intents = []\n",
    "for i in intents['intents']:\n",
    "    for j in i['responses']:\n",
    "        temp_intents.append(str(i['tag']))\n",
    "        temp_responses.append(str(j))        \n",
    "temp_response_dict['responses'] = temp_responses\n",
    "temp_response_dict['intent'] = temp_intents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "73c521bd-3213-40a4-9813-812686009531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>responses</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hello, thanks for asking</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good to see you again</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hi there, how can I help?</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>See you!</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Have a nice day</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bye! Come back again soon.</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Happy to help!</td>\n",
       "      <td>thanks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Any time!</td>\n",
       "      <td>thanks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>My pleasure</td>\n",
       "      <td>thanks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sorry, can't understand you</td>\n",
       "      <td>noanswer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     responses    intent\n",
       "0     Hello, thanks for asking  greeting\n",
       "1        Good to see you again  greeting\n",
       "2    Hi there, how can I help?  greeting\n",
       "3                     See you!   goodbye\n",
       "4              Have a nice day   goodbye\n",
       "5   Bye! Come back again soon.   goodbye\n",
       "6               Happy to help!    thanks\n",
       "7                    Any time!    thanks\n",
       "8                  My pleasure    thanks\n",
       "9  Sorry, can't understand you  noanswer"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_response_df = pd.DataFrame.from_dict(temp_response_dict) # Convert the responses dict to a dataframe\n",
    "temp_response_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e2454e91-56ce-413d-ab5a-4c2be05c3289",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_response_df.to_csv('../data_raw/responses_dataset.csv') # Write the original responses to a dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bf6a62-67f3-44b2-a995-6d1a3d3e1d2e",
   "metadata": {},
   "source": [
    "# Augment the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4586f597-ad93-4698-a5f0-8949aa659cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textattack in /home/mist861/anaconda3/lib/python3.11/site-packages (0.3.10)\n",
      "Requirement already satisfied: bert-score>=0.3.5 in /home/mist861/anaconda3/lib/python3.11/site-packages (from textattack) (0.3.13)\n",
      "Requirement already satisfied: editdistance in /home/mist861/anaconda3/lib/python3.11/site-packages (from textattack) (0.8.1)\n",
      "Requirement already satisfied: flair in /home/mist861/anaconda3/lib/python3.11/site-packages (from textattack) (0.13.1)\n",
      "Requirement already satisfied: filelock in /home/mist861/anaconda3/lib/python3.11/site-packages (from textattack) (3.9.0)\n",
      "Requirement already satisfied: language-tool-python in /home/mist861/anaconda3/lib/python3.11/site-packages (from textattack) (2.8)\n",
      "Requirement already satisfied: lemminflect in /home/mist861/anaconda3/lib/python3.11/site-packages (from textattack) (0.2.3)\n",
      "Requirement already satisfied: lru-dict in /home/mist861/anaconda3/lib/python3.11/site-packages (from textattack) (1.3.0)\n",
      "Requirement already satisfied: datasets>=2.4.0 in /home/mist861/anaconda3/lib/python3.11/site-packages (from textattack) (2.12.0)\n",
      "Requirement already satisfied: nltk in /home/mist861/anaconda3/lib/python3.11/site-packages (from textattack) (3.8.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /home/mist861/anaconda3/lib/python3.11/site-packages (from textattack) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /home/mist861/anaconda3/lib/python3.11/site-packages (from textattack) (1.5.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /home/mist861/anaconda3/lib/python3.11/site-packages (from textattack) (1.10.1)\n",
      "Requirement already satisfied: torch!=1.8,>=1.7.0 in /home/mist861/anaconda3/lib/python3.11/site-packages (from textattack) (2.3.1)\n",
      "Requirement already satisfied: transformers>=4.30.0 in /home/mist861/anaconda3/lib/python3.11/site-packages (from textattack) (4.42.3)\n",
      "Requirement already satisfied: terminaltables in /home/mist861/anaconda3/lib/python3.11/site-packages (from textattack) (3.1.10)\n",
      "Requirement already satisfied: tqdm in /home/mist861/anaconda3/lib/python3.11/site-packages (from textattack) (4.65.0)\n",
      "Requirement already satisfied: word2number in /home/mist861/anaconda3/lib/python3.11/site-packages (from textattack) (1.1)\n",
      "Requirement already satisfied: num2words in /home/mist861/anaconda3/lib/python3.11/site-packages (from textattack) (0.5.13)\n",
      "Requirement already satisfied: more-itertools in /home/mist861/anaconda3/lib/python3.11/site-packages (from textattack) (10.3.0)\n",
      "Requirement already satisfied: pinyin>=0.4.0 in /home/mist861/anaconda3/lib/python3.11/site-packages (from textattack) (0.4.0)\n",
      "Requirement already satisfied: jieba in /home/mist861/anaconda3/lib/python3.11/site-packages (from textattack) (0.42.1)\n",
      "Requirement already satisfied: OpenHowNet in /home/mist861/anaconda3/lib/python3.11/site-packages (from textattack) (2.0)\n",
      "Requirement already satisfied: requests in /home/mist861/anaconda3/lib/python3.11/site-packages (from bert-score>=0.3.5->textattack) (2.32.3)\n",
      "Requirement already satisfied: matplotlib in /home/mist861/anaconda3/lib/python3.11/site-packages (from bert-score>=0.3.5->textattack) (3.7.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/mist861/anaconda3/lib/python3.11/site-packages (from bert-score>=0.3.5->textattack) (24.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/mist861/anaconda3/lib/python3.11/site-packages (from datasets>=2.4.0->textattack) (11.0.0)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /home/mist861/anaconda3/lib/python3.11/site-packages (from datasets>=2.4.0->textattack) (0.3.6)\n",
      "Requirement already satisfied: xxhash in /home/mist861/anaconda3/lib/python3.11/site-packages (from datasets>=2.4.0->textattack) (2.0.2)\n",
      "Requirement already satisfied: multiprocess in /home/mist861/anaconda3/lib/python3.11/site-packages (from datasets>=2.4.0->textattack) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /home/mist861/anaconda3/lib/python3.11/site-packages (from datasets>=2.4.0->textattack) (2024.6.0)\n",
      "Requirement already satisfied: aiohttp in /home/mist861/anaconda3/lib/python3.11/site-packages (from datasets>=2.4.0->textattack) (3.9.5)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /home/mist861/anaconda3/lib/python3.11/site-packages (from datasets>=2.4.0->textattack) (0.23.4)\n",
      "Requirement already satisfied: responses<0.19 in /home/mist861/anaconda3/lib/python3.11/site-packages (from datasets>=2.4.0->textattack) (0.13.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/mist861/anaconda3/lib/python3.11/site-packages (from datasets>=2.4.0->textattack) (6.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/mist861/anaconda3/lib/python3.11/site-packages (from pandas>=1.0.1->textattack) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/mist861/anaconda3/lib/python3.11/site-packages (from pandas>=1.0.1->textattack) (2023.3.post1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/mist861/anaconda3/lib/python3.11/site-packages (from torch!=1.8,>=1.7.0->textattack) (4.12.2)\n",
      "Requirement already satisfied: sympy in /home/mist861/anaconda3/lib/python3.11/site-packages (from torch!=1.8,>=1.7.0->textattack) (1.11.1)\n",
      "Requirement already satisfied: networkx in /home/mist861/anaconda3/lib/python3.11/site-packages (from torch!=1.8,>=1.7.0->textattack) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/mist861/anaconda3/lib/python3.11/site-packages (from torch!=1.8,>=1.7.0->textattack) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/mist861/anaconda3/lib/python3.11/site-packages (from torch!=1.8,>=1.7.0->textattack) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/mist861/anaconda3/lib/python3.11/site-packages (from torch!=1.8,>=1.7.0->textattack) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/mist861/anaconda3/lib/python3.11/site-packages (from torch!=1.8,>=1.7.0->textattack) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/mist861/anaconda3/lib/python3.11/site-packages (from torch!=1.8,>=1.7.0->textattack) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/mist861/anaconda3/lib/python3.11/site-packages (from torch!=1.8,>=1.7.0->textattack) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/mist861/anaconda3/lib/python3.11/site-packages (from torch!=1.8,>=1.7.0->textattack) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/mist861/anaconda3/lib/python3.11/site-packages (from torch!=1.8,>=1.7.0->textattack) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/mist861/anaconda3/lib/python3.11/site-packages (from torch!=1.8,>=1.7.0->textattack) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/mist861/anaconda3/lib/python3.11/site-packages (from torch!=1.8,>=1.7.0->textattack) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/mist861/anaconda3/lib/python3.11/site-packages (from torch!=1.8,>=1.7.0->textattack) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/mist861/anaconda3/lib/python3.11/site-packages (from torch!=1.8,>=1.7.0->textattack) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.1 in /home/mist861/anaconda3/lib/python3.11/site-packages (from torch!=1.8,>=1.7.0->textattack) (2.3.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/mist861/anaconda3/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch!=1.8,>=1.7.0->textattack) (12.5.40)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/mist861/anaconda3/lib/python3.11/site-packages (from transformers>=4.30.0->textattack) (2024.5.15)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/mist861/anaconda3/lib/python3.11/site-packages (from transformers>=4.30.0->textattack) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/mist861/anaconda3/lib/python3.11/site-packages (from transformers>=4.30.0->textattack) (0.19.1)\n",
      "Requirement already satisfied: boto3>=1.20.27 in /home/mist861/anaconda3/lib/python3.11/site-packages (from flair->textattack) (1.34.127)\n",
      "Requirement already satisfied: bpemb>=0.3.2 in /home/mist861/anaconda3/lib/python3.11/site-packages (from flair->textattack) (0.3.5)\n",
      "Requirement already satisfied: conllu>=4.0 in /home/mist861/anaconda3/lib/python3.11/site-packages (from flair->textattack) (4.5.3)\n",
      "Requirement already satisfied: deprecated>=1.2.13 in /home/mist861/anaconda3/lib/python3.11/site-packages (from flair->textattack) (1.2.14)\n",
      "Requirement already satisfied: ftfy>=6.1.0 in /home/mist861/anaconda3/lib/python3.11/site-packages (from flair->textattack) (6.2.0)\n",
      "Requirement already satisfied: gdown>=4.4.0 in /home/mist861/anaconda3/lib/python3.11/site-packages (from flair->textattack) (5.2.0)\n",
      "Requirement already satisfied: gensim>=4.2.0 in /home/mist861/anaconda3/lib/python3.11/site-packages (from flair->textattack) (4.3.0)\n",
      "Requirement already satisfied: janome>=0.4.2 in /home/mist861/anaconda3/lib/python3.11/site-packages (from flair->textattack) (0.5.0)\n",
      "Requirement already satisfied: langdetect>=1.0.9 in /home/mist861/anaconda3/lib/python3.11/site-packages (from flair->textattack) (1.0.9)\n",
      "Requirement already satisfied: lxml>=4.8.0 in /home/mist861/anaconda3/lib/python3.11/site-packages (from flair->textattack) (4.9.3)\n",
      "Requirement already satisfied: mpld3>=0.3 in /home/mist861/anaconda3/lib/python3.11/site-packages (from flair->textattack) (0.5.10)\n",
      "Requirement already satisfied: pptree>=3.1 in /home/mist861/anaconda3/lib/python3.11/site-packages (from flair->textattack) (3.1)\n",
      "Requirement already satisfied: pytorch-revgrad>=0.2.0 in /home/mist861/anaconda3/lib/python3.11/site-packages (from flair->textattack) (0.2.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /home/mist861/anaconda3/lib/python3.11/site-packages (from flair->textattack) (1.5.0)\n",
      "Requirement already satisfied: segtok>=1.5.11 in /home/mist861/anaconda3/lib/python3.11/site-packages (from flair->textattack) (1.5.11)\n",
      "Requirement already satisfied: sqlitedict>=2.0.0 in /home/mist861/anaconda3/lib/python3.11/site-packages (from flair->textattack) (2.1.0)\n",
      "Requirement already satisfied: tabulate>=0.8.10 in /home/mist861/anaconda3/lib/python3.11/site-packages (from flair->textattack) (0.8.10)\n",
      "Requirement already satisfied: transformer-smaller-training-vocab>=0.2.3 in /home/mist861/anaconda3/lib/python3.11/site-packages (from flair->textattack) (0.4.0)\n",
      "Collecting urllib3<2.0.0,>=1.0.0 (from flair->textattack)\n",
      "  Obtaining dependency information for urllib3<2.0.0,>=1.0.0 from https://files.pythonhosted.org/packages/ae/6a/99eaaeae8becaa17a29aeb334a18e5d582d873b6f084c11f02581b8d7f7f/urllib3-1.26.19-py2.py3-none-any.whl.metadata\n",
      "  Using cached urllib3-1.26.19-py2.py3-none-any.whl.metadata (49 kB)\n",
      "Requirement already satisfied: wikipedia-api>=0.5.7 in /home/mist861/anaconda3/lib/python3.11/site-packages (from flair->textattack) (0.6.0)\n",
      "Requirement already satisfied: semver<4.0.0,>=3.0.0 in /home/mist861/anaconda3/lib/python3.11/site-packages (from flair->textattack) (3.0.2)\n",
      "Requirement already satisfied: pip in /home/mist861/anaconda3/lib/python3.11/site-packages (from language-tool-python->textattack) (23.2.1)\n",
      "Requirement already satisfied: wheel in /home/mist861/anaconda3/lib/python3.11/site-packages (from language-tool-python->textattack) (0.38.4)\n",
      "Requirement already satisfied: click in /home/mist861/anaconda3/lib/python3.11/site-packages (from nltk->textattack) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/mist861/anaconda3/lib/python3.11/site-packages (from nltk->textattack) (1.2.0)\n",
      "Requirement already satisfied: docopt>=0.6.2 in /home/mist861/anaconda3/lib/python3.11/site-packages (from num2words->textattack) (0.6.2)\n",
      "Requirement already satisfied: anytree in /home/mist861/anaconda3/lib/python3.11/site-packages (from OpenHowNet->textattack) (2.12.1)\n",
      "Requirement already satisfied: setuptools in /home/mist861/anaconda3/lib/python3.11/site-packages (from OpenHowNet->textattack) (70.0.0)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.127 in /home/mist861/anaconda3/lib/python3.11/site-packages (from boto3>=1.20.27->flair->textattack) (1.34.127)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/mist861/anaconda3/lib/python3.11/site-packages (from boto3>=1.20.27->flair->textattack) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /home/mist861/anaconda3/lib/python3.11/site-packages (from boto3>=1.20.27->flair->textattack) (0.10.1)\n",
      "Requirement already satisfied: sentencepiece in /home/mist861/anaconda3/lib/python3.11/site-packages (from bpemb>=0.3.2->flair->textattack) (0.2.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /home/mist861/anaconda3/lib/python3.11/site-packages (from deprecated>=1.2.13->flair->textattack) (1.14.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/mist861/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets>=2.4.0->textattack) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/mist861/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets>=2.4.0->textattack) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/mist861/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets>=2.4.0->textattack) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/mist861/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets>=2.4.0->textattack) (6.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/mist861/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets>=2.4.0->textattack) (1.8.1)\n",
      "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /home/mist861/anaconda3/lib/python3.11/site-packages (from ftfy>=6.1.0->flair->textattack) (0.2.13)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/mist861/anaconda3/lib/python3.11/site-packages (from gdown>=4.4.0->flair->textattack) (4.12.3)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/mist861/anaconda3/lib/python3.11/site-packages (from gensim>=4.2.0->flair->textattack) (5.2.1)\n",
      "Requirement already satisfied: FuzzyTM>=0.4.0 in /home/mist861/anaconda3/lib/python3.11/site-packages (from gensim>=4.2.0->flair->textattack) (2.0.9)\n",
      "Requirement already satisfied: six in /home/mist861/anaconda3/lib/python3.11/site-packages (from langdetect>=1.0.9->flair->textattack) (1.16.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/mist861/anaconda3/lib/python3.11/site-packages (from matplotlib->bert-score>=0.3.5->textattack) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/mist861/anaconda3/lib/python3.11/site-packages (from matplotlib->bert-score>=0.3.5->textattack) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/mist861/anaconda3/lib/python3.11/site-packages (from matplotlib->bert-score>=0.3.5->textattack) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/mist861/anaconda3/lib/python3.11/site-packages (from matplotlib->bert-score>=0.3.5->textattack) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/mist861/anaconda3/lib/python3.11/site-packages (from matplotlib->bert-score>=0.3.5->textattack) (9.4.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /home/mist861/anaconda3/lib/python3.11/site-packages (from matplotlib->bert-score>=0.3.5->textattack) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/mist861/anaconda3/lib/python3.11/site-packages (from requests->bert-score>=0.3.5->textattack) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/mist861/anaconda3/lib/python3.11/site-packages (from requests->bert-score>=0.3.5->textattack) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/mist861/anaconda3/lib/python3.11/site-packages (from requests->bert-score>=0.3.5->textattack) (2024.6.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/mist861/anaconda3/lib/python3.11/site-packages (from scikit-learn>=1.0.2->flair->textattack) (3.5.0)\n",
      "Requirement already satisfied: protobuf in /home/mist861/anaconda3/lib/python3.11/site-packages (from transformers>=4.30.0->textattack) (4.21.12)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/mist861/anaconda3/lib/python3.11/site-packages (from jinja2->torch!=1.8,>=1.7.0->textattack) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/mist861/anaconda3/lib/python3.11/site-packages (from sympy->torch!=1.8,>=1.7.0->textattack) (1.3.0)\n",
      "Requirement already satisfied: pyfume in /home/mist861/anaconda3/lib/python3.11/site-packages (from FuzzyTM>=0.4.0->gensim>=4.2.0->flair->textattack) (0.3.4)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /home/mist861/anaconda3/lib/python3.11/site-packages (from transformers>=4.30.0->textattack) (0.32.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/mist861/anaconda3/lib/python3.11/site-packages (from beautifulsoup4->gdown>=4.4.0->flair->textattack) (2.5)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /home/mist861/anaconda3/lib/python3.11/site-packages (from requests->bert-score>=0.3.5->textattack) (1.7.1)\n",
      "Requirement already satisfied: psutil in /home/mist861/anaconda3/lib/python3.11/site-packages (from accelerate>=0.21.0->transformers>=4.30.0->textattack) (5.9.8)\n",
      "Collecting numpy>=1.21.0 (from textattack)\n",
      "  Obtaining dependency information for numpy>=1.21.0 from https://files.pythonhosted.org/packages/22/97/dfb1a31bb46686f09e68ea6ac5c63fdee0d22d7b23b8f3f7ea07712869ef/numpy-1.24.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached numpy-1.24.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: simpful==2.12.0 in /home/mist861/anaconda3/lib/python3.11/site-packages (from pyfume->FuzzyTM>=0.4.0->gensim>=4.2.0->flair->textattack) (2.12.0)\n",
      "Requirement already satisfied: fst-pso==1.8.1 in /home/mist861/anaconda3/lib/python3.11/site-packages (from pyfume->FuzzyTM>=0.4.0->gensim>=4.2.0->flair->textattack) (1.8.1)\n",
      "Requirement already satisfied: miniful in /home/mist861/anaconda3/lib/python3.11/site-packages (from fst-pso==1.8.1->pyfume->FuzzyTM>=0.4.0->gensim>=4.2.0->flair->textattack) (0.0.6)\n",
      "Using cached urllib3-1.26.19-py2.py3-none-any.whl (143 kB)\n",
      "Using cached numpy-1.24.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "Installing collected packages: urllib3, numpy\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.2.2\n",
      "    Uninstalling urllib3-2.2.2:\n",
      "      Successfully uninstalled urllib3-2.2.2\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tables 3.8.0 requires blosc2~=2.0.0, which is not installed.\n",
      "tables 3.8.0 requires cython>=0.29.21, which is not installed.\n",
      "types-requests 2.32.0.20240602 requires urllib3>=2, but you have urllib3 1.26.19 which is incompatible.\n",
      "conda-repo-cli 1.0.75 requires clyent==1.2.1, but you have clyent 1.2.2 which is incompatible.\n",
      "conda-repo-cli 1.0.75 requires nbformat==5.9.2, but you have nbformat 5.10.4 which is incompatible.\n",
      "conda-repo-cli 1.0.75 requires python-dateutil==2.8.2, but you have python-dateutil 2.9.0.post0 which is incompatible.\n",
      "conda-repo-cli 1.0.75 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n",
      "semantic-router 0.0.50 requires numpy<2.0.0,>=1.25.2, but you have numpy 1.24.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.24.4 urllib3-1.26.19\n"
     ]
    }
   ],
   "source": [
    "!pip install textattack # For text augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "fca522e3-709d-4e17-904e-442084e35d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textattack.augmentation import EmbeddingAugmenter, CharSwapAugmenter # For text augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "4c4d5d51-c77a-4dd5-9be4-90e6a7b1b7e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Hiya there\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"H there\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Mode are you\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"HYw are you\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Is everyone there?\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"Is anyon there?\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"Ahoy\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"Healo\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"Alright day\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"GoSod day\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              utterance    intent\n",
       "0          \"Hiya there\"  greeting\n",
       "1             \"H there\"  greeting\n",
       "2        \"Mode are you\"  greeting\n",
       "3         \"HYw are you\"  greeting\n",
       "4  \"Is everyone there?\"  greeting\n",
       "5     \"Is anyon there?\"  greeting\n",
       "6                \"Ahoy\"  greeting\n",
       "7               \"Healo\"  greeting\n",
       "8         \"Alright day\"  greeting\n",
       "9           \"GoSod day\"  greeting"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For all of the current utterances, create both an easy augment and a swap augment utterance, effectively tripling the number of utterances\n",
    "\n",
    "augmented_intents = {'utterance':[],'intent':[]}\n",
    "emb_aug = EmbeddingAugmenter()\n",
    "swap_aug = CharSwapAugmenter()\n",
    "for intent in intent_full_df['intent'].unique():\n",
    "    temp_df = intent_full_df.loc[intent_full_df['intent'] == intent]\n",
    "    for utterance in temp_df['utterance']:\n",
    "        augmented_intents['utterance'].extend([emb_aug.augment(utterance)[0],swap_aug.augment(utterance)[0]])\n",
    "        augmented_intents['intent'].extend([intent,intent])\n",
    "intent_augmented_df = pd.DataFrame.from_dict(augmented_intents)\n",
    "intent_augmented_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9b447f2c-9ac0-47dd-88de-fd10ca149efe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(530, 2)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intent_augmented_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "cd22fcc2-7d4f-4e25-b89f-6ecf17610f6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(795, 2)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intent_augmented_full_df = pd.concat([intent_full_df,intent_augmented_df],axis=0) # Combine the original and augmented utterances\n",
    "intent_augmented_full_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "78962dbc-ec68-4bf0-905b-d9499beeb44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_augmented_full_df.to_csv('../data_augmented/intent_augmented_dataset.csv',index=False) # Write the combined utterances to a csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16c0dbe-62b3-4755-91cd-a83ced04afc4",
   "metadata": {},
   "source": [
    "Please note that the \"responses_augmented_data.csv\" file was created by simplifying/modifying responses_dataset.csv manually."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939daff2-2fec-4c6a-8423-6cdb5e05d6c8",
   "metadata": {},
   "source": [
    "## Dataset Load and Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "921b9db6-bc02-4504-905e-757d14bbaddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /home/mist861/anaconda3/lib/python3.11/site-packages (1.5.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /home/mist861/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/mist861/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/mist861/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/mist861/anaconda3/lib/python3.11/site-packages (from scikit-learn) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U scikit-learn # For dataset splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79af57ef-2210-4065-8898-543d6a5d2c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split # For dataset splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4634bb81-9a42-4c79-9690-4a13e5ea0dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_df = pd.read_csv('../data_augmented/intent_augmented_dataset.csv') # Load the augmented utterances/intents dataset, created above (so that it doesn't need to be generated every time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db7a39ad-0de3-4f83-a7da-0cd4fd9be34d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Hi there\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"How are you\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Is anyone there?\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Hello\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Good day\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"Bye\"</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"See you later\"</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"Goodbye\"</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"Nice chatting to you, bye\"</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"Till next time\"</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     utterance    intent\n",
       "0                   \"Hi there\"  greeting\n",
       "1                \"How are you\"  greeting\n",
       "2           \"Is anyone there?\"  greeting\n",
       "3                      \"Hello\"  greeting\n",
       "4                   \"Good day\"  greeting\n",
       "5                        \"Bye\"   goodbye\n",
       "6              \"See you later\"   goodbye\n",
       "7                    \"Goodbye\"   goodbye\n",
       "8  \"Nice chatting to you, bye\"   goodbye\n",
       "9             \"Till next time\"   goodbye"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intent_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8eeea33-e482-4bb7-8958-92a075611eaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(795, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intent_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bd59a8b-fa46-4e28-926e-5e7291e2b600",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = intent_df['utterance'] # Create X\n",
    "y = intent_df['intent'] # Create Y\n",
    "X_train_df, X_test_df, y_train_df, y_test_df = train_test_split(X, y, random_state=42, test_size=0.2, shuffle=True) # Split X and Y into test and train datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82fd95d2-a610-4484-9460-ccdb854026e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.concat([X_test_df,y_test_df],axis=1) # Recombine the X and y test datasets, for portability\n",
    "train_df = pd.concat([X_train_df,y_train_df],axis=1) # Recombine the X and y train datasets, for portability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d92908a-2a68-4239-978d-6eb304a775b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>\"Could you get my prescription poised for me?\"</td>\n",
       "      <td>medication</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>\"Search for hospitals with uregnt care services.\"</td>\n",
       "      <td>hospital_search</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>\"Hey, good to see you!\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>\"What are my blood pressure tier?\"</td>\n",
       "      <td>blood_pressure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>\"Bye!\"</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>\"I needed the attention of a doctor.\"</td>\n",
       "      <td>doctor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>\"Im' grateful.\"</td>\n",
       "      <td>thanks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>\"I'd like to order a new batch of my medicines.\"</td>\n",
       "      <td>medication</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>\"Whatis the verdict on my blood pressure today?\"</td>\n",
       "      <td>blood_pressure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>\"Where can I bu over-the-counter medications?\"</td>\n",
       "      <td>pharmacy_search</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             utterance           intent\n",
       "691     \"Could you get my prescription poised for me?\"       medication\n",
       "662  \"Search for hospitals with uregnt care services.\"  hospital_search\n",
       "63                             \"Hey, good to see you!\"         greeting\n",
       "531                 \"What are my blood pressure tier?\"   blood_pressure\n",
       "66                                              \"Bye!\"          goodbye\n",
       "749              \"I needed the attention of a doctor.\"           doctor\n",
       "382                                    \"Im' grateful.\"           thanks\n",
       "683   \"I'd like to order a new batch of my medicines.\"       medication\n",
       "554   \"Whatis the verdict on my blood pressure today?\"   blood_pressure\n",
       "624     \"Where can I bu over-the-counter medications?\"  pharmacy_search"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59ebeb94-9533-42c5-884c-2d0c3f1d21c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>\"Goodnighl!\"</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>\"I have digestive issues such as bloating or i...</td>\n",
       "      <td>symptoms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>\"Whaut do you specialize in?\"</td>\n",
       "      <td>options</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>\"gye!\"</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>\"What are the risks or drawbacs of this medica...</td>\n",
       "      <td>adverse_drug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>\"Thnk you\"</td>\n",
       "      <td>thanks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>\"See you soon!\"</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>\"What are my blood pressure levels?\"</td>\n",
       "      <td>blood_pressure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>\"How is my blood pressure search today?\"</td>\n",
       "      <td>blood_pressure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>\"I'm appreciate.\"</td>\n",
       "      <td>thanks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             utterance          intent\n",
       "360                                       \"Goodnighl!\"         goodbye\n",
       "264  \"I have digestive issues such as bloating or i...        symptoms\n",
       "440                      \"Whaut do you specialize in?\"         options\n",
       "328                                             \"gye!\"         goodbye\n",
       "486  \"What are the risks or drawbacs of this medica...    adverse_drug\n",
       "368                                         \"Thnk you\"          thanks\n",
       "79                                     \"See you soon!\"         goodbye\n",
       "148               \"What are my blood pressure levels?\"  blood_pressure\n",
       "529           \"How is my blood pressure search today?\"  blood_pressure\n",
       "381                                  \"I'm appreciate.\"          thanks"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41d7268b-bee1-4db4-8c0f-cebdc453d91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_df = intent_new_df = pd.read_csv('../data_augmented/responses_dataset_augmented.csv') # Load the augmented response dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34e42d8-d40b-441f-a556-9632a7bfa33c",
   "metadata": {},
   "source": [
    "# RAG Intent Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "83475981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/mist861/anaconda3/lib/python3.11/site-packages (2.3.1)\n",
      "Requirement already satisfied: filelock in /home/mist861/anaconda3/lib/python3.11/site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/mist861/anaconda3/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /home/mist861/anaconda3/lib/python3.11/site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in /home/mist861/anaconda3/lib/python3.11/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/mist861/anaconda3/lib/python3.11/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/mist861/anaconda3/lib/python3.11/site-packages (from torch) (2024.6.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/mist861/anaconda3/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/mist861/anaconda3/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/mist861/anaconda3/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/mist861/anaconda3/lib/python3.11/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/mist861/anaconda3/lib/python3.11/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/mist861/anaconda3/lib/python3.11/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/mist861/anaconda3/lib/python3.11/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/mist861/anaconda3/lib/python3.11/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/mist861/anaconda3/lib/python3.11/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/mist861/anaconda3/lib/python3.11/site-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/mist861/anaconda3/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.1 in /home/mist861/anaconda3/lib/python3.11/site-packages (from torch) (2.3.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/mist861/anaconda3/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.40)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/mist861/anaconda3/lib/python3.11/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/mist861/anaconda3/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: transformers in /home/mist861/anaconda3/lib/python3.11/site-packages (4.42.4)\n",
      "Requirement already satisfied: filelock in /home/mist861/anaconda3/lib/python3.11/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/mist861/anaconda3/lib/python3.11/site-packages (from transformers) (0.23.4)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17 in /home/mist861/anaconda3/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/mist861/anaconda3/lib/python3.11/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/mist861/anaconda3/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/mist861/anaconda3/lib/python3.11/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in /home/mist861/anaconda3/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/mist861/anaconda3/lib/python3.11/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/mist861/anaconda3/lib/python3.11/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/mist861/anaconda3/lib/python3.11/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/mist861/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/mist861/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/mist861/anaconda3/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/mist861/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/mist861/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/mist861/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2024.6.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U torch # For running LLMs\n",
    "!pip install -U transformers # For running LLMs/encoders.\n",
    "!pip install -qU \"semantic-router[local]\" # For the RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a8f807d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch # For running LLMs\n",
    "from semantic_router import Route # For RAG\n",
    "from semantic_router import RouteLayer # For RAG\n",
    "from semantic_router.encoders import HuggingFaceEncoder # For encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce12466d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_device(\"cuda\")\n",
    "\n",
    "# semantic_router USED to need the below, but doesn't anymore?\n",
    "\n",
    "#model = AutoModelForCausalLM.from_pretrained('microsoft/phi-1_5', torch_dtype='auto')\n",
    "#tokenizer = AutoTokenizer.from_pretrained('microsoft/phi-1_5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3aa21ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Route(name='goodbye', utterances=['\"Goodnighl!\"', '\"gye!\"', '\"See you soon!\"', '\"Adios\"', '\"Tranquil out!\"', '\"Take care!\"', '\"Farewell!\"', '\"Goodnight!\"', '\"See you later\"', '\"Until next time!\"', '\"bBye\"', '\"Seeing ya!\"', '\"Bye-bxye!\"', '\"Take it simple!\"', '\"See you nearly!\"', '\"Take caring!\"', '\"Have a good one!\"', '\"Hello!\"', '\"Have a gogd one!\"', '\"I must be going.\"', '\"Have a great dGay!\"', '\"Take cvare!\"', '\"Until next ltime!\"', '\"Till nnxt time\"', '\"Till next time\"', '\"Catch you lateB!\"', '\"Have a buena one!\"', '\"So long!\"', '\"See ya!\"', '\"Sce you later\"', '\"Bye-bye!\"', '\"Nice chatting to you, hellos\"', '\"See you quickly!\"', '\"GooKbye\"', '\"See you oson!\"', '\"Until impending time!\"', '\"Goodnight!\"', '\"Nicq chatting to you, bye\"', '\"Bye\"', '\"meace out!\"', '\"Nice chatting to you, bye\"', '\"Adiso!\"', '\"Ciao!\"', '\"See you after\"', '\"Se you around!\"', '\"Ciao!\"', '\"Has a good one!\"', '\"Take it easy!\"', '\"Catch you trailing!\"', '\"So largo!\"', '\"Adios\"', '\"I must be go.\"', '\"SeH you later!\"', '\"Have a good one!\"'], description=None, function_schemas=None, llm=None, score_threshold=None), Route(name='symptoms', utterances=['\"I have digestive issues such as bloating or indigestion.\"', '\"I\\'m experiencing diarrhoea.\"', '\"I feel dizzy and liyghtheaded.\"', '\"I have a persistent headache.\"', '\"I have a rash or skin irritation.\"', '\"I have a persistnet headache.\"', '\"I feel highly tired and lethargic.\"', '\"My throat is sore and scratchy.\"', '\"I have chest tightness and discomfort.\"', '\"I feel short of breath.\"', '\"I have digestive issues such as bloating or heartburn.\"', '\"I feel fatigued and weak.\"', '\"I have chest tightness and malay.\"', '\"I feel extremely tired and lethmargic.\"', '\"I\\'m experiencing sensitivity to light/noise.\"', '\"I have digestive issues such as blotaing or indigestion.\"', '\"I have a Yfever and chills.\"', '\"I have a runny nose and crowding.\"', '\"I have a Jash or skin irritation.\"', '\"I\\'m feeling unusually cold or hot.\"', '\"I have a fever and chills.\"', '\"I feel short of ebreath.\"', '\"I\\'m experiencing diarrhea.\"', '\"I feel jaded and weak.\"', '\"I\\'m experiencing sensibility to light/noise.\"', '\"I have chest tighvtness and discomfort.\"', '\"I have abdoinal pain and cramping.\"', '\"My larynx is sore and scratchy.\"', '\"I efel fatigued and weak.\"', '\"I have a runny nose and congestio.\"', '\"I\\'m coughing and whezeing.\"', '\"I\\'m coughing and wheezes.\"', '\"I feel dizzy and lightheaded.\"', '\"I have trouble concentrating or thinking clearly.\"', '\"I\\'m epxeriencing nausea and vomiting.\"', '\"I\\'m experiencing nausea and vomiting.\"', '\"I have muscle aches and pbins.\"', '\"My joints are swollen and painful.\"', '\"I have a eczema or skin irritation.\"', '\"My trhoat is sore and scratchy.\"', '\"I have a fever and shivers.\"', '\"I have belly pain and cramping.\"', '\"I\\'m coughing and wheezing.\"', '\"I\\'m feeling unusually cIold or hot.\"', '\"I\\'m experiencing sensiptivity to light/noise.\"', '\"I feel short of breathe.\"', '\"I have muscle aches and pains.\"', '\"I have muscle pains and pains.\"'], description=None, function_schemas=None, llm=None, score_threshold=None), Route(name='options', utterances=['\"Whaut do you specialize in?\"', '\"Wha are your abilities?\"', '\"Quoi are your competencies?\"', '\"Quoi are your talents?\"', '\"What are your professional capability?\"', '\"Waht are you capable of?\"', '\"What are your dexterity?\"', '\"What are your talents?\"', '\"How you can be helpful?\"', '\"Whta are your proficiencies?\"', '\"What are your skills?\"', '\"What aided is offered\"', '\"What kidn of tasks are you good at?\"', '\"What are your capabilities?\"', '\"What can you do good?\"', '\"How you could help me?\"', '\"uhat are your talents and skills?\"', '\"What skills do you bring to the table?\"', '\"WhaC do you excel at?\"', '\"What are your competencies?\"', '\"Whereof are your strengths?\"', '\"Waht skills do you bring to the table?\"', '\"What can you do well?\"', '\"Whereof can you bring to this project?\"', '\"Waht skills do you have?\"', '\"What do you excel at?\"', '\"What support is offered\"', '\"How you could hel me?\"', '\"What skills do you bring to the tableau?\"', '\"WhaOt can you do well?\"', '\"What kind of tasks are you good at?\"', '\"What help you provide?\"', '\"What are your proficiencies?\"', '\"What you can do?\"', '\"What are your areas of skill?\"', '\"What are your areas of expertise?\"', '\"How you can be actionable?\"', '\"What help you furnishes?\"', '\"What can you bring to this project?\"', '\"WhMt are your strong points?\"', '\"What do you excels at?\"', '\"What can you contribute?\"', '\"What are your technical skills?\"', '\"What are your areas of expertie?\"', '\"How you could support me?\"', '\"What kind of tasks are you alright at?\"', '\"What do you specialize in?\"', '\"What are your technicDal skills?\"', '\"Wat you can do?\"', '\"What can you contributing?\"', '\"What are your talent and skills?\"', '\"What are your abilities?\"', '\"What skill do you have?\"', '\"What can you bring to this porject?\"', '\"What are your techs skills?\"', '\"What are your professional skilJs?\"', '\"What are your professional skills?\"', '\"What skills do you have?\"', '\"Whereof are you capable of?\"'], description=None, function_schemas=None, llm=None, score_threshold=None), Route(name='adverse_drug', utterances=['\"What are the risks or drawbacs of this medication?\"', '\"What are the chances of experiencing side effects with this drug?\"', '\"Are there any common side effects associated with this cure?\"', '\"Could you outline the potential side effects I might encounter?\"', '\"Are there any known side effects I should be concerned about?\"', '\"What are the unintended consequences I might face while picked this medicine?\"', '\"What should I expect in terms of side effects from this medication?\"', '\"What are the risks or gaps of this medication?\"', '\"Are there any complications I should anticipate from using this medication?\"', '\"Are there any negative effects I should watch out for?\"', '\"Can you explain the possble adverse reactions of this medication?\"', '\"Which drugs dont have adverse reaction?\"', '\"Could you lgst the potential drawbacks or downsides of using this drug?\"', '\"Could you list the potential drawbacks or downsides of utilised this drug?\"', '\"Could you outline the potential side impact I might encounter?\"', '\"Are there any known side influencing I should be concerned about?\"', '\"Can you explain the doable adverse reactions of this medication?\"', '\"Are there any adverse effect I should be aware of?\"', '\"Give me a list of drugs causing adverse behavior\"', '\"Is there a chance of experiencing any uninvited effects with this medication?\"', '\"What should I expect in terms of side influence from this medication?\"', '\"What kiSnd of negative reactions should I be prepared for with this drug?\"', '\"What are the potential side effects of this medication?\"', '\"Is there a chance of experiencing any unwanted effects with this medication?\"', '\"What are the possible noxious outcomes of this treatment?\"', '\"Are there any complications I should anticipate from usng this medication?\"', '\"Open unfavourable drugs module\"', '\"Could you detail the side effects that users commonly report?\"', '\"What are the possible adverse outcomes of this treatment?\"', '\"Are there any adverse effects I should be aware of?\"', '\"What kind of answered might I experience from this medication?\"', '\"Can you tell me about the possible side effects of taking this drug?\"', '\"Give me a list of drugs causing adverse bheavior\"', '\"OKpen adverse drugs module\"', '\"Is there a chance of experiencing any unwanteA effects with this medication?\"', '\"Can you tell me about the possible side effdcts of taking this drug?\"', '\"Give me a list of pharmaceuticals causing adverse behavior\"', '\"Can you describes any undesirable effects that could occur?\"', '\"Could you outline the potential side effects I smight encounter?\"', '\"What kind of negative reactions should I be prepared for with this drug?\"', '\"Are there any common side effects associated with this treatment?\"', '\"Wo you detail the side effects that users commonly report?\"', '\"Are there any knvwn side effects I should be concerned about?\"', '\"List all drugs suitable for pQtient with adverse reaction\"', '\"Are there any complications I should anticipate from using this medications?\"', '\"What are the unintended consequences I might face while taking this medicinQe?\"', '\"Can you explain the possible adverse reactions of this medication?\"', '\"Are there any negative consequences I should watch out for?\"', '\"What should I expect in terms of side effects from this medicaton?\"', '\"What are the unintended consequences I might face while taking this medicine?\"', '\"List all pharmaceutical suitable for patient with adverse reaction\"', '\"What kind of reactions might I experience from this medication?\"', '\"What are the chances of experiencing side fefects with this drug?\"', '\"Whgt are the potential side effects of this medication?\"', '\"What are the possible adverse outcomes of this reatment?\"', '\"Are there any common sike effects associated with this treatment?\"', '\"Can you describe any undesirable evfects that could occur?\"', '\"What are the potential side repercussions of this medication?\"', '\"Could you detcail the side effects that users commonly report?\"', '\"Which drugs doct have adverse reaction?\"', '\"Open adverse drugs module\"', '\"What are the chances of witnessing side effects with this drug?\"', '\"What are the risks or drawbacks of this medication?\"', '\"How to chek Adverse drug reaction?\"', '\"How to check Adverse drug reaction?\"'], description=None, function_schemas=None, llm=None, score_threshold=None), Route(name='thanks', utterances=['\"Thnk you\"', '\"I\\'m appreciate.\"', '\"I reVally appreciate it.\"', '\"Thanks a batch!\"', '\"Thanked you!\"', '\"Much required!\"', '\"Thanks a bunch!\"', '\"You\\'re a lifesKver!\"', '\"I caA\\'t thank you enough.\"', '\"That signifies a lot to me.\"', '\"I apprecate your help.\"', '\"Thansk a million!\"', '\"You\\'ve been so kind.\"', '\"Many thanks!\"', '\"Thank you so much!\"', '\"Thank you\"', '\"I\\'m so thankful for [specific gesture or assist].\"', '\"I owe you one.\"', '\"I thankful your help.\"', '\"I\\'m grateful.\"', '\"Thanked you so much!\"', '\"That\\'s handy\"', '\"Astonishing, thanks\"', '\"You have my gratitude.\"', '\"Tha\\'ts helpful\"', '\"I\\'m profoundly thankful.\"', '\"Many thanvs!\"', '\"That\\'s helpful\"', '\"I\\'m thankful for your aid.\"', '\"\\'Im thankful for your support.\"', '\"Much obliged!\"', '\"Tahnks for helping me\"', '\"I\\'m so thankful for [specific gesture or help].\"', '\"Thanked a million!\"', '\"You\\'ve been so kidn.\"', '\"I\\'m deeplry thankful.\"', '\"I\\'n very grateful for your assistance.\"', '\"Thvnks a bunch!\"', '\"Thanks for assistance me\"', '\"That means a ot to me.\"', '\"Than you!\"', '\"Thnk you so much!\"', '\"Thank you!\"', '\"I appreciate your help.\"', '\"I owe you noe.\"', '\"You\\'re a saviour!\"', '\"I\\'m very grateful for your assistance.\"', '\"Yo have my gratitude.\"', '\"ThanTks a lot!\"', '\"I gotta you one.\"', '\"Thanks for helping me\"', '\"I really grateful it.\"', '\"I\\'m very grateful for your helped.\"', '\"Many thanking!\"', '\"Thansk\"', '\"I can\\'t thank you enough.\"', '\"Awesome, thanks\"', '\"I can\\'t appreciation you enough.\"', '\"Thanking a bunch!\"', '\"You\\'ve been so type.\"', '\"Thanks a million!\"', '\"Awesome, xthanks\"', '\"I really appreciate it.\"', '\"That means a lot to me.\"'], description=None, function_schemas=None, llm=None, score_threshold=None), Route(name='blood_pressure', utterances=['\"What are my blood pressure levels?\"', '\"How is my blood pressure search today?\"', '\"Could you let me know my current BP numbers?\"', '\"Chrissakes pressure data entry\"', '\"What should I know about my blood pressure levels right now?\"', '\"I want to log blood pressure results\"', '\"Task related to bloCd pressure\"', '\"What\\'s my systolic/diastolic pressurized right now?\"', '\"What\\'s the status of my blood pressure hoy?\"', '\"How is my blood pressure doing entire?\"', '\"What is my current blood pressure reading?\"', '\"What is my current transfusion pressure reading?\"', '\"Could you let me know my current BP numers?\"', '\"Open transfusion pressure module\"', '\"Coudl you inform me of my blood pressure results?\"', '\"Are there any concerns with my blood pressure readings?\"', '\"Open blood pressure modlue\"', '\"an you tell me what my blood pressure numbers are?\"', '\"Can you give me an refresh on my blood pressure?\"', '\"Could you leaving me know my current BP numbers?\"', '\"How is my blood pressure doing overali?\"', '\"Cjan you give me an update on my blood pressure?\"', '\"Can you told me what my blood pressure numbers are?\"', '\"How does my blood pressure compared to normal levels?\"', '\"What\\'s the status of my blood pressure today?\"', '\"Is my blood pressure Mtable?\"', '\"Do you have the newest reading of my blood pressure?\"', '\"I wants to log blood pressure results\"', '\"Could you check my blood pressure, please?\"', '\"Is my blood pressure within a healthful range?\"', '\"What is my current blood preqssure reading?\"', '\"Open blood pressure module\"', '\"Could you inform me of my blood pressure results?\"', '\"WhaB\\'s my systolic/diastolic pressure right now?\"', '\"Can you provide me with my blood pressure measures?\"', '\"Do you have the latest reading of my blood pressure?\"', '\"Could you check my blohod pressure, please?\"', '\"Task related to blood pressure\"', '\"Can you provide me with my blood pressure measurements?\"', '\"Is my blood pressure within a healthy range?\"', '\"Can you give me an update on my blood pressure?\"', '\"What\\'s my systolic/diastolic pressure right now?\"', '\"oD you have the latest reading of my blood pressure?\"', '\"How is my blood pressure looking today?\"', '\"Can you tell me what my blood pressure numbers are?\"', '\"Have you checekd my blood pressure recently?\"', '\"What\\'s the verdict on my blood pressure today?\"', '\"Blood cpressure data management\"', '\"Is my blood pressure within a healthy rnge?\"', '\"What should I know about my transfusion pressure levels right now?\"', '\"What\\'s the ruling on my blood pressure today?\"', '\"How does my blood pressure compare to normal levesl?\"', '\"Blood pressure data entry\"', '\"BlooW pressure data entry\"', '\"Is my blood pressure stable?\"', '\"How is my blood pressure doing overall?\"', '\"Have you verified my blood pressure recently?\"', '\"Are there any concerns with my chrissakes pressure readings?\"', '\"WThat should I know about my blood pressure levels right now?\"', '\"Are there any concerns with my blood pressure readihgs?\"', '\"Can you rpovide me with my blood pressure measurements?\"', '\"Have you checked my blood pressure recently?\"'], description=None, function_schemas=None, llm=None, score_threshold=None), Route(name='medication', utterances=['\"Could you get my prescription ready for me?\"', '\"Is it possible to get a prescription filled today?\"', '\"Pleasee prepare my medication for me.\"', '\"I need to replenish my supply of medication.\"', '\"Could you dispense my medication?\"', '\"Is it achievable to get a prescription filled today?\"', '\"aCn I get a prescription filled, please?\"', '\"Can I pick up my medication order?\"', '\"May I calls a refill of my prescription, please?\"', '\"Can I get a prescription filling, please?\"', '\"Could I get a reflil on my prescription?\"', '\"Please prepare my medicines for me.\"', '\"Is my medicine available for pickup?\"', '\"CoulK you get my prescription ready for me?\"', '\"I need to rplenish my supply of medication.\"', '\"I\\'d like to request a prescription refill.\"', '\"Mfy I reorder my prescription?\"', '\"May I rearranging my prescription?\"', '\"I need to chose up my medication.\"', '\"Can you preparing my prescription?\"', '\"Can you fill my oprescription for me?\"', '\"Can you prepare my prescription?\"', '\"I\\'m here to collect my prescripgion.\"', '\"Can I pick up my medication edict?\"', '\"I need to picKk up my medication.\"', '\"Is it possible to get a rpescription filled today?\"', '\"May I reorder my prescription?\"', '\"I\\'m here to gather my prescription.\"', '\"CouZld you dispense my medication?\"', '\"Is my medication available for pickup?\"', '\"Can you prepare my prescripEion?\"', '\"I my prescription ready for pickup?\"', '\"Can you fills my prescription for me?\"', '\"I need to pick up my medication.\"', '\"Did I get a refill on my prescription?\"', '\"Could you refill my prescription for me?\"', '\"Could you dispense my medical?\"', '\"I\\'d like to wondering a prescription refill.\"', '\"Can I get a prescription filled, please?\"', '\"I required to refill my medication supply.\"', '\"I need to reill my medication supply.\"', '\"Could I get a refill on my prescription?\"', '\"Vay I request a refill of my prescription, please?\"', '\"Could you filler my prescription for me?\"', '\"Is my prescription prepped for pickup?\"', '\"I\\'m here to collect my prescription.\"', '\"Could you reflil my prescription for me?\"'], description=None, function_schemas=None, llm=None, score_threshold=None), Route(name='greeting', utterances=['\"Yo!\"', '\"How\\'s it oing?\"', '\"Hi, how have you been?\"', '\"Gokod evening!\"', '\"Yao!\"', '\"Bonjour!\"', '\"Hello, good to see you!\"', '\"What\\'s up?\"', '\"Salutatoins!\"', '\"Hiya!\"', '\"Howdy!\"', '\"Nice to see you!\"', '\"Geetings!\"', '\"Hello!\"', '\"Hello\"', '\"Good afteroon!\"', '\"Salut there!\"', '\"Ahoy\"', '\"Saluting!\"', '\"Hi there\"', '\"Hyi there!\"', '\"GoSod day\"', '\"HYw are you\"', '\"Delightful to see you!\"', '\"Wlecome!\"', '\"Hi there!\"', '\"Hey, how are you?\"', '\"HeMy, how are you?\"', '\"Good evening!\"', '\"Hey, good to seGe you!\"', '\"Salut, how have you been?\"', '\"HiMya!\"', '\"Healo\"', '\"Greetings!\"', '\"Salutations!\"', '\"Hepy!\"', '\"Well fulfilled!\"', '\"Hello!\"', '\"Good morning!\"', '\"Well afternoon!\"', '\"What\\'s up?\"', '\"Heh, how are you?\"', '\"Cheerio!\"', '\"Yo!\"', '\"How\\'s it go?\"', '\"Mode are you\"', '\"oGod morning!\"', '\"Good day\"', '\"Hey!\"', '\"Hwody!\"', '\"Welcome!\"', '\"How are you doing today?\"', '\"Greetings!\"', '\"Hey!\"', '\"Is everyone there?\"', '\"How are you\"', '\"Alright day\"', '\"Well met!\"', '\"Mode are you doing today?\"', '\"Hlelo!\"', '\"Nice to dee you!\"', '\"Is anyon there?\"'], description=None, function_schemas=None, llm=None, score_threshold=None), Route(name='pharmacy_search', utterances=['\"Found a 24-hour pharmacy near me.\"', '\"Where can I unearthed a pharmacy?\"', '\"Locate a pharmacy that concedes my insurance.\"', '\"Seach pharmacy\"', '\"Find pharmacies with COVID-19 vaccines.\"', '\"Find pharmacies near me.\"', '\"Pharmacy closed to my location.\"', '\"Locate pharmaHcy\"', '\"Search for pharmacies that deliver.\"', '\"Look for a pharmacy that\\'s open Dlate.\"', '\"Look for a pharmacy that\\'s open late.\"', '\"Where can I acquisition over-the-counter medications?\"', '\"Where is the nearest pharmacy?\"', '\"Searching for pharmacies with flu shots.\"', '\"Search for pharmacies with flu shots.\"', '\"Find pharmacies with drive-thru services.\"', '\"Find drugstores with COVID-19 vaccines.\"', '\"Where can I buy over-the-counter medications?\"', '\"Loctae pharmacies with a pharmacy technician.\"', '\"Unearthed me a pharmacy\"', '\"Search pharmaceutical\"', '\"Where can I find a phrmacy?\"', '\"Find a pharmacy in [town/town].\"', '\"Pharmacies aroTnd here.\"', '\"Pinpoint pharmacy\"', '\"Locate a pharmacy that accepts my insurance.\"', '\"Locate drugstores in [neighborhood].\"', '\"Researching for drugstores nearby.\"', '\"Pharmacies around here.\"', '\"Locate pharmacy\"', '\"Find a 24-hour pharmacy near me.\"', '\"Unearthed pharmacies with drive-thru services.\"', '\"Where can I find a pharmacy?\"', '\"Search for drugstorfs nearby.\"', '\"Where can I fill a prescription nearby?\"', '\"Lists of pharmacies nearby\"', '\"Locate a pharmacy neHarby.\"', '\"Nearby drugstores open now.\"', '\"Find a pharmacy in [city/town].\"', '\"List of pharmacies nearby\"', '\"Where is the nearest phharmacy?\"', '\"Find pPharmacies with drive-thru services.\"', '\"Where can I fill a pFrescription nearby?\"', '\"Find pharmacy\"', '\"Nearby pharmaciOs open now.\"', '\"Find pharmacy near me.\"', '\"Find phramacies near me.\"', '\"Locate pharmacy in [neighborhood].\"', '\"Locate pharmacies with a pharmacy technician.\"', '\"Locating pharmacies with a pharmacy technician.\"', '\"Find pharmacies with COVID-19 vacciens.\"', '\"Where can I fill a prescription neighbour?\"', '\"Gaze for a pharmacy that\\'s open late.\"', '\"Search for pharmacies that make.\"', '\"Find pharmaceutical\"', '\"Find me a pharmacy\"', '\"Search for drugstores nearby.\"', '\"SearAh for pharmacies with flu shots.\"', '\"sharmacy close to my location.\"', '\"Lochate drugstores in [neighborhood].\"', '\"Locate a pharmacy nearby.\"', '\"Locate a pEharmacy that accepts my insurance.\"'], description=None, function_schemas=None, llm=None, score_threshold=None), Route(name='doctor', utterances=['\"Could you help me book an nominated with a doctor?\"', '\"Can you direct me to a doRtor?\"', '\"I need to consult with a merical doctor.\"', '\"I\\'m looking to see a healthcare professional.\"', '\"I require the attentien of a doctor.\"', '\"Can I speak to a healthcare provider?\"', '\"I\\'m looing to see a healthcare professional.\"', '\"I need to speak with a doctor.\"', '\"I would like to reqeust a doctor\\'s appointment.\"', '\"I needed to speak with a doctor.\"', '\"Could you arrange for me to see a medic?\"', '\"May I have a dctor\\'s consultation, please?\"', '\"May I calendars a consultation with a doctor?\"', '\"ps there a doctor available?\"', '\"Is there a octor on duty right now?\"', '\"Is a physician available to see me?\"', '\"Coulnd you arrange for me to see a doctor?\"', '\"May I have a doctor\\'s consultation, please?\"', '\"Could you help me book an appointment with a doctor?\"', '\"Can I make an appointment to see a doctor?\"', '\"I need mediccal assistance from a doctor.\"', '\"Can I make an nominate to see a doctor?\"', '\"Can I speak to a healthcare provideVr?\"', '\"Is a physician available to spee me?\"', '\"I noeed to speak with a doctor.\"', '\"Could I see a doctor, please?\"', '\"May I schedule a consultation with a doctor?\"', '\"Is there a doctor available?\"', '\"Is it possible to meet with a physiian?\"', '\"Is there a physcian I can speak with?\"', '\"Maggio I have a doctor\\'s consultation, please?\"', '\"Can I make an appointment to sbe a doctor?\"', '\"May I schedule a consultation with a doctro?\"', '\"I would like to asks a doctor\\'s appointment.\"', '\"Could you arrange for me to see a doctor?\"', '\"Is there a doctor on duty right now?\"', '\"Are there any doctors in the clinfc/hospital?\"', '\"I need medical supporting from a doctor.\"', '\"Is there a doktor available?\"', '\"I require the attention of a doctor.\"', '\"Can you direct me to a doctor?\"', '\"Is it possible to meet with a physician?\"', '\"Could you helrp me book an appointment with a doctor?\"', '\"Is there a physician I can speak with?\"', '\"I need to consult with a medical doctor.\"', '\"Is there a physician I can talk with?\"'], description=None, function_schemas=None, llm=None, score_threshold=None), Route(name='hospital_search', utterances=['\"Find hospitals with speZcific specialties (e.g., cardiology, pediatrics).\"', '\"Where is the nearest hosital?\"', '\"Look for a hospital that\\'s open 24/7.\"', '\"Look for a hospital that\\'s oKen 24/7.\"', '\"Looking up hospital details\"', '\"Neighbour hospitals open now.\"', '\"Where can I find a hospital?\"', '\"Searching for hospital to transfer patient\"', '\"Locating a hospital nearby.\"', '\"Search for hospitals that delivering telemedicine services.\"', '\"Nearby hospitals opn now.\"', '\"Hospital lookup for patient\"', '\"I want to search hospital data\"', '\"Lookup for hospitals\"', '\"Where can I finyd a hospital emergency room?\"', '\"Locate hospitals with intensive care units (ICU).\"', '\"Search for medical centers surrounding.\"', '\"Hospital close to my location.\"', '\"Unearth an emergency hospital near me.\"', '\"Find an emergency hospital near me.\"', '\"Find hospital with COVID-19 treatment facilities.\"', '\"Hspital lookup for patient\"', '\"Find hospitals near me.\"', '\"Locate hospitals in [neighborhoods].\"', '\"Locate hospitals with intensive healthcare units (ICU).\"', '\"Search for medical centers nearby.\"', '\"Where can I unearthed a hospital emergency room?\"', '\"Hospital around here.\"', '\"Locate hospials in [neighborhood].\"', '\"Searching for hospital to tranUsfer patient\"', '\"Nearby hospitals open now.\"', '\"Locnate a hospital that accepts my insurance.\"', '\"Where is the closest hospital?\"', '\"Lcoate hospitals with intensive care units (ICU).\"', '\"Hospitasl around here.\"', '\"Looking up hospital detils\"', '\"Locate a hospital nearby.\"', '\"Find hospitals with specific specialties (e.g., cardiology, pediatrics).\"', '\"Search for hospitals that offer telemedicine services.\"', '\"I want to search hosptal data\"', '\"Find an emergency hopital near me.\"', '\"Clinic lookup for patient\"', '\"Researching for hospital to transfer patient\"', '\"Wheru can I find a hospital?\"', '\"Where can I found hospitals with surgery facilities?\"', '\"Hopsital close to my location.\"', '\"Where can I find a hospital emergency room?\"', '\"Where can I find hospitals with surgery facilites?\"', '\"Find a hospital in [city/municipal].\"', '\"Lookup for hospital\"', '\"Where is the nearest hospital?\"', '\"Find hospitals with COVID-19 treatment facilities.\"', '\"Search for medical center nearby.\"', '\"Hospitals around here.\"', '\"Find a hospital in [city/town].\"', '\"Frisk for hospitals with urgent care services.\"', '\"Locate a hospital that recognises my insurance.\"'], description=None, function_schemas=None, llm=None, score_threshold=None), Route(name='blood_pressure_search', utterances=['\"Onus patient blood pressure result\"', '\"Show blood pressure esults for patient\"', '\"Exhibition blood pressure results for patient\"', '\"Load patient blod pressure result\"', '\"Find blood pressure reoults by ID\"', '\"Find blood pressure outcomes by ID\"', '\"Load patient blood pressure result\"', '\"I want to browsing for blood pressure result history\"', '\"Find blood pressure results by ID\"', '\"I want to search for bood pressure result history\"'], description=None, function_schemas=None, llm=None, score_threshold=None)]\n"
     ]
    }
   ],
   "source": [
    "# Define the list of routes (intents)\n",
    "\n",
    "routes=[]\n",
    "intents = train_df['intent'].unique()\n",
    "\n",
    "for intent in intents:\n",
    "    temp_df = train_df.loc[train_df['intent'] == intent]\n",
    "    temp_utterances = temp_df['utterance'].tolist()\n",
    "    intent_name = str(intent)\n",
    "    intent_name = Route(\n",
    "        name=intent,\n",
    "        utterances=temp_utterances,\n",
    "        responses=['N/A']\n",
    "    )\n",
    "    routes.append(intent_name)\n",
    "\n",
    "print(routes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7790c411",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = HuggingFaceEncoder() # Define the encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9df52f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rl = RouteLayer(encoder=encoder, routes=routes) # Define the RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e9309a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RouteChoice(name='adverse_drug', function_call=None, similarity_score=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rl(\"Open adverse drugs module\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74a97eca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'blood_pressure_search'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rl(\"search blood pressure\").name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "890bb6aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-07-16 14:05:14 INFO semantic_router.utils.logger Saving route config to ../results/rag_model.json\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "rl.to_json(\"../results/rag_model.json\") # Save the RAG to a json, to be loaded later by streamlit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f6cc3f-d255-4c78-8038-8fbc674160e9",
   "metadata": {},
   "source": [
    "# NN Intent Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebf33074-4783-4080-8544-078b7cea19fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /home/mist861/anaconda3/lib/python3.11/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in /home/mist861/anaconda3/lib/python3.11/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/mist861/anaconda3/lib/python3.11/site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/mist861/anaconda3/lib/python3.11/site-packages (from nltk) (2024.5.15)\n",
      "Requirement already satisfied: tqdm in /home/mist861/anaconda3/lib/python3.11/site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: flask in /home/mist861/anaconda3/lib/python3.11/site-packages (3.0.3)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in /home/mist861/anaconda3/lib/python3.11/site-packages (from flask) (3.0.3)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in /home/mist861/anaconda3/lib/python3.11/site-packages (from flask) (3.1.4)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in /home/mist861/anaconda3/lib/python3.11/site-packages (from flask) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in /home/mist861/anaconda3/lib/python3.11/site-packages (from flask) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in /home/mist861/anaconda3/lib/python3.11/site-packages (from flask) (1.8.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/mist861/anaconda3/lib/python3.11/site-packages (from Jinja2>=3.1.2->flask) (2.1.5)\n",
      "Requirement already satisfied: flask_cors in /home/mist861/anaconda3/lib/python3.11/site-packages (4.0.1)\n",
      "Requirement already satisfied: Flask>=0.9 in /home/mist861/anaconda3/lib/python3.11/site-packages (from flask_cors) (3.0.3)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in /home/mist861/anaconda3/lib/python3.11/site-packages (from Flask>=0.9->flask_cors) (3.0.3)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in /home/mist861/anaconda3/lib/python3.11/site-packages (from Flask>=0.9->flask_cors) (3.1.4)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in /home/mist861/anaconda3/lib/python3.11/site-packages (from Flask>=0.9->flask_cors) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in /home/mist861/anaconda3/lib/python3.11/site-packages (from Flask>=0.9->flask_cors) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in /home/mist861/anaconda3/lib/python3.11/site-packages (from Flask>=0.9->flask_cors) (1.8.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/mist861/anaconda3/lib/python3.11/site-packages (from Jinja2>=3.1.2->Flask>=0.9->flask_cors) (2.1.5)\n",
      "Requirement already satisfied: keras in /home/mist861/anaconda3/lib/python3.11/site-packages (3.4.1)\n",
      "Requirement already satisfied: absl-py in /home/mist861/anaconda3/lib/python3.11/site-packages (from keras) (2.1.0)\n",
      "Requirement already satisfied: numpy in /home/mist861/anaconda3/lib/python3.11/site-packages (from keras) (1.26.4)\n",
      "Requirement already satisfied: rich in /home/mist861/anaconda3/lib/python3.11/site-packages (from keras) (13.7.1)\n",
      "Requirement already satisfied: namex in /home/mist861/anaconda3/lib/python3.11/site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: h5py in /home/mist861/anaconda3/lib/python3.11/site-packages (from keras) (3.11.0)\n",
      "Requirement already satisfied: optree in /home/mist861/anaconda3/lib/python3.11/site-packages (from keras) (0.11.0)\n",
      "Requirement already satisfied: ml-dtypes in /home/mist861/anaconda3/lib/python3.11/site-packages (from keras) (0.3.2)\n",
      "Requirement already satisfied: packaging in /home/mist861/anaconda3/lib/python3.11/site-packages (from keras) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /home/mist861/anaconda3/lib/python3.11/site-packages (from optree->keras) (4.12.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/mist861/anaconda3/lib/python3.11/site-packages (from rich->keras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/mist861/anaconda3/lib/python3.11/site-packages (from rich->keras) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/mist861/anaconda3/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.0)\n",
      "Requirement already satisfied: tensorflow in /home/mist861/anaconda3/lib/python3.11/site-packages (2.17.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/mist861/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/mist861/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /home/mist861/anaconda3/lib/python3.11/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/mist861/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/mist861/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /home/mist861/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/mist861/anaconda3/lib/python3.11/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /home/mist861/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/mist861/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /home/mist861/anaconda3/lib/python3.11/site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/mist861/anaconda3/lib/python3.11/site-packages (from tensorflow) (4.21.12)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/mist861/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /home/mist861/anaconda3/lib/python3.11/site-packages (from tensorflow) (70.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/mist861/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/mist861/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/mist861/anaconda3/lib/python3.11/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/mist861/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/mist861/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.64.1)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in /home/mist861/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.17.0)\n",
      "Requirement already satisfied: keras>=3.2.0 in /home/mist861/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/mist861/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.37.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /home/mist861/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/mist861/anaconda3/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: rich in /home/mist861/anaconda3/lib/python3.11/site-packages (from keras>=3.2.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in /home/mist861/anaconda3/lib/python3.11/site-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /home/mist861/anaconda3/lib/python3.11/site-packages (from keras>=3.2.0->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/mist861/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/mist861/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/mist861/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/mist861/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.6.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/mist861/anaconda3/lib/python3.11/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/mist861/anaconda3/lib/python3.11/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/mist861/anaconda3/lib/python3.11/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/mist861/anaconda3/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/mist861/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.2.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/mist861/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/mist861/anaconda3/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U nltk # For tokenizing and stemming\n",
    "!pip install -U flask # For \n",
    "!pip install -U flask_cors\n",
    "!pip install -U keras # For the NN\n",
    "!pip install -U tensorflow # For the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "899dd2fd-d64f-469f-a4c3-d20d57345c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk # For stemming and tokenizing\n",
    "from nltk.stem.lancaster import LancasterStemmer # for stemming\n",
    "import numpy as np # For numbers/arrays\n",
    "from keras.models import Sequential # For the NN\n",
    "from keras.layers import Dense, Activation, Dropout # For the NN\n",
    "from keras.optimizers import SGD # NOTE: this was originally written with an older version of SGD, so I'm using the legacy version just to implement what they had as they had it\n",
    "import random \n",
    "from flask import Flask, jsonify, request\n",
    "from flask_cors import CORS, cross_origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d34d4a4-c27e-4ad6-a56d-76466efc965e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.set_visible_devices([], 'GPU') # For resonas beyond my comprehension, the NN decided to explode when using the GPU the literal last time I tried to use it. So I disabled its GPU access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d9ab86d-70b5-42c1-8538-e6b648f99ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/mist861/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = LancasterStemmer() # Define the stemmer\n",
    "nltk.download('punkt') # Download the punkt NLTK module for tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d11fd030-1247-4284-92ef-93b6f12ad477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636 documents\n",
      "12 intents ['adverse_drug', 'blood_pressure', 'blood_pressure_search', 'doctor', 'goodbye', 'greeting', 'hospital_search', 'medication', 'options', 'pharmacy_search', 'symptoms', 'thanks']\n",
      "663 unique stemmed words ['!', \"''\", \"'d\", \"'im\", \"'m\", \"'re\", \"'s\", \"'ve\", '(', ')', ',', '.', '24-hour', '24/7', '[', ']', '``', 'a', 'abdoin', 'abl', 'about', 'acceiv', 'ach', 'achiev', 'acn', 'acquisit', 'act', 'adio', 'adiso', 'advers', 'aft', 'afternoon', 'afteroon', 'ahoy', 'aid', 'al', 'alright', 'an', 'and', 'answ', 'anticip', 'any', 'anyon', 'appoint', 'apprec', 'apprecy', 'ar', 'area', 'arotnd', 'around', 'arrang', 'as', 'ask', 'assist', 'assocy', 'aston', 'at', 'attenty', 'avail', 'aw', 'awesom', 'batch', 'bby', 'be', 'been', 'behavy', 'bel', 'bheavy', 'blo', 'blocd', 'blod', 'blohod', 'blood', 'bloow', 'blota', 'bonjo', 'bood', 'book', 'bp', 'brea', 'breath', 'bring', 'brows', 'buen', 'bunch', 'buy', 'by', 'bye', 'bye-bxy', 'bye-by', 'ca', \"caa't\", 'cal', 'calend', 'can', 'cap', 'car', 'cardiolog', 'catch', 'caus', 'cent', 'chant', 'chat', 'checekd', 'check', 'cheerio', 'chek', 'chest', 'chil', 'chos', 'chrissakes', 'ciao', 'ciold', 'city/municipal', 'city/town', 'cjan', 'clear', 'clin', 'clinfc/hospital', 'clos', 'closest', 'cold', 'collect', 'common', 'comp', 'compet', 'comply', 'concern', 'congestio', 'consequ', 'consult', 'cont', 'contribut', 'coudl', 'cough', 'could', 'coulk', 'coulnd', 'couzld', 'covid-19', 'cpressure', 'cramp', 'crowd', 'cur', 'cvar', 'dat', 'day', 'dctor', 'dee', 'deeplry', 'del', 'delight', 'describ', 'detail', 'detcail', 'detil', 'dext', 'dgay', 'diarrhe', 'diarrhoe', 'did', 'digest', 'direct', 'discomfort', 'dispens', 'dizzy', 'dlat', 'do', 'doabl', 'doct', 'doctro', 'doe', 'doing', 'dokt', 'dont', 'dort', 'downsid', 'drawbac', 'drawback', 'drive-thru', 'drug', 'drugst', 'drugstorf', 'duty', 'e.g.', 'easy', 'ebrea', 'eczem', 'edict', 'efel', 'effdct', 'effect', 'emerg', 'encount', 'enough', 'entir', 'entry', 'epxery', 'esult', 'ev', 'everyon', 'evfect', 'excel', 'exhibit', 'expect', 'expert', 'experty', 'expery', 'explain', 'extrem', 'fac', 'facil', 'facilit', 'farewel', 'fatigu', 'feel', 'fefect', 'fev', 'fil', 'find', 'finyd', 'flu', 'for', 'found', 'frisk', 'from', 'fulfil', 'furn', 'gap', 'gath', 'gaz', 'geet', 'gest', 'get', 'giv', 'go', 'gogd', 'going', 'gokod', 'good', 'goodnighl', 'goodnight', 'gookby', 'gosod', 'got', 'grat', 'gratitud', 'gre', 'greet', 'gye', 'handy', 'has', 'hav', 'headach', 'healo', 'health', 'healthc', 'healthy', 'heartburn', 'heh', 'hel', 'hello', 'help', 'helrp', 'hemy', 'hepy', 'her', 'hey', 'hi', 'high', 'himy', 'hist', 'hiy', 'hlelo', 'hopit', 'hopsit', 'hosit', 'hosp', 'hospit', 'hospitasl', 'hospt', 'hot', 'how', 'howdy', 'hoy', 'hspital', 'hwody', 'hyi', 'hyw', 'i', \"i'n\", 'icu', 'id', 'impact', 'impend', 'in', 'indigest', 'influ', 'inform', 'ins', 'intend', 'irrit', 'is', 'issu', 'it', 'jad', 'jash', 'joint', 'kidn', 'kind', 'kisnd', 'know', 'known', 'knvwn', 'largo', 'larynx', 'lat', 'lateb', 'latest', 'lco', 'leav', 'let', 'letharg', 'lethmarg', 'level', 'levesl', 'lgst', 'lifeskv', 'light/noise', 'lighthead', 'lik', 'list', 'liyghthead', 'load', 'loc', 'loch', 'locn', 'locta', 'log', 'long', 'loo', 'look', 'lookup', 'lot', 'ltim', 'maggio', 'mak', 'malay', 'man', 'many', 'may', 'me', 'meac', 'mean', 'meas', 'med', 'medicaton', 'medicc', 'medicin', 'medicinq', 'meet', 'mer', 'met', 'mfy', 'might', 'mil', 'mod', 'modlu', 'morn', 'mtabl', 'much', 'musc', 'must', 'my', \"n't\", 'nause', 'near', 'nearby', 'nearest', 'nee', 'neg', 'neharby', 'neighb', 'neighbo', 'newest', 'next', 'nic', 'nicq', 'nnxt', 'noe', 'noee', 'nomin', 'norm', 'nos', 'now', 'noxy', 'num', 'numb', 'oblig', 'occ', 'oct', 'od', 'of', 'off', 'ogod', 'oing', 'ok', 'okp', 'on', 'op', 'opn', 'oprescrib', 'or', 'ord', 'oson', 'ot', 'out', 'outcom', 'outlin', 'over-the-count', 'overal', 'ow', 'pain', 'paty', 'pbin', 'pedy', 'peharm', 'persist', 'persistnet', 'pfrescription', 'pharm', 'pharmaceut', 'pharmacio', 'pharmahcy', 'phharmacy', 'phramacies', 'phrmacy', 'phys', 'physc', 'physy', 'pick', 'pickk', 'pickup', 'pinpoint', 'pleas', 'point', 'porject', 'poss', 'possbl', 'pot', 'ppharmacies', 'pqtient', 'prep', 'preqss', 'prescrib', 'prescrip', 'prescripg', 'press', 'profess', 'proficy', 'profound', 'project', 'provid', 'providevr', 'ps', 'quick', 'quo', 'rang', 'rash', 'react', 'read', 'readihg', 'ready', 'real', 'rearrang', 'reat', 'rec', 'recogn', 'refil', 'reflil', 'refresh', 'reil', 'rel', 'reord', 'reoult', 'repercuss', 'repl', 'report', 'reqeust', 'request', 'requir', 'research', 'result', 'rev', 'right', 'risk', 'rnge', 'room', 'rpescrib', 'rplenish', 'rpovid', 'rul', 'runny', 'salut', 'salutatoin', 'savio', 'sbe', 'sce', 'schedule', 'scratchy', 'se', 'seach', 'searah', 'search', 'see', 'seg', 'seh', 'sens', 'sensipt', 'sensit', 'serv', 'sharm', 'shiv', 'short', 'shot', 'should', 'show', 'sid', 'sign', 'sik', 'simpl', 'skil', 'skils', 'skin', 'smight', 'so', 'soon', 'sor', 'spe', 'speak', 'spec', 'special', 'spezc', 'stabl', 'stat', 'strengths', 'strong', 'such', 'suit', 'supply', 'support', 'surgery', 'surround', 'swol', 'systolic/diastol', 'ta', 'tabl', 'tableau', 'tahnk', 'tak', 'tal', 'talk', 'task', 'tech', 'techn', 'technicd', 'tel', 'telemedicin', 'term', \"tha'ts\", 'than', 'thank', 'thansk', 'thantk', 'thanv', 'that', 'the', 'ther', 'thi', 'think', 'thnk', 'throat', 'thvnks', 'tight', 'tighvt', 'til', 'tim', 'tir', 'to', 'today', 'told', 'town/town', 'trail', 'tranquil', 'transf', 'transfus', 'tranusf', 'tre', 'trhoat', 'troubl', 'typ', 'uh', 'undesir', 'unear', 'unearth', 'unfavo', 'unintend', 'uninvit', 'unit', 'until', 'unus', 'unw', 'unwante', 'up', 'upd', 'urg', 'us', 'usng', 'util', 'vaccin', 'vaccy', 'vay', 'ver', 'verdict', 'very', 'vomit', 'waht', 'want', 'wat', 'watch', 'weak', 'wel', 'welcom', 'wha', 'whab', 'whac', 'whaot', 'what', 'whaut', 'wheez', 'wher', 'whereof', 'wheru', 'whez', 'whgt', 'which', 'whil', 'whmt', 'whta', 'wit', 'with', 'within', 'wlecom', 'wo', 'wond', 'would', 'wthat', 'xthanks', 'ya', 'yao', 'yfev', 'yo', 'you']\n"
     ]
    }
   ],
   "source": [
    "words = [] # Define an array to hold words\n",
    "#classes = [] # Define an array to hold intents\n",
    "documents = [] # Define an array to hold documents\n",
    "ignore_words = ['?'] # The original katana code ignored specifically ? for some reason?  I just left this in.\n",
    "intents = sorted(list(set(train_df['intent'].unique()))) # Load the set of intents\n",
    "for intent in intents: # loop through each intent\n",
    "    temp_df = train_df.loc[train_df['intent'] == intent] # Create a temporary dataframe to hold only the utterances for the intent\n",
    "    #temp_utterances = temp_df['utterance'].tolist() # Turn the utterances into a list\n",
    "    for pattern in temp_df['utterance']: # For each utterance/pattern\n",
    "        w = nltk.word_tokenize(pattern) # Tokenize each word in the sentence\n",
    "        words.extend(w) # Add the words to the word array\n",
    "        documents.append((w, intent)) # Add the words, along with their respective intent, to the documents array\n",
    "#        if intent not in classes:\n",
    "#            classes.append(intent)\n",
    "\n",
    "words = [stemmer.stem(w.lower()) for w in words if w not in ignore_words] # Stem each word, lowercase it, and ignore specifically ?\n",
    "words = sorted(list(set(words))) # Sort the words\n",
    "\n",
    "# sort classes\n",
    "#classes = sorted(list(set(classes)))\n",
    "\n",
    "# documents = combination between patterns and intents\n",
    "print (len(documents), \"documents\")\n",
    "# classes = intents\n",
    "print (len(intents), \"intents\", intents)\n",
    "# words = all words, vocabulary\n",
    "print (len(words), \"unique stemmed words\", words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "610f78cd-9a27-4ee2-a730-19124fe32d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = [] # Create an array to store training data\n",
    "output_empty = [0] * len(intents) # Create an array to mark outputs\n",
    "\n",
    "for doc in documents: # For each document (sentence + intent):\n",
    "    bag = [] # Create an array to store a bag of words\n",
    "    pattern_words = doc[0] # Create list of tokenized words for the pattern\n",
    "    pattern_words = [stemmer.stem(word.lower()) for word in pattern_words] # Stem each word\n",
    "    for w in words: # For each word in words\n",
    "        bag.append(1) if w in pattern_words else bag.append(0) # If there is a match in the current pattern, append it\n",
    "    output_row = list(output_empty)  # Get the currently, nulled list of outputs\n",
    "    output_row[intents.index(doc[1])] = 1 # Set the output index that matches the intent to 1\n",
    "    training.append([bag, output_row]) # Append the training data with the bag of words and the output row (which shows which intent the bag is for)\n",
    "    \n",
    "random.shuffle(training) # Shuffle the training array\n",
    "train_x, train_y = zip(*training) # Split the training array into bag of words and intent\n",
    "train_x = np.array(train_x) # Convert the lists, separately, into arrays\n",
    "train_y = np.array(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "554ba040-1233-4b70-88af-188bd84e396a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mist861/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Create the NN.  This was taken wholesale, unmodified from the Katana folks\n",
    "model = Sequential() # Define the NN\n",
    "model.add(Dense(128, input_shape=(len(train_x[0]),), activation='relu')) # Add a relu layer\n",
    "model.add(Dropout(0.5)) # Add a dropout layer\n",
    "model.add(Dense(64, activation='relu')) # Add a relu layer\n",
    "model.add(Dropout(0.5)) # Add a dropout layer\n",
    "model.add(Dense(len(train_y[0]), activation='softmax')) # Add the prediction softmax layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fbb7e186-5e4f-4195-bf18-8a102d66dbc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mist861/anaconda3/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py:33: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Compile the model.  This was MOSTLY taken from the Katana folks\n",
    "sgd = SGD(learning_rate=0.01, decay=1e-6, momentum=0.9, nesterov=True) # Define the SGD optimizer.  I had to tweak this slightly, because even the legacy SGD was too new for the original Katana code\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy']) # Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "17112444-0877-4d05-8a92-91cdb500c08c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1721156943.283688   30615 service.cc:146] XLA service 0x7ff4dc00a990 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1721156943.283715   30615 service.cc:154]   StreamExecutor device (0): Host, Default Version\n",
      "2024-07-16 14:09:03.294817: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 76/128\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 670us/step - accuracy: 0.1208 - loss: 2.4839      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1721156943.515610   30615 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1394 - loss: 2.4403\n",
      "Epoch 2/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - accuracy: 0.4359 - loss: 1.6815\n",
      "Epoch 3/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577us/step - accuracy: 0.6292 - loss: 1.0387\n",
      "Epoch 4/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - accuracy: 0.7486 - loss: 0.6955\n",
      "Epoch 5/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - accuracy: 0.7471 - loss: 0.6145\n",
      "Epoch 6/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - accuracy: 0.7873 - loss: 0.5248\n",
      "Epoch 7/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606us/step - accuracy: 0.8441 - loss: 0.4848\n",
      "Epoch 8/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834us/step - accuracy: 0.8512 - loss: 0.3798\n",
      "Epoch 9/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576us/step - accuracy: 0.8604 - loss: 0.3247\n",
      "Epoch 10/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593us/step - accuracy: 0.8753 - loss: 0.2947\n",
      "Epoch 11/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704us/step - accuracy: 0.8820 - loss: 0.2725\n",
      "Epoch 12/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625us/step - accuracy: 0.9141 - loss: 0.2382\n",
      "Epoch 13/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step - accuracy: 0.8917 - loss: 0.2655\n",
      "Epoch 14/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 614us/step - accuracy: 0.9106 - loss: 0.2462\n",
      "Epoch 15/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step - accuracy: 0.9177 - loss: 0.2540\n",
      "Epoch 16/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - accuracy: 0.9081 - loss: 0.2433\n",
      "Epoch 17/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step - accuracy: 0.9134 - loss: 0.2149\n",
      "Epoch 18/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - accuracy: 0.9478 - loss: 0.1587\n",
      "Epoch 19/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step - accuracy: 0.9360 - loss: 0.1654\n",
      "Epoch 20/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - accuracy: 0.9372 - loss: 0.1738\n",
      "Epoch 21/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593us/step - accuracy: 0.9525 - loss: 0.1169\n",
      "Epoch 22/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - accuracy: 0.9596 - loss: 0.1047\n",
      "Epoch 23/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 552us/step - accuracy: 0.9542 - loss: 0.1510\n",
      "Epoch 24/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - accuracy: 0.9519 - loss: 0.1391\n",
      "Epoch 25/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - accuracy: 0.9811 - loss: 0.0757\n",
      "Epoch 26/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579us/step - accuracy: 0.9367 - loss: 0.1576\n",
      "Epoch 27/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 547us/step - accuracy: 0.9546 - loss: 0.1458\n",
      "Epoch 28/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 552us/step - accuracy: 0.9620 - loss: 0.1244\n",
      "Epoch 29/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - accuracy: 0.9431 - loss: 0.1960\n",
      "Epoch 30/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - accuracy: 0.9708 - loss: 0.1049\n",
      "Epoch 31/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593us/step - accuracy: 0.9778 - loss: 0.0776\n",
      "Epoch 32/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569us/step - accuracy: 0.9503 - loss: 0.0995\n",
      "Epoch 33/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548us/step - accuracy: 0.9745 - loss: 0.0939\n",
      "Epoch 34/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - accuracy: 0.9716 - loss: 0.0870\n",
      "Epoch 35/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - accuracy: 0.9696 - loss: 0.0896\n",
      "Epoch 36/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - accuracy: 0.9619 - loss: 0.0848 \n",
      "Epoch 37/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - accuracy: 0.9447 - loss: 0.1151\n",
      "Epoch 38/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 0.9757 - loss: 0.0487 \n",
      "Epoch 39/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - accuracy: 0.9612 - loss: 0.0791\n",
      "Epoch 40/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577us/step - accuracy: 0.9735 - loss: 0.0682\n",
      "Epoch 41/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - accuracy: 0.9981 - loss: 0.0239\n",
      "Epoch 42/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571us/step - accuracy: 0.9899 - loss: 0.0752\n",
      "Epoch 43/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 552us/step - accuracy: 0.9893 - loss: 0.0492\n",
      "Epoch 44/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - accuracy: 0.9914 - loss: 0.0376\n",
      "Epoch 45/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561us/step - accuracy: 0.9832 - loss: 0.0750\n",
      "Epoch 46/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - accuracy: 0.9799 - loss: 0.0638\n",
      "Epoch 47/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - accuracy: 0.9821 - loss: 0.0510\n",
      "Epoch 48/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - accuracy: 0.9867 - loss: 0.0580 \n",
      "Epoch 49/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566us/step - accuracy: 0.9950 - loss: 0.0301 \n",
      "Epoch 50/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566us/step - accuracy: 0.9805 - loss: 0.0594\n",
      "Epoch 51/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - accuracy: 0.9557 - loss: 0.1200 \n",
      "Epoch 52/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 546us/step - accuracy: 0.9728 - loss: 0.0833 \n",
      "Epoch 53/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576us/step - accuracy: 0.9887 - loss: 0.0385\n",
      "Epoch 54/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576us/step - accuracy: 0.9773 - loss: 0.0715 \n",
      "Epoch 55/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561us/step - accuracy: 0.9784 - loss: 0.0461 \n",
      "Epoch 56/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569us/step - accuracy: 0.9916 - loss: 0.0352\n",
      "Epoch 57/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step - accuracy: 0.9960 - loss: 0.0260\n",
      "Epoch 58/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586us/step - accuracy: 0.9945 - loss: 0.0271\n",
      "Epoch 59/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - accuracy: 0.9970 - loss: 0.0208\n",
      "Epoch 60/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 546us/step - accuracy: 0.9887 - loss: 0.0333 \n",
      "Epoch 61/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - accuracy: 0.9856 - loss: 0.0692\n",
      "Epoch 62/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - accuracy: 0.9725 - loss: 0.0857\n",
      "Epoch 63/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 613us/step - accuracy: 0.9850 - loss: 0.0474\n",
      "Epoch 64/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step - accuracy: 0.9951 - loss: 0.0201 \n",
      "Epoch 65/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544us/step - accuracy: 0.9768 - loss: 0.0700 \n",
      "Epoch 66/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 552us/step - accuracy: 0.9815 - loss: 0.0418\n",
      "Epoch 67/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - accuracy: 0.9710 - loss: 0.0567\n",
      "Epoch 68/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596us/step - accuracy: 0.9947 - loss: 0.0273 \n",
      "Epoch 69/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - accuracy: 0.9975 - loss: 0.0215\n",
      "Epoch 70/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - accuracy: 0.9819 - loss: 0.0655 \n",
      "Epoch 71/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - accuracy: 0.9912 - loss: 0.0580\n",
      "Epoch 72/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - accuracy: 0.9869 - loss: 0.0445\n",
      "Epoch 73/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553us/step - accuracy: 0.9920 - loss: 0.0232\n",
      "Epoch 74/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - accuracy: 0.9870 - loss: 0.0446\n",
      "Epoch 75/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576us/step - accuracy: 0.9946 - loss: 0.0183\n",
      "Epoch 76/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558us/step - accuracy: 0.9873 - loss: 0.0224\n",
      "Epoch 77/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - accuracy: 0.9989 - loss: 0.0133 \n",
      "Epoch 78/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578us/step - accuracy: 0.9914 - loss: 0.0377\n",
      "Epoch 79/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - accuracy: 0.9710 - loss: 0.1193\n",
      "Epoch 80/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542us/step - accuracy: 0.9796 - loss: 0.0885\n",
      "Epoch 81/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565us/step - accuracy: 0.9872 - loss: 0.0677\n",
      "Epoch 82/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574us/step - accuracy: 0.9974 - loss: 0.0254\n",
      "Epoch 83/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593us/step - accuracy: 0.9920 - loss: 0.0262 \n",
      "Epoch 84/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578us/step - accuracy: 0.9858 - loss: 0.0501\n",
      "Epoch 85/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608us/step - accuracy: 0.9737 - loss: 0.0769\n",
      "Epoch 86/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576us/step - accuracy: 0.9925 - loss: 0.0322\n",
      "Epoch 87/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596us/step - accuracy: 0.9824 - loss: 0.0448 \n",
      "Epoch 88/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - accuracy: 0.9845 - loss: 0.0532\n",
      "Epoch 89/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561us/step - accuracy: 0.9706 - loss: 0.0634\n",
      "Epoch 90/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - accuracy: 0.9936 - loss: 0.0255 \n",
      "Epoch 91/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 614us/step - accuracy: 0.9953 - loss: 0.0293\n",
      "Epoch 92/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - accuracy: 0.9882 - loss: 0.0585 \n",
      "Epoch 93/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593us/step - accuracy: 0.9874 - loss: 0.0528 \n",
      "Epoch 94/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - accuracy: 0.9726 - loss: 0.0797\n",
      "Epoch 95/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - accuracy: 0.9945 - loss: 0.0319 \n",
      "Epoch 96/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 551us/step - accuracy: 0.9782 - loss: 0.0432 \n",
      "Epoch 97/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - accuracy: 0.9879 - loss: 0.0317 \n",
      "Epoch 98/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - accuracy: 0.9952 - loss: 0.0303\n",
      "Epoch 99/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - accuracy: 0.9960 - loss: 0.0180 \n",
      "Epoch 100/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step - accuracy: 0.9878 - loss: 0.0347\n",
      "Epoch 101/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - accuracy: 0.9887 - loss: 0.0257\n",
      "Epoch 102/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579us/step - accuracy: 0.9867 - loss: 0.0449 \n",
      "Epoch 103/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step - accuracy: 0.9896 - loss: 0.0416\n",
      "Epoch 104/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624us/step - accuracy: 0.9874 - loss: 0.0305 \n",
      "Epoch 105/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - accuracy: 0.9953 - loss: 0.0300 \n",
      "Epoch 106/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - accuracy: 0.9812 - loss: 0.0449\n",
      "Epoch 107/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - accuracy: 0.9930 - loss: 0.0266\n",
      "Epoch 108/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 724us/step - accuracy: 0.9934 - loss: 0.0230\n",
      "Epoch 109/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - accuracy: 0.9998 - loss: 0.0092\n",
      "Epoch 110/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - accuracy: 0.9863 - loss: 0.0261\n",
      "Epoch 111/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - accuracy: 0.9874 - loss: 0.0484\n",
      "Epoch 112/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - accuracy: 0.9927 - loss: 0.0191\n",
      "Epoch 113/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598us/step - accuracy: 0.9944 - loss: 0.0196 \n",
      "Epoch 114/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571us/step - accuracy: 0.9982 - loss: 0.0224\n",
      "Epoch 115/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - accuracy: 0.9904 - loss: 0.0183 \n",
      "Epoch 116/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - accuracy: 0.9937 - loss: 0.0205 \n",
      "Epoch 117/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - accuracy: 0.9856 - loss: 0.0440 \n",
      "Epoch 118/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - accuracy: 0.9914 - loss: 0.0163 \n",
      "Epoch 119/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - accuracy: 0.9887 - loss: 0.0261\n",
      "Epoch 120/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579us/step - accuracy: 0.9905 - loss: 0.0230\n",
      "Epoch 121/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - accuracy: 0.9905 - loss: 0.0477 \n",
      "Epoch 122/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579us/step - accuracy: 0.9929 - loss: 0.0245 \n",
      "Epoch 123/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608us/step - accuracy: 0.9857 - loss: 0.0474 \n",
      "Epoch 124/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 614us/step - accuracy: 0.9903 - loss: 0.0325 \n",
      "Epoch 125/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - accuracy: 0.9835 - loss: 0.0507\n",
      "Epoch 126/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step - accuracy: 0.9938 - loss: 0.0141 \n",
      "Epoch 127/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step - accuracy: 0.9910 - loss: 0.0239\n",
      "Epoch 128/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576us/step - accuracy: 0.9948 - loss: 0.0170\n",
      "Epoch 129/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593us/step - accuracy: 0.9905 - loss: 0.0238 \n",
      "Epoch 130/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step - accuracy: 0.9941 - loss: 0.0165 \n",
      "Epoch 131/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - accuracy: 0.9888 - loss: 0.0188 \n",
      "Epoch 132/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - accuracy: 0.9989 - loss: 0.0101 \n",
      "Epoch 133/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605us/step - accuracy: 0.9853 - loss: 0.0517\n",
      "Epoch 134/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607us/step - accuracy: 0.9962 - loss: 0.0234\n",
      "Epoch 135/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594us/step - accuracy: 0.9912 - loss: 0.0293 \n",
      "Epoch 136/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609us/step - accuracy: 0.9988 - loss: 0.0075\n",
      "Epoch 137/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565us/step - accuracy: 0.9907 - loss: 0.0223\n",
      "Epoch 138/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596us/step - accuracy: 0.9987 - loss: 0.0049\n",
      "Epoch 139/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544us/step - accuracy: 0.9963 - loss: 0.0147 \n",
      "Epoch 140/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - accuracy: 0.9982 - loss: 0.0108\n",
      "Epoch 141/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - accuracy: 0.9922 - loss: 0.0263\n",
      "Epoch 142/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592us/step - accuracy: 0.9990 - loss: 0.0122\n",
      "Epoch 143/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 0.9960 - loss: 0.0216 \n",
      "Epoch 144/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561us/step - accuracy: 0.9953 - loss: 0.0241 \n",
      "Epoch 145/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 633us/step - accuracy: 0.9910 - loss: 0.0221 \n",
      "Epoch 146/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578us/step - accuracy: 0.9879 - loss: 0.0635 \n",
      "Epoch 147/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - accuracy: 0.9904 - loss: 0.0361\n",
      "Epoch 148/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step - accuracy: 0.9872 - loss: 0.0367\n",
      "Epoch 149/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565us/step - accuracy: 0.9867 - loss: 0.0337 \n",
      "Epoch 150/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step - accuracy: 0.9883 - loss: 0.0400\n",
      "Epoch 151/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step - accuracy: 0.9882 - loss: 0.0311 \n",
      "Epoch 152/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - accuracy: 0.9941 - loss: 0.0173\n",
      "Epoch 153/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step - accuracy: 0.9931 - loss: 0.0237\n",
      "Epoch 154/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - accuracy: 0.9922 - loss: 0.0185 \n",
      "Epoch 155/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565us/step - accuracy: 0.9934 - loss: 0.0218 \n",
      "Epoch 156/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - accuracy: 0.9954 - loss: 0.0188 \n",
      "Epoch 157/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - accuracy: 0.9911 - loss: 0.0246 \n",
      "Epoch 158/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 550us/step - accuracy: 0.9919 - loss: 0.0235\n",
      "Epoch 159/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566us/step - accuracy: 0.9967 - loss: 0.0159\n",
      "Epoch 160/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.9946 - loss: 0.0299 \n",
      "Epoch 161/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548us/step - accuracy: 0.9856 - loss: 0.0405\n",
      "Epoch 162/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538us/step - accuracy: 0.9888 - loss: 0.0427\n",
      "Epoch 163/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - accuracy: 0.9885 - loss: 0.0327 \n",
      "Epoch 164/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561us/step - accuracy: 0.9784 - loss: 0.0376\n",
      "Epoch 165/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - accuracy: 0.9998 - loss: 0.0056 \n",
      "Epoch 166/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576us/step - accuracy: 0.9982 - loss: 0.0122 \n",
      "Epoch 167/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609us/step - accuracy: 0.9982 - loss: 0.0186\n",
      "Epoch 168/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610us/step - accuracy: 0.9878 - loss: 0.0361\n",
      "Epoch 169/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 633us/step - accuracy: 0.9851 - loss: 0.0369\n",
      "Epoch 170/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - accuracy: 0.9966 - loss: 0.0127 \n",
      "Epoch 171/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - accuracy: 0.9877 - loss: 0.0207\n",
      "Epoch 172/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571us/step - accuracy: 0.9984 - loss: 0.0111 \n",
      "Epoch 173/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593us/step - accuracy: 0.9987 - loss: 0.0086 \n",
      "Epoch 174/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - accuracy: 0.9974 - loss: 0.0081 \n",
      "Epoch 175/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - accuracy: 0.9957 - loss: 0.0113 \n",
      "Epoch 176/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578us/step - accuracy: 0.9830 - loss: 0.0293 \n",
      "Epoch 177/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - accuracy: 0.9935 - loss: 0.0349 \n",
      "Epoch 178/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step - accuracy: 0.9936 - loss: 0.0171\n",
      "Epoch 179/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 616us/step - accuracy: 0.9942 - loss: 0.0240 \n",
      "Epoch 180/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step - accuracy: 0.9932 - loss: 0.0219\n",
      "Epoch 181/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574us/step - accuracy: 0.9928 - loss: 0.0292\n",
      "Epoch 182/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598us/step - accuracy: 0.9992 - loss: 0.0093\n",
      "Epoch 183/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - accuracy: 0.9958 - loss: 0.0118\n",
      "Epoch 184/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - accuracy: 0.9951 - loss: 0.0145 \n",
      "Epoch 185/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569us/step - accuracy: 0.9894 - loss: 0.0266\n",
      "Epoch 186/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586us/step - accuracy: 0.9953 - loss: 0.0222\n",
      "Epoch 187/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 552us/step - accuracy: 0.9946 - loss: 0.0144 \n",
      "Epoch 188/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step - accuracy: 0.9957 - loss: 0.0075 \n",
      "Epoch 189/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553us/step - accuracy: 0.9930 - loss: 0.0249 \n",
      "Epoch 190/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step - accuracy: 0.9939 - loss: 0.0314 \n",
      "Epoch 191/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592us/step - accuracy: 0.9979 - loss: 0.0113 \n",
      "Epoch 192/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 680us/step - accuracy: 0.9986 - loss: 0.0063\n",
      "Epoch 193/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569us/step - accuracy: 0.9986 - loss: 0.0088\n",
      "Epoch 194/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - accuracy: 0.9948 - loss: 0.0120 \n",
      "Epoch 195/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577us/step - accuracy: 0.9962 - loss: 0.0116 \n",
      "Epoch 196/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step - accuracy: 0.9888 - loss: 0.0274 \n",
      "Epoch 197/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - accuracy: 0.9965 - loss: 0.0116 \n",
      "Epoch 198/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559us/step - accuracy: 0.9964 - loss: 0.0092 \n",
      "Epoch 199/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542us/step - accuracy: 0.9955 - loss: 0.0146 \n",
      "Epoch 200/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - accuracy: 0.9876 - loss: 0.0283 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7ff603a77850>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, epochs=200, batch_size=5, verbose=1) # Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ce670531-6aaa-43f7-a4e9-f97f5efb616a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up_sentence(sentence): # Define a method to preprocess sentences for classification\n",
    "    sentence_words = nltk.word_tokenize(sentence) # Tokenize the sentence\n",
    "    sentence_words = [stemmer.stem(word.lower()) for word in sentence_words] # Stem each word\n",
    "    return sentence_words\n",
    "\n",
    "def bow(sentence, words, show_details=True): # Define a method to turn the sentence into a bag of words, for classification\n",
    "    sentence_words = clean_up_sentence(sentence) # Tokenize/stem the sentence using the above\n",
    "    bag = [0]*len(words) # Create a bag of words\n",
    "    for s in sentence_words: # For each word in the sentence\n",
    "        for i,w in enumerate(words): # For each word in the original training set\n",
    "            if w == s: # If the sentence word matches the training word\n",
    "                bag[i] = 1 # Set its position to 1\n",
    "                if show_details:\n",
    "                    print (\"found in bag: %s\" % w)\n",
    "    return(np.array(bag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e328198b-a8e9-4edd-94a4-82398c83611c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_local(sentence): # Define a method to classify sentences\n",
    "    ERROR_THRESHOLD = 0.25 # Set an internal error threshold, any predictions lower than this will not be included in the results\n",
    "    input_data = pd.DataFrame([bow(sentence, words)], dtype=float, index=['input']) # Take the input sentence, the original training words, and apply the above functions to them\n",
    "    results = model.predict([input_data])[0] # Call the NN model to predict the intent\n",
    "    results = [[i,r] for i,r in enumerate(results) if r>ERROR_THRESHOLD] # Return any predictions with a confidence threshold above ERROR_THRESHOLD\n",
    "    results.sort(key=lambda x: x[1], reverse=True) # Sort by confidence\n",
    "    return_list = [] # Define an empty array to store results\n",
    "    for r in results: # For each result:\n",
    "        return_list.append((intents[r[0]], str(r[1]))) # Append to the return list\n",
    "    return return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5bab6409-848d-48f6-b6d4-7f1bf272c99b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "noanswer\n"
     ]
    }
   ],
   "source": [
    "results = classify_local(\"askldjfjasldijf\") # Testing the NN\n",
    "(results)\n",
    "if float(results[0][1]) < 0.6:\n",
    "    print('noanswer')\n",
    "else:\n",
    "    print(response[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "019266bb-e7cc-4126-ba71-c5c53f398950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found in bag: pleas\n",
      "found in bag: help\n",
      "found in bag: me\n",
      "found in bag: find\n",
      "found in bag: my\n",
      "found in bag: med\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n"
     ]
    }
   ],
   "source": [
    "response = classify_local(\"Please help me find my medication\") # Testing the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1a45674c-dfe5-46c0-9230-afc635782e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "medication\n"
     ]
    }
   ],
   "source": [
    "print(response[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0520595e-2a43-4c32-aff2-1df1069ce741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I think this is what you're after.  Navigating to the Medication module...\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses_df.responses[responses_df['intent'] == response[0][0]].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "49a59bea-7d1a-4470-9c07-842f99ef27e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../results/nn_model.keras\") # Save the NN to be reused in the streamlit UI (note that those scripts are separate from this notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "186fd5cb-2f4e-454d-9ccb-2b120c4c733d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../results/intents.pickle', 'wb') as file: # Save the intents and words files to be reused in the streamlit UI\n",
    "    pickle.dump(intents, file)\n",
    "with open('../results/words.pickle', 'wb') as file:\n",
    "    pickle.dump(words, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ea3846-5151-4c72-95c0-4359e2b86256",
   "metadata": {},
   "source": [
    "# Comparing NN and RAG Intent Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "41dfbb32-22e2-44cc-9e52-b5b41cbbb9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['medication', 'hospital_search', 'greeting', 'blood_pressure', 'goodbye', 'doctor', 'thanks', 'medication', 'blood_pressure', 'pharmacy_search', 'goodbye', 'greeting', 'hospital_search', 'goodbye', 'goodbye', 'thanks', 'doctor', 'hospital_search', 'doctor', 'hospital_search', 'thanks', 'blood_pressure', 'pharmacy_search', 'doctor', 'hospital_search', 'blood_pressure', 'symptoms', 'goodbye', 'pharmacy_search', 'symptoms', 'medication', 'greeting', 'blood_pressure', 'hospital_search', 'pharmacy_search', 'adverse_drug', 'hospital_search', 'greeting', 'symptoms', 'greeting', 'adverse_drug', 'symptoms', 'pharmacy_search', 'medication', 'pharmacy_search', 'blood_pressure', 'options', 'options', 'hospital_search', 'options', 'greeting', 'options', 'symptoms', 'pharmacy_search', 'goodbye', 'thanks', 'greeting', 'doctor', 'hospital_search', 'pharmacy_search', 'adverse_drug', 'adverse_drug', 'hospital_search', 'adverse_drug', 'doctor', 'blood_pressure', 'greeting', 'blood_pressure_search', 'goodbye', 'thanks', 'blood_pressure', 'hospital_search', 'symptoms', 'blood_pressure_search', 'blood_pressure_search', 'hospital_search', 'pharmacy_search', 'blood_pressure_search', 'medication', 'doctor', 'doctor', 'adverse_drug', 'goodbye', 'goodbye', 'pharmacy_search', 'goodbye', 'symptoms', 'options', 'goodbye', 'thanks', 'goodbye', 'medication', 'adverse_drug', 'symptoms', 'hospital_search', 'pharmacy_search', 'symptoms', 'blood_pressure', 'greeting', 'doctor', 'blood_pressure', 'options', 'thanks', 'options', 'goodbye', 'hospital_search', 'greeting', 'symptoms', 'medication', 'doctor', 'options', 'options', 'goodbye', 'thanks', 'doctor', 'options', 'greeting', 'adverse_drug', 'medication', 'doctor', 'options', 'doctor', 'options', 'medication', 'medication', 'symptoms', 'greeting', 'blood_pressure', 'greeting', 'noanswer', 'hospital_search', 'medication', 'goodbye', 'hospital_search', 'options', 'hospital_search', 'symptoms', 'options', 'hospital_search', 'options', 'medication', 'blood_pressure', 'adverse_drug', 'medication', 'goodbye', 'pharmacy_search', 'thanks', 'goodbye', 'blood_pressure', 'greeting', 'goodbye', 'greeting', 'thanks', 'thanks', 'blood_pressure', 'pharmacy_search', 'options', 'doctor', 'adverse_drug']\n"
     ]
    }
   ],
   "source": [
    "rag_results = []\n",
    "for utterance in test_df['utterance']: # Generate predictions with the test data for the RAG\n",
    "    result = rl(utterance).name\n",
    "    if result == None:\n",
    "        result = 'noanswer'\n",
    "    rag_results.append(result)\n",
    "\n",
    "print(rag_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f271b01e-a478-45c9-9c73-546e960798f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found in bag: ``\n",
      "found in bag: could\n",
      "found in bag: you\n",
      "found in bag: get\n",
      "found in bag: my\n",
      "found in bag: prescrib\n",
      "found in bag: for\n",
      "found in bag: me\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: search\n",
      "found in bag: for\n",
      "found in bag: hospit\n",
      "found in bag: with\n",
      "found in bag: car\n",
      "found in bag: serv\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: hey\n",
      "found in bag: ,\n",
      "found in bag: good\n",
      "found in bag: to\n",
      "found in bag: see\n",
      "found in bag: you\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: ar\n",
      "found in bag: my\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: bye\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: nee\n",
      "found in bag: the\n",
      "found in bag: at\n",
      "found in bag: of\n",
      "found in bag: a\n",
      "found in bag: doct\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: grat\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: 'd\n",
      "found in bag: lik\n",
      "found in bag: to\n",
      "found in bag: ord\n",
      "found in bag: a\n",
      "found in bag: batch\n",
      "found in bag: of\n",
      "found in bag: my\n",
      "found in bag: medicin\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: the\n",
      "found in bag: verdict\n",
      "found in bag: on\n",
      "found in bag: my\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: today\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: wher\n",
      "found in bag: can\n",
      "found in bag: i\n",
      "found in bag: over-the-count\n",
      "found in bag: med\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: wel\n",
      "found in bag: ev\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: search\n",
      "found in bag: up\n",
      "found in bag: hospit\n",
      "found in bag: detail\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: see\n",
      "found in bag: you\n",
      "found in bag: lat\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: much\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: ar\n",
      "found in bag: ther\n",
      "found in bag: any\n",
      "found in bag: doct\n",
      "found in bag: in\n",
      "found in bag: the\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: want\n",
      "found in bag: to\n",
      "found in bag: search\n",
      "found in bag: hospit\n",
      "found in bag: dat\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: 'm\n",
      "found in bag: look\n",
      "found in bag: to\n",
      "found in bag: see\n",
      "found in bag: a\n",
      "found in bag: healthc\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: a\n",
      "found in bag: hospit\n",
      "found in bag: in\n",
      "found in bag: [\n",
      "found in bag: city/town\n",
      "found in bag: ]\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: you\n",
      "found in bag: hav\n",
      "found in bag: my\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: waht\n",
      "found in bag: ar\n",
      "found in bag: my\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: level\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: for\n",
      "found in bag: pharm\n",
      "found in bag: that\n",
      "found in bag: del\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: could\n",
      "found in bag: i\n",
      "found in bag: see\n",
      "found in bag: a\n",
      "found in bag: doct\n",
      "found in bag: ,\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: find\n",
      "found in bag: hospit\n",
      "found in bag: me\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: want\n",
      "found in bag: to\n",
      "found in bag: search\n",
      "found in bag: for\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: result\n",
      "found in bag: hist\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: feel\n",
      "found in bag: extrem\n",
      "found in bag: tir\n",
      "found in bag: and\n",
      "found in bag: letharg\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: so\n",
      "found in bag: long\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: find\n",
      "found in bag: a\n",
      "found in bag: in\n",
      "found in bag: [\n",
      "found in bag: city/town\n",
      "found in bag: ]\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: feel\n",
      "found in bag: and\n",
      "found in bag: lighthead\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: pleas\n",
      "found in bag: prep\n",
      "found in bag: my\n",
      "found in bag: med\n",
      "found in bag: for\n",
      "found in bag: me\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: hav\n",
      "found in bag: a\n",
      "found in bag: gre\n",
      "found in bag: day\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: 's\n",
      "found in bag: the\n",
      "found in bag: stat\n",
      "found in bag: of\n",
      "found in bag: my\n",
      "found in bag: press\n",
      "found in bag: today\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: loc\n",
      "found in bag: a\n",
      "found in bag: nearby\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: search\n",
      "found in bag: pharm\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: list\n",
      "found in bag: al\n",
      "found in bag: drug\n",
      "found in bag: suit\n",
      "found in bag: for\n",
      "found in bag: paty\n",
      "found in bag: with\n",
      "found in bag: advers\n",
      "found in bag: react\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: unear\n",
      "found in bag: hospit\n",
      "found in bag: with\n",
      "found in bag: spec\n",
      "found in bag: special\n",
      "found in bag: (\n",
      "found in bag: e.g.\n",
      "found in bag: ,\n",
      "found in bag: cardiolog\n",
      "found in bag: ,\n",
      "found in bag: pedy\n",
      "found in bag: )\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: welcom\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: 'm\n",
      "found in bag: feel\n",
      "found in bag: cold\n",
      "found in bag: or\n",
      "found in bag: hot\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: wel\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: can\n",
      "found in bag: you\n",
      "found in bag: describ\n",
      "found in bag: any\n",
      "found in bag: undesir\n",
      "found in bag: effect\n",
      "found in bag: that\n",
      "found in bag: could\n",
      "found in bag: occ\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: hav\n",
      "found in bag: a\n",
      "found in bag: runny\n",
      "found in bag: nos\n",
      "found in bag: and\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: nearby\n",
      "found in bag: pharm\n",
      "found in bag: op\n",
      "found in bag: now\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: 'd\n",
      "found in bag: lik\n",
      "found in bag: to\n",
      "found in bag: ord\n",
      "found in bag: a\n",
      "found in bag: batch\n",
      "found in bag: of\n",
      "found in bag: my\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: pharm\n",
      "found in bag: her\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: dat\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: how\n",
      "found in bag: you\n",
      "found in bag: can\n",
      "found in bag: be\n",
      "found in bag: help\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: waht\n",
      "found in bag: ar\n",
      "found in bag: yo\n",
      "found in bag: tal\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: search\n",
      "found in bag: for\n",
      "found in bag: that\n",
      "found in bag: off\n",
      "found in bag: telemedicin\n",
      "found in bag: serv\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: ar\n",
      "found in bag: yo\n",
      "found in bag: cap\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: hiy\n",
      "found in bag: ther\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: ar\n",
      "found in bag: yo\n",
      "found in bag: strengths\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: 'm\n",
      "found in bag: diarrhe\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: wher\n",
      "found in bag: is\n",
      "found in bag: the\n",
      "found in bag: clos\n",
      "found in bag: pharm\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: thank\n",
      "found in bag: you\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: ar\n",
      "found in bag: you\n",
      "found in bag: doing\n",
      "found in bag: today\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: ar\n",
      "found in bag: ther\n",
      "found in bag: any\n",
      "found in bag: doct\n",
      "found in bag: in\n",
      "found in bag: the\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: search\n",
      "found in bag: for\n",
      "found in bag: hospit\n",
      "found in bag: with\n",
      "found in bag: urg\n",
      "found in bag: car\n",
      "found in bag: serv\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: pharm\n",
      "found in bag: clos\n",
      "found in bag: to\n",
      "found in bag: my\n",
      "found in bag: loc\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: ar\n",
      "found in bag: ther\n",
      "found in bag: any\n",
      "found in bag: effect\n",
      "found in bag: i\n",
      "found in bag: should\n",
      "found in bag: watch\n",
      "found in bag: out\n",
      "found in bag: for\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: which\n",
      "found in bag: drug\n",
      "found in bag: dont\n",
      "found in bag: hav\n",
      "found in bag: react\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: can\n",
      "found in bag: i\n",
      "found in bag: find\n",
      "found in bag: a\n",
      "found in bag: hospit\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: how\n",
      "found in bag: to\n",
      "found in bag: ver\n",
      "found in bag: advers\n",
      "found in bag: drug\n",
      "found in bag: react\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: would\n",
      "found in bag: lik\n",
      "found in bag: to\n",
      "found in bag: request\n",
      "found in bag: a\n",
      "found in bag: doct\n",
      "found in bag: 's\n",
      "found in bag: appoint\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: is\n",
      "found in bag: my\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: stabl\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "found in bag: ``\n",
      "found in bag: good\n",
      "found in bag: afternoon\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: chrissakes\n",
      "found in bag: press\n",
      "found in bag: for\n",
      "found in bag: paty\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: it\n",
      "found in bag: easy\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: thank\n",
      "found in bag: a\n",
      "found in bag: lot\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: could\n",
      "found in bag: you\n",
      "found in bag: inform\n",
      "found in bag: me\n",
      "found in bag: of\n",
      "found in bag: my\n",
      "found in bag: transfus\n",
      "found in bag: press\n",
      "found in bag: result\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: loc\n",
      "found in bag: hospit\n",
      "found in bag: in\n",
      "found in bag: [\n",
      "found in bag: neighb\n",
      "found in bag: ]\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: hav\n",
      "found in bag: troubl\n",
      "found in bag: cont\n",
      "found in bag: or\n",
      "found in bag: clear\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: show\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: result\n",
      "found in bag: for\n",
      "found in bag: paty\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: for\n",
      "found in bag: paty\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: loc\n",
      "found in bag: a\n",
      "found in bag: hospit\n",
      "found in bag: that\n",
      "found in bag: acceiv\n",
      "found in bag: my\n",
      "found in bag: ins\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: pharm\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: for\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: nee\n",
      "found in bag: to\n",
      "found in bag: my\n",
      "found in bag: supply\n",
      "found in bag: of\n",
      "found in bag: med\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: requir\n",
      "found in bag: to\n",
      "found in bag: consult\n",
      "found in bag: with\n",
      "found in bag: a\n",
      "found in bag: med\n",
      "found in bag: doct\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: is\n",
      "found in bag: ther\n",
      "found in bag: a\n",
      "found in bag: doct\n",
      "found in bag: on\n",
      "found in bag: right\n",
      "found in bag: now\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: could\n",
      "found in bag: you\n",
      "found in bag: list\n",
      "found in bag: the\n",
      "found in bag: pot\n",
      "found in bag: drawback\n",
      "found in bag: or\n",
      "found in bag: downsid\n",
      "found in bag: of\n",
      "found in bag: us\n",
      "found in bag: thi\n",
      "found in bag: drug\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: catch\n",
      "found in bag: you\n",
      "found in bag: lat\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: bye-by\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: me\n",
      "found in bag: a\n",
      "found in bag: pharm\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: must\n",
      "found in bag: be\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: my\n",
      "found in bag: joint\n",
      "found in bag: ar\n",
      "found in bag: and\n",
      "found in bag: pain\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: can\n",
      "found in bag: you\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: see\n",
      "found in bag: ta\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: you\n",
      "found in bag: 're\n",
      "found in bag: a\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: a\n",
      "found in bag: good\n",
      "found in bag: on\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: 'd\n",
      "found in bag: lik\n",
      "found in bag: to\n",
      "found in bag: request\n",
      "found in bag: a\n",
      "found in bag: refil\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "found in bag: ``\n",
      "found in bag: ar\n",
      "found in bag: ther\n",
      "found in bag: any\n",
      "found in bag: effect\n",
      "found in bag: i\n",
      "found in bag: should\n",
      "found in bag: be\n",
      "found in bag: aw\n",
      "found in bag: of\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: my\n",
      "found in bag: joint\n",
      "found in bag: ar\n",
      "found in bag: swol\n",
      "found in bag: and\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "found in bag: ``\n",
      "found in bag: for\n",
      "found in bag: hospit\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: find\n",
      "found in bag: a\n",
      "found in bag: 24-hour\n",
      "found in bag: near\n",
      "found in bag: me\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: hav\n",
      "found in bag: troubl\n",
      "found in bag: cont\n",
      "found in bag: or\n",
      "found in bag: think\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: could\n",
      "found in bag: you\n",
      "found in bag: check\n",
      "found in bag: my\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: ,\n",
      "found in bag: pleas\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: how\n",
      "found in bag: 's\n",
      "found in bag: it\n",
      "found in bag: going\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: can\n",
      "found in bag: you\n",
      "found in bag: direct\n",
      "found in bag: me\n",
      "found in bag: to\n",
      "found in bag: a\n",
      "found in bag: phys\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: how\n",
      "found in bag: doe\n",
      "found in bag: my\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: comp\n",
      "found in bag: to\n",
      "found in bag: norm\n",
      "found in bag: level\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: do\n",
      "found in bag: you\n",
      "found in bag: spec\n",
      "found in bag: in\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: 'm\n",
      "found in bag: thank\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: ar\n",
      "found in bag: yo\n",
      "found in bag: tal\n",
      "found in bag: and\n",
      "found in bag: skil\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: adio\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: wher\n",
      "found in bag: can\n",
      "found in bag: i\n",
      "found in bag: find\n",
      "found in bag: hospit\n",
      "found in bag: with\n",
      "found in bag: surgery\n",
      "found in bag: facil\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: hav\n",
      "found in bag: a\n",
      "found in bag: day\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: hav\n",
      "found in bag: a\n",
      "found in bag: headach\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: is\n",
      "found in bag: my\n",
      "found in bag: prescrib\n",
      "found in bag: ready\n",
      "found in bag: for\n",
      "found in bag: pickup\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: can\n",
      "found in bag: i\n",
      "found in bag: speak\n",
      "found in bag: to\n",
      "found in bag: a\n",
      "found in bag: provid\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: wha\n",
      "found in bag: support\n",
      "found in bag: is\n",
      "found in bag: off\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: ar\n",
      "found in bag: yo\n",
      "found in bag: strong\n",
      "found in bag: point\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: out\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "found in bag: ``\n",
      "found in bag: thank\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: could\n",
      "found in bag: i\n",
      "found in bag: see\n",
      "found in bag: a\n",
      "found in bag: med\n",
      "found in bag: ,\n",
      "found in bag: pleas\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: ar\n",
      "found in bag: you\n",
      "found in bag: cap\n",
      "found in bag: of\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: wel\n",
      "found in bag: morn\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: can\n",
      "found in bag: you\n",
      "found in bag: me\n",
      "found in bag: about\n",
      "found in bag: the\n",
      "found in bag: poss\n",
      "found in bag: sid\n",
      "found in bag: effect\n",
      "found in bag: of\n",
      "found in bag: tak\n",
      "found in bag: thi\n",
      "found in bag: drug\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: 'd\n",
      "found in bag: lik\n",
      "found in bag: to\n",
      "found in bag: ord\n",
      "found in bag: a\n",
      "found in bag: batch\n",
      "found in bag: of\n",
      "found in bag: my\n",
      "found in bag: med\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: nee\n",
      "found in bag: med\n",
      "found in bag: assist\n",
      "found in bag: from\n",
      "found in bag: a\n",
      "found in bag: doct\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: quo\n",
      "found in bag: ar\n",
      "found in bag: yo\n",
      "found in bag: proficy\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: is\n",
      "found in bag: it\n",
      "found in bag: poss\n",
      "found in bag: to\n",
      "found in bag: fulfil\n",
      "found in bag: with\n",
      "found in bag: a\n",
      "found in bag: phys\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: ar\n",
      "found in bag: yo\n",
      "found in bag: strong\n",
      "found in bag: point\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: is\n",
      "found in bag: my\n",
      "found in bag: med\n",
      "found in bag: avail\n",
      "found in bag: for\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: may\n",
      "found in bag: i\n",
      "found in bag: request\n",
      "found in bag: a\n",
      "found in bag: refil\n",
      "found in bag: of\n",
      "found in bag: my\n",
      "found in bag: prescrib\n",
      "found in bag: ,\n",
      "found in bag: pleas\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: hav\n",
      "found in bag: pain\n",
      "found in bag: and\n",
      "found in bag: cramp\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: up\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: dat\n",
      "found in bag: man\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: ther\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: look\n",
      "found in bag: for\n",
      "found in bag: a\n",
      "found in bag: hospit\n",
      "found in bag: that\n",
      "found in bag: 's\n",
      "found in bag: op\n",
      "found in bag: 24/7\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: pick\n",
      "found in bag: up\n",
      "found in bag: my\n",
      "found in bag: med\n",
      "found in bag: ord\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: see\n",
      "found in bag: you\n",
      "found in bag: around\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: find\n",
      "found in bag: hospit\n",
      "found in bag: with\n",
      "found in bag: tre\n",
      "found in bag: facil\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: whereof\n",
      "found in bag: you\n",
      "found in bag: can\n",
      "found in bag: do\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: find\n",
      "found in bag: hospit\n",
      "found in bag: me\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: 'm\n",
      "found in bag: expery\n",
      "found in bag: nause\n",
      "found in bag: and\n",
      "found in bag: vomit\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: help\n",
      "found in bag: you\n",
      "found in bag: provid\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: hospit\n",
      "found in bag: clos\n",
      "found in bag: to\n",
      "found in bag: my\n",
      "found in bag: loc\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: ar\n",
      "found in bag: yo\n",
      "found in bag: compet\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: can\n",
      "found in bag: you\n",
      "found in bag: fil\n",
      "found in bag: my\n",
      "found in bag: prescrib\n",
      "found in bag: for\n",
      "found in bag: me\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: ow\n",
      "found in bag: is\n",
      "found in bag: my\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: look\n",
      "found in bag: today\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: kind\n",
      "found in bag: of\n",
      "found in bag: react\n",
      "found in bag: i\n",
      "found in bag: expery\n",
      "found in bag: from\n",
      "found in bag: thi\n",
      "found in bag: med\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: nee\n",
      "found in bag: to\n",
      "found in bag: refil\n",
      "found in bag: my\n",
      "found in bag: med\n",
      "found in bag: supply\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: list\n",
      "found in bag: of\n",
      "found in bag: pharm\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: 'm\n",
      "found in bag: thank\n",
      "found in bag: for\n",
      "found in bag: yo\n",
      "found in bag: support\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: until\n",
      "found in bag: next\n",
      "found in bag: tim\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: want\n",
      "found in bag: to\n",
      "found in bag: log\n",
      "found in bag: blood\n",
      "found in bag: result\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: ,\n",
      "found in bag: how\n",
      "found in bag: hav\n",
      "found in bag: you\n",
      "found in bag: been\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: see\n",
      "found in bag: you\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: is\n",
      "found in bag: anyon\n",
      "found in bag: ther\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: thank\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: 'm\n",
      "found in bag: so\n",
      "found in bag: thank\n",
      "found in bag: for\n",
      "found in bag: [\n",
      "found in bag: spec\n",
      "found in bag: gest\n",
      "found in bag: or\n",
      "found in bag: help\n",
      "found in bag: ]\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: task\n",
      "found in bag: to\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: loc\n",
      "found in bag: a\n",
      "found in bag: nearby\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: ar\n",
      "found in bag: yo\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: is\n",
      "found in bag: a\n",
      "found in bag: phys\n",
      "found in bag: avail\n",
      "found in bag: to\n",
      "found in bag: me\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: kind\n",
      "found in bag: of\n",
      "found in bag: react\n",
      "found in bag: should\n",
      "found in bag: i\n",
      "found in bag: be\n",
      "found in bag: prep\n",
      "found in bag: for\n",
      "found in bag: with\n",
      "found in bag: thi\n",
      "found in bag: drug\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "['medication', 'hospital_search', 'greeting', 'blood_pressure', 'goodbye', 'doctor', 'thanks', 'medication', 'blood_pressure', 'pharmacy_search', 'greeting', 'greeting', 'hospital_search', 'goodbye', 'greeting', 'thanks', 'doctor', 'hospital_search', 'doctor', 'hospital_search', 'thanks', 'blood_pressure', 'pharmacy_search', 'doctor', 'hospital_search', 'blood_pressure_search', 'symptoms', 'goodbye', 'pharmacy_search', 'symptoms', 'medication', 'goodbye', 'blood_pressure', 'pharmacy_search', 'pharmacy_search', 'adverse_drug', 'hospital_search', 'greeting', 'symptoms', 'greeting', 'adverse_drug', 'symptoms', 'pharmacy_search', 'medication', 'pharmacy_search', 'blood_pressure', 'options', 'options', 'pharmacy_search', 'options', 'greeting', 'options', 'symptoms', 'pharmacy_search', 'greeting', 'thanks', 'greeting', 'doctor', 'hospital_search', 'pharmacy_search', 'adverse_drug', 'adverse_drug', 'hospital_search', 'adverse_drug', 'doctor', 'blood_pressure', 'greeting', 'blood_pressure_search', 'goodbye', 'thanks', 'blood_pressure', 'hospital_search', 'symptoms', 'blood_pressure_search', 'blood_pressure_search', 'hospital_search', 'pharmacy_search', 'blood_pressure', 'medication', 'doctor', 'doctor', 'adverse_drug', 'goodbye', 'goodbye', 'pharmacy_search', 'goodbye', 'symptoms', 'options', 'goodbye', 'thanks', 'goodbye', 'medication', 'adverse_drug', 'symptoms', 'hospital_search', 'pharmacy_search', 'symptoms', 'blood_pressure', 'greeting', 'doctor', 'blood_pressure', 'options', 'thanks', 'options', 'goodbye', 'hospital_search', 'goodbye', 'symptoms', 'medication', 'doctor', 'options', 'options', 'goodbye', 'thanks', 'doctor', 'options', 'greeting', 'adverse_drug', 'medication', 'doctor', 'options', 'doctor', 'options', 'medication', 'medication', 'symptoms', 'greeting', 'blood_pressure', 'greeting', 'greeting', 'hospital_search', 'medication', 'goodbye', 'hospital_search', 'options', 'hospital_search', 'symptoms', 'options', 'hospital_search', 'options', 'medication', 'blood_pressure', 'adverse_drug', 'medication', 'goodbye', 'pharmacy_search', 'thanks', 'goodbye', 'blood_pressure', 'greeting', 'goodbye', 'greeting', 'thanks', 'thanks', 'blood_pressure', 'pharmacy_search', 'options', 'doctor', 'adverse_drug']\n"
     ]
    }
   ],
   "source": [
    "nn_results = []\n",
    "for utterance in test_df['utterance']: # Generate predictions with the test data for the NN\n",
    "    result = classify_local(utterance)[0][0]\n",
    "    nn_results.append(result)\n",
    "\n",
    "print(nn_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1fabbade-1731-41c5-9cbb-728120934d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,  silhouette_score, multilabel_confusion_matrix as mcm) # Importing sklearn metrics for supervised model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "13494d4c-2be5-4a7f-bf42-08c6a0187a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "023368df-b1d6-4188-8efa-eb0d668385b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN Accuracy: 0.9559748427672956, NN Recall: 0.9582010582010582, NN Precision: 0.963328664799253\n"
     ]
    }
   ],
   "source": [
    "nn_accuracy = accuracy_score(test_df['intent'], nn_results)\n",
    "nn_recall = recall_score(test_df['intent'], nn_results, average='macro')\n",
    "nn_precision = precision_score(test_df['intent'], nn_results, average='macro')\n",
    "results['NN'] = {'accuracy':nn_accuracy,'recall':nn_recall,'precision':nn_precision}\n",
    "print(f'NN Accuracy: {nn_accuracy}, NN Recall: {nn_recall}, NN Precision: {nn_precision}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "34f3aa90-51ed-4a5d-a48c-cc58f41e9b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Accuracy: 0.9748427672955975, RAG Recall: 0.8967032967032966, RAG Precision: 0.9073260073260074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mist861/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "rag_accuracy = accuracy_score(test_df['intent'], rag_results)\n",
    "rag_recall = recall_score(test_df['intent'], rag_results, average='macro')\n",
    "rag_precision = precision_score(test_df['intent'], rag_results, average='macro')\n",
    "results['RAG'] = {'accuracy':rag_accuracy,'recall':rag_recall,'precision':rag_precision}\n",
    "print(f'RAG Accuracy: {rag_accuracy}, RAG Recall: {rag_recall}, RAG Precision: {rag_precision}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "936df99c-c7f3-4f6e-9646-ddaa6be6b5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plotly in /home/mist861/anaconda3/lib/python3.11/site-packages (5.9.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /home/mist861/anaconda3/lib/python3.11/site-packages (from plotly) (8.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaleido in /home/mist861/anaconda3/lib/python3.11/site-packages (0.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install plotly\n",
    "!pip install -U kaleido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3c04bbef-9042-4b56-8ab2-59d9fff5c623",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import kaleido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "91c34ab0-c5c0-4bc1-a7b6-59d003aea9da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NN</th>\n",
       "      <td>0.955975</td>\n",
       "      <td>0.958201</td>\n",
       "      <td>0.963329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAG</th>\n",
       "      <td>0.974843</td>\n",
       "      <td>0.896703</td>\n",
       "      <td>0.907326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     accuracy    recall  precision\n",
       "NN   0.955975  0.958201   0.963329\n",
       "RAG  0.974843  0.896703   0.907326"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame.from_dict(results,orient='index')\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3410ad4f-a163-4d00-ba18-cb7d3bbd4d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "hovertemplate": "variable=accuracy<br>index=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "accuracy",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "accuracy",
         "offsetgroup": "accuracy",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "NN",
          "RAG"
         ],
         "xaxis": "x",
         "y": [
          0.9559748427672956,
          0.9748427672955975
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "variable=recall<br>index=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "recall",
         "marker": {
          "color": "#EF553B",
          "pattern": {
           "shape": ""
          }
         },
         "name": "recall",
         "offsetgroup": "recall",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "NN",
          "RAG"
         ],
         "xaxis": "x",
         "y": [
          0.9582010582010582,
          0.8967032967032966
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "variable=precision<br>index=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "precision",
         "marker": {
          "color": "#00cc96",
          "pattern": {
           "shape": ""
          }
         },
         "name": "precision",
         "offsetgroup": "precision",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "NN",
          "RAG"
         ],
         "xaxis": "x",
         "y": [
          0.963328664799253,
          0.9073260073260074
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "autosize": true,
        "barmode": "group",
        "legend": {
         "title": {
          "text": "Metric"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "<b>Intent Prediction Metrics</b>"
        },
        "xaxis": {
         "anchor": "y",
         "autorange": true,
         "domain": [
          0,
          1
         ],
         "range": [
          -0.5,
          1.5
         ],
         "title": {
          "text": "<b>Model</b>"
         },
         "type": "category"
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "range": [
          0.8,
          1
         ],
         "title": {
          "text": "<b>Percentage</b>"
         },
         "type": "linear"
        }
       }
      },
      "image/png": "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",
      "text/html": [
       "<div>                            <div id=\"2bc69849-1a08-4bcd-9533-ff13ce3a59f9\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"2bc69849-1a08-4bcd-9533-ff13ce3a59f9\")) {                    Plotly.newPlot(                        \"2bc69849-1a08-4bcd-9533-ff13ce3a59f9\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=accuracy<br>index=%{x}<br>value=%{y}<extra></extra>\",\"legendgroup\":\"accuracy\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"accuracy\",\"offsetgroup\":\"accuracy\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[\"NN\",\"RAG\"],\"xaxis\":\"x\",\"y\":[0.9559748427672956,0.9748427672955975],\"yaxis\":\"y\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=recall<br>index=%{x}<br>value=%{y}<extra></extra>\",\"legendgroup\":\"recall\",\"marker\":{\"color\":\"#EF553B\",\"pattern\":{\"shape\":\"\"}},\"name\":\"recall\",\"offsetgroup\":\"recall\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[\"NN\",\"RAG\"],\"xaxis\":\"x\",\"y\":[0.9582010582010582,0.8967032967032966],\"yaxis\":\"y\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=precision<br>index=%{x}<br>value=%{y}<extra></extra>\",\"legendgroup\":\"precision\",\"marker\":{\"color\":\"#00cc96\",\"pattern\":{\"shape\":\"\"}},\"name\":\"precision\",\"offsetgroup\":\"precision\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[\"NN\",\"RAG\"],\"xaxis\":\"x\",\"y\":[0.963328664799253,0.9073260073260074],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"<b>Model</b>\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"<b>Percentage</b>\"},\"range\":[0.8,1]},\"legend\":{\"title\":{\"text\":\"Metric\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"group\",\"title\":{\"text\":\"<b>Intent Prediction Metrics</b>\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('2bc69849-1a08-4bcd-9533-ff13ce3a59f9');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_fig = px.bar(results_df, x=results_df.index, y=results_df.columns, barmode='group') # Define a bar chart, using the combined overal results above except Successes\n",
    "results_fig.update_layout(title_text=f\"<b>Intent Prediction Metrics</b>\") # Add a title to the figure\n",
    "results_fig.update_xaxes(title_text=\"<b>Model</b>\") # Add a title to the x axis\n",
    "results_fig.update_yaxes(title_text=\"<b>Percentage</b>\",range=(0.8,1)) # Add a title to the primary y axis\n",
    "results_fig.update_layout(legend=dict(title=\"Metric\"))\n",
    "#results_fig.update_legend(title_text=\"Metric\") # Add a title to the legend\n",
    "results_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "58264b05-3aaa-4c3e-a395-15248de3660a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_fig.write_image('../results/results_fig.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdaf44e3-b094-47b4-935d-1e6f7e5abc1c",
   "metadata": {},
   "source": [
    "# RAG-LLM Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "430208df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-cpp-python in /home/mist861/anaconda3/lib/python3.11/site-packages (0.2.78)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /home/mist861/anaconda3/lib/python3.11/site-packages (from llama-cpp-python) (4.12.2)\n",
      "Requirement already satisfied: numpy>=1.20.0 in /home/mist861/anaconda3/lib/python3.11/site-packages (from llama-cpp-python) (1.26.4)\n",
      "Requirement already satisfied: diskcache>=5.6.1 in /home/mist861/anaconda3/lib/python3.11/site-packages (from llama-cpp-python) (5.6.3)\n",
      "Requirement already satisfied: jinja2>=2.11.3 in /home/mist861/anaconda3/lib/python3.11/site-packages (from llama-cpp-python) (3.1.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/mist861/anaconda3/lib/python3.11/site-packages (from jinja2>=2.11.3->llama-cpp-python) (2.1.5)\n",
      "Requirement already satisfied: ollama in /home/mist861/anaconda3/lib/python3.11/site-packages (0.2.1)\n",
      "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in /home/mist861/anaconda3/lib/python3.11/site-packages (from ollama) (0.27.0)\n",
      "Requirement already satisfied: anyio in /home/mist861/anaconda3/lib/python3.11/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (4.4.0)\n",
      "Requirement already satisfied: certifi in /home/mist861/anaconda3/lib/python3.11/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in /home/mist861/anaconda3/lib/python3.11/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.0.5)\n",
      "Requirement already satisfied: idna in /home/mist861/anaconda3/lib/python3.11/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (2.10)\n",
      "Requirement already satisfied: sniffio in /home/mist861/anaconda3/lib/python3.11/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/mist861/anaconda3/lib/python3.11/site-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "! CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" pip install llama-cpp-python\n",
    "!pip install ollama # Ollama, to run the LLM used by the RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "2ab0d136-41d5-4fdb-915a-b2e467305e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "b3d4e88d-07e9-437e-b5f8-299658230315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Absolutely, I'd be happy to assist you in finding a suitable doctor! To begin with, please provide some details about your medical needs or preferences. This could include information such as the type of specialist you need (like a cardiologist or dermatologist), any specific location where you'd like to find a clinic or hospital, preferred gender of the healthcare provider if important to you, and insurance coverage considerations.\n",
      "\n",
      "Once I have this information, I can help guide you in searching through available doctor profiles and directories, so that you may easily locate and connect with the right medical professional for your needs. Navigating to the Doctor Search module... Let's get started!\n"
     ]
    }
   ],
   "source": [
    "response = ollama.chat(model='superdrew100/kappa-3-phi-3-4k-instruct-abliterated', messages = [ \n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful medical assistant. Your response should be similar to: I can do that!  Navigating to the Doctor Search module...\"}, \n",
    "    {\"role\": \"user\", \"content\": \"Can you help me find a doctor?\"}\n",
    "]) # Testing the LLM with a manually-created prompt\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "8096f44c-3115-4066-a9d1-5c958924e3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rag_respose(prompt): # Generate a method to use the RAG to call the LLM\n",
    "    intent = rl(prompt).name # First, genreate an intent prediction\n",
    "    if intent != None: # If the predicted intent is not None:\n",
    "        response = responses_df.responses[responses_df['intent'] == intent].item() # Set the suggested response, from the responses_df, to the suggestion for that intent\n",
    "    else:\n",
    "        response = responses_df.responses[responses_df['intent'] == 'noanswer'].item() # Else set it to the suggestion for the noanswer intent\n",
    "    msg = ollama.chat(model='superdrew100/kappa-3-phi-3-4k-instruct-abliterated', messages = [ \n",
    "        {\"role\": \"system\", \"content\": f\"You are a helpful medical assistant. Your response should be similar to: {response}\"}, \n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]) # Invoke the LLM\n",
    "    return msg['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "8e88235a-f74b-4fbc-89ef-8590098096ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Absolutely, I'd be happy to assist you with that!\n",
      "\n",
      "To check your current blood pressure reading, please use a home blood pressure monitor or visit a healthcare provider for an accurate measurement. If using a monitor at home, ensure it is properly calibrated and used according to the manufacturer's instructions. Remember to sit quietly for several minutes before taking the reading as physical activity can temporarily affect your blood pressure levels.\n",
      "\n",
      "If you need any more help locating or understanding information about this, please let me know! I am here to support you.\n"
     ]
    }
   ],
   "source": [
    "response = generate_rag_respose(\"Can you help me find my blood pressure?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098af5ca-a730-4027-a1db-4da82082f5d2",
   "metadata": {},
   "source": [
    "Please note that using a LLM uh...  Introduces some random nonsense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2ca0ce-978c-41fb-aa87-2dc0e446d44a",
   "metadata": {},
   "source": [
    "# NN Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36608df4-31dc-4d37-85a7-a72e952417a0",
   "metadata": {},
   "source": [
    "The below is significantly messier than the above, but it's mostly just for fun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "7dd1a1f2-0c23-46c9-908d-92cd35605f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fold_data(fold,fold_size,df): # Define a method to generate the fold test/train data.  It is identical to the above aside from the first two lines, so most of this will not be commented.\n",
    "    test_df = shuffled_df[fold_size*fold - fold_size:fold_size*fold] # Set the testing data to be the fold, that is, size of the dataset divided by number of folds, with the index window increasing by one fold size each fold\n",
    "    train_df = shuffled_df.loc[~shuffled_df.index.isin(test_df.index)] # Set the training data to be everything else, that is, everything in the original data that doesn't have an index as what's in the testing data\n",
    "    words = [] # Define an array to hold words\n",
    "    #classes = [] # Define an array to hold intents\n",
    "    documents = [] # Define an array to hold documents\n",
    "    ignore_words = ['?'] # The original katana code ignored specifically ? for some reason?  I just left this in.\n",
    "    intents = sorted(list(set(train_df['intent'].unique()))) # Load the set of intents\n",
    "    for intent in intents: # loop through each intent\n",
    "        temp_df = train_df.loc[train_df['intent'] == intent] # Create a temporary dataframe to hold only the utterances for the intent\n",
    "        #temp_utterances = temp_df['utterance'].tolist() # Turn the utterances into a list\n",
    "        for pattern in temp_df['utterance']: # For each utterance/pattern\n",
    "            w = nltk.word_tokenize(pattern) # Tokenize each word in the sentence\n",
    "            words.extend(w) # Add the words to the word array\n",
    "            documents.append((w, intent)) # Add the words, along with their respective intent, to the documents array\n",
    "    #        if intent not in classes:\n",
    "    #            classes.append(intent)\n",
    "        \n",
    "    words = [stemmer.stem(w.lower()) for w in words if w not in ignore_words] # Stem each word, lowercase it, and ignore specifically ?\n",
    "    words = sorted(list(set(words))) # Sort the words\n",
    "    \n",
    "    # documents = combination between patterns and intents\n",
    "    print (len(documents), \"documents\")\n",
    "    # classes = intents\n",
    "    print (len(intents), \"intents\", intents)\n",
    "    # words = all words, vocabulary\n",
    "    print (len(words), \"unique stemmed words\", words)\n",
    "\n",
    "    training = [] # Create an array to store training data\n",
    "    output_empty = [0] * len(intents) # Create an array to mark outputs\n",
    "    \n",
    "    for doc in documents: # For each document (sentence + intent):\n",
    "        bag = [] # Create an array to store a bag of words\n",
    "        pattern_words = doc[0] # Create list of tokenized words for the pattern\n",
    "        pattern_words = [stemmer.stem(word.lower()) for word in pattern_words] # Stem each word\n",
    "        for w in words: # For each word in words\n",
    "            bag.append(1) if w in pattern_words else bag.append(0) # If there is a match in the current pattern, append it\n",
    "        output_row = list(output_empty)  # Get the currently, nulled list of outputs\n",
    "        output_row[intents.index(doc[1])] = 1 # Set the output index that matches the intent to 1\n",
    "        training.append([bag, output_row]) # Append the training data with the bag of words and the output row (which shows which intent the bag is for)\n",
    "        \n",
    "    random.shuffle(training) # Shuffle the training array\n",
    "    train_x, train_y = zip(*training) # Split the training array into bag of words and intent\n",
    "    train_x = np.array(train_x) # Convert the lists, separately, into arrays\n",
    "    train_y = np.array(train_y)\n",
    "    return train_x, train_y, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "858bb8c5-272b-4520-b985-64a10bd103fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_nn(fold,fold_size,shuffled_df): # Generate a method to build the model, like with the above, this is mostly the same as the original NN, so most will not be commented\n",
    "    train_x, train_y, test_df = generate_fold_data(fold,fold_size,shuffled_df) # Generate data using the above method\n",
    "    model = None\n",
    "    model = Sequential() # Define the NN\n",
    "    model.add(Dense(128, input_shape=(len(train_x[0]),), activation='relu')) # Add a relu layer\n",
    "    model.add(Dropout(0.5)) # Add a dropout layer\n",
    "    model.add(Dense(64, activation='relu')) # Add a relu layer\n",
    "    model.add(Dropout(0.5)) # Add a dropout layer\n",
    "    model.add(Dense(len(train_y[0]), activation='softmax')) # Add the prediction softmax layer\n",
    "    # Compile the model.  This was MOSTLY taken from the Katana folks\n",
    "    sgd = SGD(learning_rate=0.01, decay=1e-6, momentum=0.9, nesterov=True) # Define the SGD optimizer.  I had to tweak this slightly, because even the legacy SGD was too new for the original Katana code\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy']) # Compile the model\n",
    "    model.fit(train_x, train_y, epochs=200, batch_size=5, verbose=1) # Fit the model\n",
    "    return model, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "cff2fc5a-3c43-4d3b-9563-007881f3480f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_nn_results(folds): # Generate a method to make predictions and calculate the results.  Like the above two, most of this will not be commented.\n",
    "    results = {} # Create an empty dict to store results\n",
    "    shuffled_df = intent_df.sample(frac=1).reset_index(drop=True) # Shuffle the original data\n",
    "    fold_size = int(len(shuffled_df)/folds) # Calculate the size of each fold\n",
    "    for fold in range(1,folds+1): # For each fold\n",
    "        model, test_df = generate_nn(fold,fold_size,shuffled_df) # Generate a model (and data) by calling the above method\n",
    "        fold_predictions = []\n",
    "        for utterance in test_df['utterance']: # Generate predictions with the test data for the NN\n",
    "            result = classify_local(utterance)[0][0]\n",
    "            fold_predictions.append(result)\n",
    "        nn_accuracy = accuracy_score(test_df['intent'], fold_predictions)\n",
    "        nn_recall = recall_score(test_df['intent'], fold_predictions, average='macro')\n",
    "        nn_precision = precision_score(test_df['intent'], fold_predictions, average='macro')\n",
    "        results[fold] = {'accuracy':nn_accuracy,'recall':nn_recall,'precision':nn_precision}\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "667676e3-a0a7-48ce-9a65-b9a5b70ab359",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636 documents\n",
      "12 intents ['adverse_drug', 'blood_pressure', 'blood_pressure_search', 'doctor', 'goodbye', 'greeting', 'hospital_search', 'medication', 'options', 'pharmacy_search', 'symptoms', 'thanks']\n",
      "662 unique stemmed words ['!', \"''\", \"'d\", \"'m\", \"'re\", \"'s\", \"'ve\", '(', ')', ',', '.', '24-hour', '24/7', '[', ']', '``', 'a', 'abdomin', 'abl', 'about', 'acceiv', 'ach', 'achiev', 'acknowledg', 'acn', 'act', 'adio', 'adiso', 'advers', 'advesr', 'aft', 'afternoon', 'afteroon', 'afterward', 'ahoy', 'ahv', 'aid', 'al', 'almost', 'alright', 'an', 'and', 'answ', 'anticip', 'any', 'anyon', 'appoint', 'apprec', 'apprecy', 'ar', 'area', 'arotnd', 'around', 'arrang', 'as', 'assist', 'assocy', 'aston', 'at', 'attenty', 'avail', 'aw', 'awesom', 'batch', 'bby', 'be', 'been', 'behavy', 'bel', 'bheavy', 'blo', 'blocd', 'blod', 'blood', 'bloow', 'blota', 'bolod', 'bonjo', 'bood', 'book', 'bound', 'bp', 'breath', 'bring', 'brows', 'bu', 'buen', 'bunch', 'buy', 'by', 'bye', 'bye-bxy', 'bye-by', 'ca', 'cad', 'cal', 'calend', 'can', 'cap', 'car', 'cardiolog', 'catch', 'caus', 'cent', 'chant', 'chat', 'checekd', 'check', 'cheerio', 'chek', 'chest', 'chil', 'chos', 'chrissakes', 'ciao', 'ciold', 'city/town', 'cjan', 'clear', 'clin', 'clinfc/hospital', 'clinic/hospital', 'clinically/hospital', 'clos', 'closest', 'cold', 'collect', 'common', 'comp', 'compet', 'comply', 'concern', 'congest', 'congestio', 'consequ', 'consult', 'cont', 'contribu', 'contribut', 'coudl', 'cough', 'could', 'coulk', 'coulnd', 'couzld', 'covid-19', 'covid-k19', 'cpressure', 'cramp', 'crowd', 'cur', 'cvar', 'dat', 'day', 'dctor', 'dee', 'deeplry', 'deeply', 'del', 'describ', 'detail', 'detcail', 'detil', 'dgay', 'diarrhoe', 'did', 'digest', 'direct', 'discomfort', 'dispens', 'dizzy', 'dlat', 'do', 'doabl', 'doct', 'doctro', 'doe', 'doing', 'dokt', 'dont', 'dort', 'downsid', 'drawbac', 'drawback', 'drive-thru', 'drug', 'drugst', 'drugstorf', 'duty', 'e.g.', 'easy', 'ebrea', 'eczem', 'edict', 'efel', 'effdct', 'effect', 'emerg', 'encount', 'enough', 'entir', 'entry', 'epxery', 'etrength', 'ev', 'everyon', 'evfect', 'excel', 'exhibit', 'expect', 'expert', 'expery', 'explain', 'extrem', 'fac', 'facil', 'facilit', 'farewel', 'farewelql', 'fatigu', 'feel', 'fefect', 'fev', 'fil', 'find', 'finsd', 'finyd', 'flu', 'fnd', 'for', 'found', 'from', 'fulfil', 'gap', 'gath', 'gaz', 'gest', 'get', 'giv', 'go', 'gogd', 'going', 'gokod', 'gonig', 'good', 'goodby', 'goodbyt', 'goodnighl', 'goodnight', 'gosod', 'grat', 'gratitud', 'gre', 'greet', 'h', 'handy', 'has', 'hav', 'headach', 'heal', 'healo', 'health', 'healthc', 'healthy', 'heartburn', 'hel', 'hello', 'help', 'helrp', 'hemy', 'hepy', 'her', 'hey', 'hi', 'high', 'himy', 'hist', 'hiy', 'hlelo', 'hopit', 'hopsit', 'hosit', 'hospiot', 'hospit', 'hospitasl', 'hospt', 'hot', 'how', 'hoxw', 'hspital', 'hwat', 'hwody', 'hyi', 'hyw', 'i', \"i'n\", 'icu', 'id', 'impact', 'impend', 'in', 'incred', 'indigest', 'influ', 'inform', 'ins', 'intend', 'irrit', 'is', 'issu', 'it', 'jad', 'joint', 'kidn', 'kind', 'kisnd', 'know', 'known', 'knvwn', 'kwhat', 'largo', 'larynx', 'lat', 'lateb', 'latest', 'let', 'letharg', 'lethmarg', 'level', 'levesl', 'lgst', 'liabl', 'lifesav', 'lifeskv', 'light/noise', 'lighthead', 'lik', 'list', 'liyghthead', 'load', 'loc', 'locn', 'log', 'long', 'look', 'lookup', 'lookut', 'lot', 'ltim', 'maggio', 'mak', 'malay', 'man', 'many', 'may', 'me', 'meac', 'mean', 'meas', 'med', 'medicatifon', 'medicaton', 'medicc', 'medicin', 'medicinq', 'meet', 'mer', 'met', 'mfy', 'might', 'mil', 'mod', 'modlu', 'morn', 'mtabl', 'much', 'musc', 'must', 'my', \"n't\", 'nar', 'narby', 'nause', 'near', 'nearby', 'nearest', 'nee', 'neg', 'neighb', 'neighbo', 'new', 'newest', 'next', 'nic', 'nicq', 'nneg', 'nnxt', 'nomin', 'norm', 'nos', 'now', 'num', 'numb', 'oblgy', 'oblig', 'occ', 'oct', 'od', 'of', 'off', 'oing', 'ok', 'okp', 'on', 'op', 'oprescrib', 'or', 'ord', 'oson', 'ot', 'out', 'outcom', 'outlin', 'over-the-count', 'overal', 'ow', 'pain', 'painb', 'pat', 'paty', 'pbin', 'peac', 'pedy', 'peharm', 'persist', 'persistnet', 'pfrescription', 'pharm', 'pharmac', 'pharmaceut', 'pharmacio', 'pharmahcy', 'phharmacy', 'phramacies', 'phrmacy', 'phys', 'physc', 'physy', 'pick', 'pickk', 'pickup', 'pinpoint', 'pleas', 'point', 'pois', 'porject', 'poss', 'pot', 'pqtient', 'prep', 'preqss', 'prescrib', 'prescripg', 'press', 'profess', 'proficy', 'profound', 'project', 'provid', 'providevr', 'puffy', 'quick', 'quo', 'rang', 'rash', 'react', 'read', 'readihg', 'ready', 'real', 'reat', 'rec', 'recogn', 'refil', 'reflil', 'refresh', 'reg', 'reil', 'rel', 'reord', 'reoult', 'repercuss', 'repl', 'report', 'reqeust', 'request', 'requir', 'research', 'result', 'rev', 'right', 'risk', 'rnge', 'room', 'rplenish', 'runny', 'salut', 'salutatoin', 'say', 'sbe', 'sce', 'schedule', 'scratchy', 'seach', 'searah', 'search', 'searhc', 'see', 'seg', 'sensipt', 'sensit', 'serv', 'sharm', 'shiv', 'short', 'shot', 'should', 'show', 'sid', 'sign', 'sik', 'simpl', 'skil', 'skin', 'smight', 'so', 'soon', 'sor', 'speak', 'spec', 'special', 'spezc', 'sress', 'stabl', 'stat', 'strengths', 'strong', 'stubborn', 'such', 'suit', 'supply', 'support', 'surgery', 'swol', 'systolic/diastol', 'ta', 'tabl', 'tableau', 'tae', 'tahnk', 'tak', 'tal', 'talk', 'task', 'tech', 'techn', 'tel', 'telemedicin', 'term', \"tha'ts\", 'than', 'thank', 'thansk', 'thantk', 'thanv', 'that', 'the', 'ther', 'thi', 'think', 'thinmk', 'thnk', 'throat', 'thvnks', 'tier', 'tight', 'til', 'tim', 'tir', 'to', 'today', 'told', 'town/town', 'tranquil', 'transf', 'transfus', 'tranusf', 'tre', 'trhoat', 'troubl', 'typ', 'uh', 'undesir', 'unear', 'unearth', 'unfav', 'unfavo', 'unintend', 'uninvit', 'unit', 'until', 'unus', 'unw', 'unwante', 'up', 'upd', 'uregnt', 'urg', 'us', 'usng', 'util', 'vaccin', 'vay', 'ver', 'verdict', 'very', 'vomit', 'waht', 'want', 'watch', 'weak', 'wel', 'welcom', 'wha', 'whab', 'whac', 'whaot', 'whar', 'what', 'whaut', 'wheez', 'wher', 'whereby', 'whereof', 'wheru', 'whez', 'whgt', 'which', 'whil', 'whnt', 'whta', 'with', 'within', 'wlecom', 'wo', 'would', 'wthat', 'ya', 'yao', 'yfev', 'yo', 'you']\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mist861/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n",
      "/home/mist861/anaconda3/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py:33: UserWarning:\n",
      "\n",
      "Argument `decay` is no longer supported and will be ignored.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1454 - loss: 2.4171   \n",
      "Epoch 2/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 546us/step - accuracy: 0.4096 - loss: 1.7059\n",
      "Epoch 3/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 551us/step - accuracy: 0.5987 - loss: 1.1582\n",
      "Epoch 4/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566us/step - accuracy: 0.7231 - loss: 0.8094\n",
      "Epoch 5/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - accuracy: 0.7729 - loss: 0.5898\n",
      "Epoch 6/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - accuracy: 0.8105 - loss: 0.5035\n",
      "Epoch 7/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step - accuracy: 0.7982 - loss: 0.4853\n",
      "Epoch 8/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 547us/step - accuracy: 0.8441 - loss: 0.4040\n",
      "Epoch 9/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559us/step - accuracy: 0.8654 - loss: 0.3676\n",
      "Epoch 10/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750us/step - accuracy: 0.8761 - loss: 0.3338\n",
      "Epoch 11/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571us/step - accuracy: 0.9010 - loss: 0.3181\n",
      "Epoch 12/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - accuracy: 0.8869 - loss: 0.3334\n",
      "Epoch 13/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.9394 - loss: 0.1934\n",
      "Epoch 14/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 546us/step - accuracy: 0.9197 - loss: 0.2268\n",
      "Epoch 15/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - accuracy: 0.9410 - loss: 0.1909\n",
      "Epoch 16/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.9502 - loss: 0.1556\n",
      "Epoch 17/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543us/step - accuracy: 0.9385 - loss: 0.1770\n",
      "Epoch 18/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - accuracy: 0.9278 - loss: 0.1723\n",
      "Epoch 19/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - accuracy: 0.9455 - loss: 0.1470\n",
      "Epoch 20/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554us/step - accuracy: 0.9404 - loss: 0.1620\n",
      "Epoch 21/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - accuracy: 0.9428 - loss: 0.1424\n",
      "Epoch 22/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569us/step - accuracy: 0.9648 - loss: 0.1336\n",
      "Epoch 23/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step - accuracy: 0.9651 - loss: 0.1205\n",
      "Epoch 24/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565us/step - accuracy: 0.9541 - loss: 0.1343\n",
      "Epoch 25/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594us/step - accuracy: 0.9707 - loss: 0.0899\n",
      "Epoch 26/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - accuracy: 0.9762 - loss: 0.0804\n",
      "Epoch 27/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step - accuracy: 0.9719 - loss: 0.0808\n",
      "Epoch 28/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 549us/step - accuracy: 0.9625 - loss: 0.1076\n",
      "Epoch 29/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554us/step - accuracy: 0.9656 - loss: 0.0949 \n",
      "Epoch 30/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - accuracy: 0.9711 - loss: 0.0989 \n",
      "Epoch 31/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - accuracy: 0.9693 - loss: 0.0756\n",
      "Epoch 32/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - accuracy: 0.9590 - loss: 0.1124\n",
      "Epoch 33/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - accuracy: 0.9774 - loss: 0.0753\n",
      "Epoch 34/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559us/step - accuracy: 0.9901 - loss: 0.0520 \n",
      "Epoch 35/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - accuracy: 0.9617 - loss: 0.0827\n",
      "Epoch 36/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553us/step - accuracy: 0.9761 - loss: 0.0678\n",
      "Epoch 37/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - accuracy: 0.9993 - loss: 0.0328\n",
      "Epoch 38/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 549us/step - accuracy: 0.9729 - loss: 0.0643\n",
      "Epoch 39/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 546us/step - accuracy: 0.9660 - loss: 0.0724\n",
      "Epoch 40/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553us/step - accuracy: 0.9939 - loss: 0.0222 \n",
      "Epoch 41/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541us/step - accuracy: 0.9886 - loss: 0.0578\n",
      "Epoch 42/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 730us/step - accuracy: 0.9802 - loss: 0.0555\n",
      "Epoch 43/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561us/step - accuracy: 0.9886 - loss: 0.0614\n",
      "Epoch 44/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 545us/step - accuracy: 0.9665 - loss: 0.0735\n",
      "Epoch 45/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544us/step - accuracy: 0.9940 - loss: 0.0273\n",
      "Epoch 46/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 552us/step - accuracy: 0.9795 - loss: 0.0658\n",
      "Epoch 47/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - accuracy: 0.9835 - loss: 0.0447 \n",
      "Epoch 48/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596us/step - accuracy: 0.9835 - loss: 0.0334 \n",
      "Epoch 49/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606us/step - accuracy: 0.9855 - loss: 0.0342\n",
      "Epoch 50/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586us/step - accuracy: 0.9687 - loss: 0.0951\n",
      "Epoch 51/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step - accuracy: 0.9784 - loss: 0.0505 \n",
      "Epoch 52/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735us/step - accuracy: 0.9902 - loss: 0.0358\n",
      "Epoch 53/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 708us/step - accuracy: 0.9934 - loss: 0.0249\n",
      "Epoch 54/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - accuracy: 0.9893 - loss: 0.0230 \n",
      "Epoch 55/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577us/step - accuracy: 0.9783 - loss: 0.0492 \n",
      "Epoch 56/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - accuracy: 0.9947 - loss: 0.0228 \n",
      "Epoch 57/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596us/step - accuracy: 0.9933 - loss: 0.0190 \n",
      "Epoch 58/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step - accuracy: 0.9935 - loss: 0.0285 \n",
      "Epoch 59/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - accuracy: 0.9665 - loss: 0.0975\n",
      "Epoch 60/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - accuracy: 0.9911 - loss: 0.0450\n",
      "Epoch 61/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - accuracy: 0.9915 - loss: 0.0230 \n",
      "Epoch 62/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - accuracy: 0.9970 - loss: 0.0223 \n",
      "Epoch 63/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step - accuracy: 0.9910 - loss: 0.0263\n",
      "Epoch 64/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 725us/step - accuracy: 0.9941 - loss: 0.0156 \n",
      "Epoch 65/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554us/step - accuracy: 0.9913 - loss: 0.0210\n",
      "Epoch 66/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step - accuracy: 0.9923 - loss: 0.0168 \n",
      "Epoch 67/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596us/step - accuracy: 0.9884 - loss: 0.0253\n",
      "Epoch 68/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579us/step - accuracy: 0.9965 - loss: 0.0206\n",
      "Epoch 69/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559us/step - accuracy: 0.9992 - loss: 0.0112 \n",
      "Epoch 70/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - accuracy: 0.9926 - loss: 0.0294\n",
      "Epoch 71/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571us/step - accuracy: 0.9768 - loss: 0.0795 \n",
      "Epoch 72/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - accuracy: 0.9885 - loss: 0.0376\n",
      "Epoch 73/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step - accuracy: 0.9868 - loss: 0.0344\n",
      "Epoch 74/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 549us/step - accuracy: 0.9935 - loss: 0.0224 \n",
      "Epoch 75/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559us/step - accuracy: 0.9969 - loss: 0.0172\n",
      "Epoch 76/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - accuracy: 0.9956 - loss: 0.0184 \n",
      "Epoch 77/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579us/step - accuracy: 0.9994 - loss: 0.0076\n",
      "Epoch 78/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - accuracy: 0.9987 - loss: 0.0122 \n",
      "Epoch 79/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566us/step - accuracy: 0.9961 - loss: 0.0229 \n",
      "Epoch 80/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - accuracy: 0.9983 - loss: 0.0109 \n",
      "Epoch 81/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726us/step - accuracy: 0.9900 - loss: 0.0256\n",
      "Epoch 82/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - accuracy: 0.9905 - loss: 0.0167\n",
      "Epoch 83/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - accuracy: 0.9958 - loss: 0.0133 \n",
      "Epoch 84/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591us/step - accuracy: 0.9936 - loss: 0.0215 \n",
      "Epoch 85/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578us/step - accuracy: 0.9922 - loss: 0.0416\n",
      "Epoch 86/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - accuracy: 0.9962 - loss: 0.0087 \n",
      "Epoch 87/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - accuracy: 0.9917 - loss: 0.0207 \n",
      "Epoch 88/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543us/step - accuracy: 0.9976 - loss: 0.0073 \n",
      "Epoch 89/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - accuracy: 0.9980 - loss: 0.0171\n",
      "Epoch 90/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - accuracy: 0.9964 - loss: 0.0112\n",
      "Epoch 91/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594us/step - accuracy: 0.9903 - loss: 0.0242\n",
      "Epoch 92/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554us/step - accuracy: 0.9925 - loss: 0.0306 \n",
      "Epoch 93/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566us/step - accuracy: 0.9951 - loss: 0.0168 \n",
      "Epoch 94/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576us/step - accuracy: 0.9907 - loss: 0.0277 \n",
      "Epoch 95/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step - accuracy: 0.9939 - loss: 0.0134\n",
      "Epoch 96/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - accuracy: 0.9993 - loss: 0.0131 \n",
      "Epoch 97/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608us/step - accuracy: 0.9977 - loss: 0.0082 \n",
      "Epoch 98/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - accuracy: 0.9903 - loss: 0.0304 \n",
      "Epoch 99/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - accuracy: 0.9986 - loss: 0.0076 \n",
      "Epoch 100/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574us/step - accuracy: 0.9936 - loss: 0.0183 \n",
      "Epoch 101/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - accuracy: 0.9911 - loss: 0.0285 \n",
      "Epoch 102/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596us/step - accuracy: 0.9989 - loss: 0.0132\n",
      "Epoch 103/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 551us/step - accuracy: 0.9958 - loss: 0.0338\n",
      "Epoch 104/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - accuracy: 0.9909 - loss: 0.0246\n",
      "Epoch 105/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step - accuracy: 0.9968 - loss: 0.0118\n",
      "Epoch 106/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592us/step - accuracy: 0.9952 - loss: 0.0178\n",
      "Epoch 107/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - accuracy: 0.9953 - loss: 0.0124\n",
      "Epoch 108/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - accuracy: 0.9828 - loss: 0.0622\n",
      "Epoch 109/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591us/step - accuracy: 0.9963 - loss: 0.0106 \n",
      "Epoch 110/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586us/step - accuracy: 0.9850 - loss: 0.0238 \n",
      "Epoch 111/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577us/step - accuracy: 0.9972 - loss: 0.0080 \n",
      "Epoch 112/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 545us/step - accuracy: 0.9994 - loss: 0.0073 \n",
      "Epoch 113/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - accuracy: 0.9953 - loss: 0.0173\n",
      "Epoch 114/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 551us/step - accuracy: 0.9838 - loss: 0.0549\n",
      "Epoch 115/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 551us/step - accuracy: 0.9979 - loss: 0.0126\n",
      "Epoch 116/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 552us/step - accuracy: 0.9949 - loss: 0.0215 \n",
      "Epoch 117/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609us/step - accuracy: 0.9963 - loss: 0.0155 \n",
      "Epoch 118/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596us/step - accuracy: 0.9963 - loss: 0.0139\n",
      "Epoch 119/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553us/step - accuracy: 0.9965 - loss: 0.0165\n",
      "Epoch 120/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - accuracy: 0.9936 - loss: 0.0226 \n",
      "Epoch 121/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540us/step - accuracy: 0.9854 - loss: 0.0341 \n",
      "Epoch 122/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544us/step - accuracy: 0.9927 - loss: 0.0151\n",
      "Epoch 123/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - accuracy: 0.9945 - loss: 0.0195\n",
      "Epoch 124/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591us/step - accuracy: 0.9918 - loss: 0.0399\n",
      "Epoch 125/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594us/step - accuracy: 0.9972 - loss: 0.0178 \n",
      "Epoch 126/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586us/step - accuracy: 0.9968 - loss: 0.0129\n",
      "Epoch 127/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566us/step - accuracy: 0.9862 - loss: 0.0242\n",
      "Epoch 128/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544us/step - accuracy: 0.9842 - loss: 0.0420\n",
      "Epoch 129/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 549us/step - accuracy: 0.9861 - loss: 0.0313 \n",
      "Epoch 130/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 751us/step - accuracy: 0.9896 - loss: 0.0337 \n",
      "Epoch 131/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544us/step - accuracy: 0.9989 - loss: 0.0101\n",
      "Epoch 132/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - accuracy: 0.9873 - loss: 0.0164 \n",
      "Epoch 133/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step - accuracy: 0.9997 - loss: 0.0066 \n",
      "Epoch 134/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548us/step - accuracy: 0.9876 - loss: 0.0464\n",
      "Epoch 135/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541us/step - accuracy: 0.9950 - loss: 0.0147 \n",
      "Epoch 136/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566us/step - accuracy: 0.9959 - loss: 0.0101\n",
      "Epoch 137/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541us/step - accuracy: 0.9967 - loss: 0.0163 \n",
      "Epoch 138/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - accuracy: 0.9967 - loss: 0.0146\n",
      "Epoch 139/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 552us/step - accuracy: 0.9987 - loss: 0.0098 \n",
      "Epoch 140/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544us/step - accuracy: 0.9992 - loss: 0.0061 \n",
      "Epoch 141/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 0.9904 - loss: 0.0426\n",
      "Epoch 142/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 547us/step - accuracy: 0.9963 - loss: 0.0135 \n",
      "Epoch 143/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - accuracy: 0.9913 - loss: 0.0174 \n",
      "Epoch 144/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - accuracy: 0.9935 - loss: 0.0262 \n",
      "Epoch 145/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - accuracy: 0.9948 - loss: 0.0150 \n",
      "Epoch 146/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561us/step - accuracy: 0.9919 - loss: 0.0250 \n",
      "Epoch 147/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step - accuracy: 0.9934 - loss: 0.0158\n",
      "Epoch 148/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544us/step - accuracy: 0.9991 - loss: 0.0135\n",
      "Epoch 149/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 547us/step - accuracy: 1.0000 - loss: 0.0081\n",
      "Epoch 150/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576us/step - accuracy: 0.9966 - loss: 0.0258 \n",
      "Epoch 151/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - accuracy: 0.9978 - loss: 0.0059 \n",
      "Epoch 152/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 547us/step - accuracy: 0.9959 - loss: 0.0085 \n",
      "Epoch 153/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 550us/step - accuracy: 0.9975 - loss: 0.0078 \n",
      "Epoch 154/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 0.9971 - loss: 0.0087 \n",
      "Epoch 155/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 713us/step - accuracy: 0.9969 - loss: 0.0154 \n",
      "Epoch 156/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - accuracy: 0.9679 - loss: 0.1092 \n",
      "Epoch 157/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step - accuracy: 0.9897 - loss: 0.0225 \n",
      "Epoch 158/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - accuracy: 0.9945 - loss: 0.0169 \n",
      "Epoch 159/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 549us/step - accuracy: 0.9820 - loss: 0.0378 \n",
      "Epoch 160/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - accuracy: 0.9937 - loss: 0.0297\n",
      "Epoch 161/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542us/step - accuracy: 1.0000 - loss: 0.0058 \n",
      "Epoch 162/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - accuracy: 0.9945 - loss: 0.0232 \n",
      "Epoch 163/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - accuracy: 0.9702 - loss: 0.1265\n",
      "Epoch 164/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566us/step - accuracy: 0.9934 - loss: 0.0303\n",
      "Epoch 165/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 546us/step - accuracy: 0.9945 - loss: 0.0135 \n",
      "Epoch 166/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - accuracy: 0.9995 - loss: 0.0086 \n",
      "Epoch 167/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561us/step - accuracy: 0.9809 - loss: 0.0706 \n",
      "Epoch 168/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571us/step - accuracy: 0.9951 - loss: 0.0249 \n",
      "Epoch 169/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - accuracy: 0.9943 - loss: 0.0118 \n",
      "Epoch 170/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621us/step - accuracy: 0.9863 - loss: 0.0272 \n",
      "Epoch 171/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - accuracy: 0.9938 - loss: 0.0378 \n",
      "Epoch 172/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - accuracy: 0.9864 - loss: 0.0235 \n",
      "Epoch 173/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574us/step - accuracy: 0.9917 - loss: 0.0320\n",
      "Epoch 174/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576us/step - accuracy: 0.9895 - loss: 0.0163 \n",
      "Epoch 175/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 551us/step - accuracy: 0.9815 - loss: 0.0894 \n",
      "Epoch 176/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - accuracy: 0.9783 - loss: 0.0673 \n",
      "Epoch 177/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574us/step - accuracy: 0.9890 - loss: 0.0386 \n",
      "Epoch 178/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 706us/step - accuracy: 0.9911 - loss: 0.0244\n",
      "Epoch 179/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559us/step - accuracy: 0.9953 - loss: 0.0244\n",
      "Epoch 180/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - accuracy: 0.9929 - loss: 0.0169\n",
      "Epoch 181/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step - accuracy: 0.9890 - loss: 0.0239 \n",
      "Epoch 182/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559us/step - accuracy: 0.9975 - loss: 0.0111\n",
      "Epoch 183/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586us/step - accuracy: 0.9930 - loss: 0.0288\n",
      "Epoch 184/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - accuracy: 0.9981 - loss: 0.0122 \n",
      "Epoch 185/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558us/step - accuracy: 0.9974 - loss: 0.0096 \n",
      "Epoch 186/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 549us/step - accuracy: 0.9984 - loss: 0.0129 \n",
      "Epoch 187/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 550us/step - accuracy: 0.9890 - loss: 0.0158 \n",
      "Epoch 188/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - accuracy: 0.9926 - loss: 0.0197\n",
      "Epoch 189/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - accuracy: 0.9951 - loss: 0.0217\n",
      "Epoch 190/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - accuracy: 0.9953 - loss: 0.0131 \n",
      "Epoch 191/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541us/step - accuracy: 0.9977 - loss: 0.0199\n",
      "Epoch 192/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538us/step - accuracy: 0.9886 - loss: 0.0564\n",
      "Epoch 193/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - accuracy: 0.9791 - loss: 0.0600 \n",
      "Epoch 194/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step - accuracy: 0.9961 - loss: 0.0177\n",
      "Epoch 195/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step - accuracy: 0.9937 - loss: 0.0333\n",
      "Epoch 196/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548us/step - accuracy: 0.9972 - loss: 0.0153 \n",
      "Epoch 197/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - accuracy: 0.9989 - loss: 0.0099\n",
      "Epoch 198/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577us/step - accuracy: 0.9892 - loss: 0.0191\n",
      "Epoch 199/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 547us/step - accuracy: 0.9973 - loss: 0.0115 \n",
      "Epoch 200/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594us/step - accuracy: 0.9938 - loss: 0.0210 \n",
      "found in bag: ``\n",
      "found in bag: 'm\n",
      "found in bag: so\n",
      "found in bag: thank\n",
      "found in bag: for\n",
      "found in bag: [\n",
      "found in bag: spec\n",
      "found in bag: gest\n",
      "found in bag: or\n",
      "found in bag: help\n",
      "found in bag: ]\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: ar\n",
      "found in bag: yo\n",
      "found in bag: dext\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: kind\n",
      "found in bag: of\n",
      "found in bag: react\n",
      "found in bag: i\n",
      "found in bag: expery\n",
      "found in bag: from\n",
      "found in bag: thi\n",
      "found in bag: med\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: op\n",
      "found in bag: advers\n",
      "found in bag: drug\n",
      "found in bag: mod\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: 's\n",
      "found in bag: the\n",
      "found in bag: rul\n",
      "found in bag: on\n",
      "found in bag: my\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: today\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: kind\n",
      "found in bag: of\n",
      "found in bag: neg\n",
      "found in bag: react\n",
      "found in bag: should\n",
      "found in bag: i\n",
      "found in bag: be\n",
      "found in bag: prep\n",
      "found in bag: for\n",
      "found in bag: with\n",
      "found in bag: thi\n",
      "found in bag: drug\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: dat\n",
      "found in bag: man\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: hav\n",
      "found in bag: chest\n",
      "found in bag: tighvt\n",
      "found in bag: and\n",
      "found in bag: discomfort\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: ar\n",
      "found in bag: yo\n",
      "found in bag: profess\n",
      "found in bag: skils\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: pharm\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: 'd\n",
      "found in bag: lik\n",
      "found in bag: to\n",
      "found in bag: wond\n",
      "found in bag: a\n",
      "found in bag: prescrib\n",
      "found in bag: refil\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: tak\n",
      "found in bag: car\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: 'm\n",
      "found in bag: look\n",
      "found in bag: to\n",
      "found in bag: see\n",
      "found in bag: a\n",
      "found in bag: healthc\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: find\n",
      "found in bag: pharm\n",
      "found in bag: with\n",
      "found in bag: covid-19\n",
      "found in bag: vaccin\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: is\n",
      "found in bag: a\n",
      "found in bag: phys\n",
      "found in bag: avail\n",
      "found in bag: to\n",
      "found in bag: me\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: awesom\n",
      "found in bag: ,\n",
      "found in bag: xthanks\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: loch\n",
      "found in bag: drugst\n",
      "found in bag: in\n",
      "found in bag: [\n",
      "found in bag: neighb\n",
      "found in bag: ]\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: 's\n",
      "found in bag: the\n",
      "found in bag: stat\n",
      "found in bag: of\n",
      "found in bag: my\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: hoy\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: whmt\n",
      "found in bag: ar\n",
      "found in bag: yo\n",
      "found in bag: strong\n",
      "found in bag: point\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: 'd\n",
      "found in bag: lik\n",
      "found in bag: to\n",
      "found in bag: request\n",
      "found in bag: a\n",
      "found in bag: refil\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: could\n",
      "found in bag: you\n",
      "found in bag: check\n",
      "found in bag: my\n",
      "found in bag: blohod\n",
      "found in bag: press\n",
      "found in bag: ,\n",
      "found in bag: pleas\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: feel\n",
      "found in bag: and\n",
      "found in bag: lighthead\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: hav\n",
      "found in bag: abdoin\n",
      "found in bag: pain\n",
      "found in bag: and\n",
      "found in bag: cramp\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: ar\n",
      "found in bag: yo\n",
      "found in bag: tal\n",
      "found in bag: and\n",
      "found in bag: skil\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: can\n",
      "found in bag: you\n",
      "found in bag: rpovid\n",
      "found in bag: me\n",
      "found in bag: with\n",
      "found in bag: my\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: meas\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: could\n",
      "found in bag: you\n",
      "found in bag: list\n",
      "found in bag: the\n",
      "found in bag: pot\n",
      "found in bag: drawback\n",
      "found in bag: or\n",
      "found in bag: downsid\n",
      "found in bag: of\n",
      "found in bag: us\n",
      "found in bag: thi\n",
      "found in bag: drug\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: 'm\n",
      "found in bag: expery\n",
      "found in bag: diarrhe\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: ar\n",
      "found in bag: yo\n",
      "found in bag: techn\n",
      "found in bag: skil\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: is\n",
      "found in bag: it\n",
      "found in bag: poss\n",
      "found in bag: to\n",
      "found in bag: get\n",
      "found in bag: a\n",
      "found in bag: rpescrib\n",
      "found in bag: fil\n",
      "found in bag: today\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: up\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: ciao\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: pharm\n",
      "found in bag: clos\n",
      "found in bag: to\n",
      "found in bag: my\n",
      "found in bag: loc\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: good\n",
      "found in bag: ev\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: nearby\n",
      "found in bag: hospit\n",
      "found in bag: opn\n",
      "found in bag: now\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: til\n",
      "found in bag: next\n",
      "found in bag: tim\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: 'm\n",
      "found in bag: cough\n",
      "found in bag: and\n",
      "found in bag: wheez\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: 'm\n",
      "found in bag: feel\n",
      "found in bag: unus\n",
      "found in bag: cold\n",
      "found in bag: or\n",
      "found in bag: hot\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: search\n",
      "found in bag: for\n",
      "found in bag: hospit\n",
      "found in bag: to\n",
      "found in bag: transf\n",
      "found in bag: paty\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: can\n",
      "found in bag: you\n",
      "found in bag: prep\n",
      "found in bag: my\n",
      "found in bag: prescrip\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: how\n",
      "found in bag: is\n",
      "found in bag: my\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: search\n",
      "found in bag: today\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: caa't\n",
      "found in bag: thank\n",
      "found in bag: you\n",
      "found in bag: enough\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: search\n",
      "found in bag: for\n",
      "found in bag: that\n",
      "found in bag: off\n",
      "found in bag: telemedicin\n",
      "found in bag: serv\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: catch\n",
      "found in bag: you\n",
      "found in bag: lat\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: frisk\n",
      "found in bag: for\n",
      "found in bag: hospit\n",
      "found in bag: with\n",
      "found in bag: urg\n",
      "found in bag: car\n",
      "found in bag: serv\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "found in bag: ``\n",
      "found in bag: is\n",
      "found in bag: my\n",
      "found in bag: med\n",
      "found in bag: avail\n",
      "found in bag: for\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: heh\n",
      "found in bag: ,\n",
      "found in bag: how\n",
      "found in bag: ar\n",
      "found in bag: you\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: ar\n",
      "found in bag: yo\n",
      "found in bag: area\n",
      "found in bag: of\n",
      "found in bag: experty\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: search\n",
      "found in bag: pharm\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: how\n",
      "found in bag: to\n",
      "found in bag: ver\n",
      "found in bag: advers\n",
      "found in bag: drug\n",
      "found in bag: react\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: grat\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: ar\n",
      "found in bag: my\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: level\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: hav\n",
      "found in bag: a\n",
      "found in bag: good\n",
      "found in bag: on\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: loc\n",
      "found in bag: a\n",
      "found in bag: hospit\n",
      "found in bag: nearby\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: look\n",
      "found in bag: for\n",
      "found in bag: a\n",
      "found in bag: hospit\n",
      "found in bag: that\n",
      "found in bag: 's\n",
      "found in bag: op\n",
      "found in bag: 24/7\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: do\n",
      "found in bag: you\n",
      "found in bag: excel\n",
      "found in bag: at\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: real\n",
      "found in bag: grat\n",
      "found in bag: it\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: could\n",
      "found in bag: you\n",
      "found in bag: leav\n",
      "found in bag: me\n",
      "found in bag: know\n",
      "found in bag: my\n",
      "found in bag: cur\n",
      "found in bag: bp\n",
      "found in bag: numb\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: whereof\n",
      "found in bag: ar\n",
      "found in bag: you\n",
      "found in bag: cap\n",
      "found in bag: of\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: do\n",
      "found in bag: you\n",
      "found in bag: hav\n",
      "found in bag: the\n",
      "found in bag: latest\n",
      "found in bag: read\n",
      "found in bag: of\n",
      "found in bag: my\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: got\n",
      "found in bag: ta\n",
      "found in bag: you\n",
      "found in bag: on\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: geet\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: my\n",
      "found in bag: joint\n",
      "found in bag: ar\n",
      "found in bag: swol\n",
      "found in bag: and\n",
      "found in bag: pain\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: salut\n",
      "found in bag: ,\n",
      "found in bag: how\n",
      "found in bag: hav\n",
      "found in bag: you\n",
      "found in bag: been\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: hello\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: feel\n",
      "found in bag: extrem\n",
      "found in bag: tir\n",
      "found in bag: and\n",
      "found in bag: letharg\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: until\n",
      "found in bag: next\n",
      "found in bag: tim\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: much\n",
      "found in bag: requir\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: show\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: esult\n",
      "found in bag: for\n",
      "found in bag: paty\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: do\n",
      "found in bag: you\n",
      "found in bag: excel\n",
      "found in bag: at\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: pleas\n",
      "found in bag: prep\n",
      "found in bag: my\n",
      "found in bag: med\n",
      "found in bag: for\n",
      "found in bag: me\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: you\n",
      "found in bag: 're\n",
      "found in bag: a\n",
      "found in bag: savio\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: find\n",
      "found in bag: pharm\n",
      "found in bag: with\n",
      "found in bag: covid-19\n",
      "found in bag: vaccy\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: could\n",
      "found in bag: you\n",
      "found in bag: detail\n",
      "found in bag: the\n",
      "found in bag: sid\n",
      "found in bag: effect\n",
      "found in bag: that\n",
      "found in bag: us\n",
      "found in bag: common\n",
      "found in bag: report\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: is\n",
      "found in bag: my\n",
      "found in bag: prescrib\n",
      "found in bag: prep\n",
      "found in bag: for\n",
      "found in bag: pickup\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: could\n",
      "found in bag: i\n",
      "found in bag: see\n",
      "found in bag: a\n",
      "found in bag: doct\n",
      "found in bag: ,\n",
      "found in bag: pleas\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: can\n",
      "found in bag: you\n",
      "found in bag: fil\n",
      "found in bag: my\n",
      "found in bag: prescrib\n",
      "found in bag: for\n",
      "found in bag: me\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: many\n",
      "found in bag: thank\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: find\n",
      "found in bag: ppharmacies\n",
      "found in bag: with\n",
      "found in bag: drive-thru\n",
      "found in bag: serv\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: ar\n",
      "found in bag: ther\n",
      "found in bag: any\n",
      "found in bag: concern\n",
      "found in bag: with\n",
      "found in bag: my\n",
      "found in bag: chrissakes\n",
      "found in bag: press\n",
      "found in bag: read\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: pleas\n",
      "found in bag: prep\n",
      "found in bag: my\n",
      "found in bag: medicin\n",
      "found in bag: for\n",
      "found in bag: me\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: noee\n",
      "found in bag: to\n",
      "found in bag: speak\n",
      "found in bag: with\n",
      "found in bag: a\n",
      "found in bag: doct\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: ar\n",
      "found in bag: yo\n",
      "found in bag: technicd\n",
      "found in bag: skil\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: lookup\n",
      "found in bag: for\n",
      "found in bag: hospit\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: thank\n",
      "found in bag: a\n",
      "found in bag: bunch\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: hospit\n",
      "found in bag: lookup\n",
      "found in bag: for\n",
      "found in bag: paty\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: help\n",
      "found in bag: you\n",
      "found in bag: furn\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: could\n",
      "found in bag: i\n",
      "found in bag: see\n",
      "found in bag: a\n",
      "found in bag: doct\n",
      "found in bag: ,\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: search\n",
      "found in bag: for\n",
      "found in bag: pharm\n",
      "found in bag: with\n",
      "found in bag: flu\n",
      "found in bag: shot\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: ps\n",
      "found in bag: ther\n",
      "found in bag: a\n",
      "found in bag: doct\n",
      "found in bag: avail\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: thank\n",
      "found in bag: a\n",
      "found in bag: mil\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: wher\n",
      "found in bag: is\n",
      "found in bag: the\n",
      "found in bag: nearest\n",
      "found in bag: hospit\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: 'm\n",
      "found in bag: so\n",
      "found in bag: thank\n",
      "found in bag: for\n",
      "found in bag: [\n",
      "found in bag: spec\n",
      "found in bag: gest\n",
      "found in bag: or\n",
      "found in bag: help\n",
      "found in bag: ]\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: seh\n",
      "found in bag: you\n",
      "found in bag: lat\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: wat\n",
      "found in bag: you\n",
      "found in bag: can\n",
      "found in bag: do\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: search\n",
      "found in bag: for\n",
      "found in bag: med\n",
      "found in bag: cent\n",
      "found in bag: surround\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: loc\n",
      "found in bag: hosp\n",
      "found in bag: in\n",
      "found in bag: [\n",
      "found in bag: neighb\n",
      "found in bag: ]\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: locta\n",
      "found in bag: pharm\n",
      "found in bag: with\n",
      "found in bag: a\n",
      "found in bag: pharm\n",
      "found in bag: techn\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: neighbo\n",
      "found in bag: hospit\n",
      "found in bag: op\n",
      "found in bag: now\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: thank\n",
      "found in bag: you\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: 'm\n",
      "found in bag: expery\n",
      "found in bag: sens\n",
      "found in bag: to\n",
      "found in bag: light/noise\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: hav\n",
      "found in bag: a\n",
      "found in bag: jash\n",
      "found in bag: or\n",
      "found in bag: skin\n",
      "found in bag: irrit\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: ar\n",
      "found in bag: the\n",
      "found in bag: poss\n",
      "found in bag: noxy\n",
      "found in bag: outcom\n",
      "found in bag: of\n",
      "found in bag: thi\n",
      "found in bag: tre\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: wher\n",
      "found in bag: can\n",
      "found in bag: i\n",
      "found in bag: acquisit\n",
      "found in bag: over-the-count\n",
      "found in bag: med\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: loc\n",
      "found in bag: a\n",
      "found in bag: pharm\n",
      "found in bag: neharby\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: how\n",
      "found in bag: ar\n",
      "found in bag: you\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: could\n",
      "found in bag: you\n",
      "found in bag: inform\n",
      "found in bag: me\n",
      "found in bag: of\n",
      "found in bag: my\n",
      "found in bag: transfus\n",
      "found in bag: press\n",
      "found in bag: result\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: how\n",
      "found in bag: is\n",
      "found in bag: my\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: doing\n",
      "found in bag: overal\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: can\n",
      "found in bag: you\n",
      "found in bag: tel\n",
      "found in bag: me\n",
      "found in bag: about\n",
      "found in bag: the\n",
      "found in bag: poss\n",
      "found in bag: sid\n",
      "found in bag: effect\n",
      "found in bag: of\n",
      "found in bag: tak\n",
      "found in bag: thi\n",
      "found in bag: drug\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: chrissakes\n",
      "found in bag: press\n",
      "found in bag: for\n",
      "found in bag: paty\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: dat\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: could\n",
      "found in bag: you\n",
      "found in bag: arrang\n",
      "found in bag: for\n",
      "found in bag: me\n",
      "found in bag: to\n",
      "found in bag: see\n",
      "found in bag: a\n",
      "found in bag: doct\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: may\n",
      "found in bag: i\n",
      "found in bag: rearrang\n",
      "found in bag: my\n",
      "found in bag: prescrib\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: find\n",
      "found in bag: a\n",
      "found in bag: in\n",
      "found in bag: [\n",
      "found in bag: city/town\n",
      "found in bag: ]\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: ow\n",
      "found in bag: you\n",
      "found in bag: noe\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: nee\n",
      "found in bag: to\n",
      "found in bag: refil\n",
      "found in bag: my\n",
      "found in bag: med\n",
      "found in bag: supply\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: which\n",
      "found in bag: drug\n",
      "found in bag: dont\n",
      "found in bag: hav\n",
      "found in bag: react\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: ca\n",
      "found in bag: n't\n",
      "found in bag: thank\n",
      "found in bag: you\n",
      "found in bag: enough\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: must\n",
      "found in bag: be\n",
      "found in bag: going\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: catch\n",
      "found in bag: you\n",
      "found in bag: trail\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: feel\n",
      "found in bag: short\n",
      "found in bag: of\n",
      "found in bag: brea\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: kind\n",
      "found in bag: of\n",
      "found in bag: task\n",
      "found in bag: ar\n",
      "found in bag: you\n",
      "found in bag: alright\n",
      "found in bag: at\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: gye\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: se\n",
      "found in bag: you\n",
      "found in bag: around\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: ow\n",
      "found in bag: is\n",
      "found in bag: my\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: look\n",
      "found in bag: today\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: find\n",
      "found in bag: a\n",
      "found in bag: hospit\n",
      "found in bag: in\n",
      "found in bag: [\n",
      "found in bag: city/municipal\n",
      "found in bag: ]\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: ar\n",
      "found in bag: yo\n",
      "found in bag: abl\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: tak\n",
      "found in bag: car\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: wel\n",
      "found in bag: fulfil\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: gookby\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: delight\n",
      "found in bag: to\n",
      "found in bag: see\n",
      "found in bag: you\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: wel\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: wher\n",
      "found in bag: is\n",
      "found in bag: the\n",
      "found in bag: clos\n",
      "found in bag: pharm\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: find\n",
      "found in bag: hospit\n",
      "found in bag: with\n",
      "found in bag: spec\n",
      "found in bag: special\n",
      "found in bag: (\n",
      "found in bag: e.g.\n",
      "found in bag: ,\n",
      "found in bag: cardiolog\n",
      "found in bag: ,\n",
      "found in bag: pedy\n",
      "found in bag: )\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: salut\n",
      "found in bag: ther\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: thank\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: giv\n",
      "found in bag: me\n",
      "found in bag: a\n",
      "found in bag: list\n",
      "found in bag: of\n",
      "found in bag: drug\n",
      "found in bag: caus\n",
      "found in bag: advers\n",
      "found in bag: behavy\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: would\n",
      "found in bag: lik\n",
      "found in bag: to\n",
      "found in bag: ask\n",
      "found in bag: a\n",
      "found in bag: doct\n",
      "found in bag: 's\n",
      "found in bag: appoint\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: ar\n",
      "found in bag: yo\n",
      "found in bag: area\n",
      "found in bag: of\n",
      "found in bag: skil\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: ar\n",
      "found in bag: ther\n",
      "found in bag: any\n",
      "found in bag: known\n",
      "found in bag: sid\n",
      "found in bag: influ\n",
      "found in bag: i\n",
      "found in bag: should\n",
      "found in bag: be\n",
      "found in bag: concern\n",
      "found in bag: about\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: hello\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: howdy\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: ar\n",
      "found in bag: yo\n",
      "found in bag: skil\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: find\n",
      "found in bag: a\n",
      "found in bag: 24-hour\n",
      "found in bag: near\n",
      "found in bag: me\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: ar\n",
      "found in bag: the\n",
      "found in bag: chant\n",
      "found in bag: of\n",
      "found in bag: wit\n",
      "found in bag: sid\n",
      "found in bag: effect\n",
      "found in bag: with\n",
      "found in bag: thi\n",
      "found in bag: drug\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: find\n",
      "found in bag: me\n",
      "found in bag: a\n",
      "found in bag: pharm\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: lco\n",
      "found in bag: hospit\n",
      "found in bag: with\n",
      "found in bag: intend\n",
      "found in bag: car\n",
      "found in bag: unit\n",
      "found in bag: (\n",
      "found in bag: icu\n",
      "found in bag: )\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: ogod\n",
      "found in bag: morn\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: find\n",
      "found in bag: pharmaceut\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: 'im\n",
      "found in bag: thank\n",
      "found in bag: for\n",
      "found in bag: yo\n",
      "found in bag: support\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: 'm\n",
      "found in bag: loo\n",
      "found in bag: to\n",
      "found in bag: see\n",
      "found in bag: a\n",
      "found in bag: healthc\n",
      "found in bag: profess\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: hav\n",
      "found in bag: troubl\n",
      "found in bag: cont\n",
      "found in bag: or\n",
      "found in bag: think\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: 'm\n",
      "found in bag: diarrhe\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: hav\n",
      "found in bag: a\n",
      "found in bag: day\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: can\n",
      "found in bag: you\n",
      "found in bag: explain\n",
      "found in bag: the\n",
      "found in bag: possbl\n",
      "found in bag: advers\n",
      "found in bag: react\n",
      "found in bag: of\n",
      "found in bag: thi\n",
      "found in bag: med\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: should\n",
      "found in bag: i\n",
      "found in bag: expect\n",
      "found in bag: in\n",
      "found in bag: term\n",
      "found in bag: of\n",
      "found in bag: sid\n",
      "found in bag: effect\n",
      "found in bag: from\n",
      "found in bag: thi\n",
      "found in bag: med\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: is\n",
      "found in bag: a\n",
      "found in bag: phys\n",
      "found in bag: avail\n",
      "found in bag: to\n",
      "found in bag: spe\n",
      "found in bag: me\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: could\n",
      "found in bag: i\n",
      "found in bag: get\n",
      "found in bag: a\n",
      "found in bag: reflil\n",
      "found in bag: on\n",
      "found in bag: my\n",
      "found in bag: prescrib\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: loc\n",
      "found in bag: pharm\n",
      "found in bag: in\n",
      "found in bag: [\n",
      "found in bag: neighb\n",
      "found in bag: ]\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: waht\n",
      "found in bag: skil\n",
      "found in bag: do\n",
      "found in bag: you\n",
      "found in bag: hav\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "636 documents\n",
      "12 intents ['adverse_drug', 'blood_pressure', 'blood_pressure_search', 'doctor', 'goodbye', 'greeting', 'hospital_search', 'medication', 'options', 'pharmacy_search', 'symptoms', 'thanks']\n",
      "673 unique stemmed words ['!', \"'\", \"''\", \"'d\", \"'im\", \"'m\", \"'re\", \"'s\", \"'ve\", '(', ')', ',', '.', '24-hour', '24/7', '[', ']', '``', 'a', 'abdoin', 'abdomin', 'abl', 'about', 'acceiv', 'ach', 'acn', 'acquisit', 'act', 'adio', 'adiso', 'admin', 'advers', 'advesr', 'aft', 'afternoon', 'afteroon', 'afterward', 'ahv', 'aid', 'al', 'almost', 'alright', 'an', 'and', 'any', 'anyon', 'appoint', 'apprec', 'apprecy', 'ar', 'area', 'arotnd', 'around', 'arrang', 'as', 'ask', 'assist', 'assocy', 'aston', 'at', 'attenty', 'avail', 'aw', 'awesom', 'batch', 'bby', 'be', 'been', 'behavy', 'behold', 'bel', 'bheavy', 'blat', 'blo', 'blocd', 'blod', 'blohod', 'blood', 'bloow', 'blota', 'bonjo', 'book', 'bound', 'bp', 'brea', 'breath', 'bring', 'brows', 'bu', 'bunch', 'buy', 'by', 'bye', 'ca', \"caa't\", 'cad', 'calend', 'can', 'cap', 'car', 'cardiolog', 'catch', 'caus', 'cent', 'chant', 'chat', 'checekd', 'check', 'cheerio', 'chek', 'chest', 'chil', 'chrissakes', 'ciao', 'ciold', 'city/municipal', 'city/town', 'cjan', 'clear', 'clin', 'clinfc/hospital', 'clinic/hospital', 'clos', 'closest', 'cold', 'collect', 'common', 'comp', 'compet', 'concern', 'congestio', 'consequ', 'consult', 'cont', 'contribu', 'contribut', 'coudl', 'cough', 'could', 'coulk', 'coulnd', 'couzld', 'covid-19', 'covid-k19', 'cpressure', 'cramp', 'crowd', 'cur', 'cvar', 'dat', 'day', 'dctor', 'deeply', 'del', 'delight', 'describ', 'detail', 'detcail', 'dext', 'dgay', 'diarrhe', 'diarrhoe', 'did', 'digest', 'direct', 'discomfort', 'dispens', 'dizzy', 'do', 'doabl', 'doct', 'doctro', 'doe', 'doing', 'dokt', 'dont', 'dort', 'downsid', 'drawbac', 'drawback', 'drive-thru', 'drug', 'drugst', 'drugstorf', 'duty', 'e.g.', 'easy', 'edict', 'effdct', 'effect', 'emerg', 'encount', 'enough', 'entir', 'entry', 'epharm', 'epxery', 'esult', 'etrength', 'ev', 'evfect', 'excel', 'exery', 'exhibit', 'expect', 'expert', 'experty', 'expery', 'explain', 'extrem', 'fac', 'facil', 'facilit', 'farewel', 'farewelql', 'fatigu', 'feel', 'fefect', 'fev', 'fil', 'find', 'flu', 'fnd', 'for', 'frisk', 'from', 'fulfil', 'furn', 'gath', 'gaz', 'geet', 'gest', 'get', 'giv', 'go', 'going', 'gokod', 'gonig', 'good', 'goodby', 'goodnight', 'gookby', 'gosod', 'got', 'grat', 'gratitud', 'gre', 'greet', 'gye', 'h', 'handy', 'has', 'hav', 'headach', 'health', 'healthc', 'healthy', 'heh', 'hel', 'hello', 'help', 'helrp', 'hemy', 'hepy', 'her', 'hey', 'hi', 'high', 'himy', 'hist', 'hiy', 'hlelo', 'hopit', 'hosit', 'hosp', 'hospiot', 'hospit', 'hospitasl', 'hospt', 'hot', 'how', 'howdy', 'hoxw', 'hoy', 'hspital', 'hwat', 'hyi', 'i', \"i'n\", 'icu', 'id', 'im', 'impact', 'impend', 'in', 'inauspicy', 'incred', 'indigest', 'influ', 'inform', 'ins', 'intend', 'irrit', 'is', 'issu', 'it', 'jad', 'jash', 'joint', 'kidn', 'kind', 'kisnd', 'know', 'known', 'knvwn', 'kwhat', 'largo', 'larynx', 'lat', 'latest', 'lco', 'leav', 'let', 'letharg', 'lethmarg', 'level', 'levesl', 'lgst', 'liabl', 'lifesav', 'light/noise', 'lighthead', 'lik', 'lind', 'list', 'liyghthead', 'load', 'loc', 'loch', 'locn', 'locta', 'log', 'long', 'loo', 'look', 'lookup', 'lookut', 'lot', 'ltim', 'maggio', 'magn', 'mak', 'malay', 'man', 'many', 'may', 'me', 'meac', 'mean', 'meas', 'med', 'medicatifon', 'medicaton', 'medicc', 'medicin', 'meet', 'mer', 'met', 'might', 'migt', 'mil', 'mod', 'modlu', 'morn', 'mtabl', 'mte', 'much', 'musc', 'must', 'my', \"n't\", 'nar', 'narby', 'nause', 'near', 'nearby', 'nearest', 'nee', 'neg', 'neharby', 'neighb', 'neighbo', 'new', 'newest', 'next', 'nic', 'nicq', 'nneg', 'nnxt', 'noe', 'noee', 'nomin', 'norm', 'nos', 'now', 'noxy', 'num', 'numb', 'oblig', 'occ', 'occup', 'oct', 'od', 'of', 'off', 'ogod', 'oing', 'ok', 'okp', 'on', 'op', 'opn', 'or', 'ord', 'oson', 'ot', 'out', 'outcom', 'outlin', 'over-the-count', 'overal', 'ow', 'pain', 'painb', 'pat', 'paty', 'pbin', 'pedy', 'peharm', 'persist', 'pharm', 'pharmac', 'pharmaceut', 'pharmacio', 'pharmahcy', 'phharmacy', 'phospit', 'phramacies', 'phys', 'physy', 'pick', 'pickk', 'pickup', 'pkckup', 'pleas', 'poharm', 'point', 'pois', 'porject', 'poss', 'possbl', 'pot', 'ppharmacies', 'pqtient', 'prep', 'preqss', 'prescrib', 'prescrip', 'presrib', 'press', 'profess', 'proficy', 'profound', 'project', 'provid', 'providevr', 'ps', 'puffy', 'pyleas', 'quick', 'quo', 'rang', 'react', 'read', 'readihg', 'ready', 'real', 'rearrang', 'rec', 'recogn', 'refil', 'reflil', 'refresh', 'reg', 'reil', 'rel', 'reord', 'reoult', 'repercuss', 'repl', 'report', 'reqeust', 'request', 'requir', 'research', 'result', 'rev', 'right', 'risk', 'room', 'rpescrib', 'rplenish', 'rpovid', 'rul', 'runny', 'salut', 'salutatoin', 'savio', 'say', 'sce', 'schedule', 'scratchy', 'se', 'seach', 'searah', 'search', 'searhc', 'see', 'seg', 'seh', 'sens', 'serv', 'sharm', 'shiv', 'short', 'shot', 'should', 'show', 'sid', 'sign', 'sik', 'simpl', 'skil', 'skils', 'skin', 'smight', 'so', 'sor', 'spe', 'speak', 'spec', 'special', 'spezc', 'stabl', 'stat', 'strengths', 'strong', 'stubborn', 'such', 'suit', 'supply', 'support', 'surgery', 'surround', 'swol', 'systolic/diastol', 'ta', 'tabl', 'tableau', 'tae', 'tahnk', 'tak', 'tal', 'talk', 'task', 'tech', 'techn', 'technicd', 'tel', 'telemedicin', 'term', \"tha'ts\", 'than', 'thank', 'thansk', 'thantk', 'thanv', 'that', 'the', 'ther', 'thi', 'think', 'thinmk', 'thnk', 'throat', 'thvnks', 'tier', 'tight', 'tighvt', 'til', 'tim', 'tir', 'to', 'today', 'told', 'town/town', 'trail', 'transf', 'transfus', 'tranusf', 'tre', 'trhoat', 'troubl', 'typ', 'undesir', 'unear', 'unearth', 'unfav', 'unintend', 'uninvit', 'unit', 'until', 'unus', 'unwante', 'up', 'upd', 'uregnt', 'urg', 'us', 'vaccin', 'vaccy', 'vay', 'ver', 'verdict', 'vertigo', 'very', 'vomit', 'waht', 'want', 'wat', 'watch', 'weak', 'wel', 'welcom', 'wha', 'whab', 'whaot', 'what', 'whaut', 'wheez', 'wher', 'whereby', 'whereof', 'wheru', 'whez', 'whgt', 'which', 'whil', 'whmt', 'whta', 'wit', 'with', 'within', 'wo', 'wond', 'would', 'wthat', 'xthanks', 'ya', 'yao', 'yfev', 'yo', 'you']\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mist861/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n",
      "/home/mist861/anaconda3/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py:33: UserWarning:\n",
      "\n",
      "Argument `decay` is no longer supported and will be ignored.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1363 - loss: 2.4078\n",
      "Epoch 2/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - accuracy: 0.4840 - loss: 1.5644\n",
      "Epoch 3/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - accuracy: 0.6072 - loss: 1.0685\n",
      "Epoch 4/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step - accuracy: 0.7163 - loss: 0.7909\n",
      "Epoch 5/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step - accuracy: 0.8136 - loss: 0.5212\n",
      "Epoch 6/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - accuracy: 0.7789 - loss: 0.5357\n",
      "Epoch 7/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step - accuracy: 0.8233 - loss: 0.4225\n",
      "Epoch 8/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - accuracy: 0.8761 - loss: 0.3795\n",
      "Epoch 9/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - accuracy: 0.8666 - loss: 0.3206\n",
      "Epoch 10/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543us/step - accuracy: 0.8876 - loss: 0.2660\n",
      "Epoch 11/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - accuracy: 0.9285 - loss: 0.2204\n",
      "Epoch 12/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - accuracy: 0.8989 - loss: 0.2604\n",
      "Epoch 13/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - accuracy: 0.9472 - loss: 0.1758\n",
      "Epoch 14/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538us/step - accuracy: 0.9518 - loss: 0.1728\n",
      "Epoch 15/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 549us/step - accuracy: 0.9525 - loss: 0.1485\n",
      "Epoch 16/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.9548 - loss: 0.1545\n",
      "Epoch 17/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - accuracy: 0.9393 - loss: 0.1783\n",
      "Epoch 18/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - accuracy: 0.9480 - loss: 0.1306\n",
      "Epoch 19/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543us/step - accuracy: 0.9536 - loss: 0.1503 \n",
      "Epoch 20/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - accuracy: 0.9550 - loss: 0.1347\n",
      "Epoch 21/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step - accuracy: 0.9497 - loss: 0.1383\n",
      "Epoch 22/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553us/step - accuracy: 0.9723 - loss: 0.0972\n",
      "Epoch 23/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - accuracy: 0.9634 - loss: 0.1093\n",
      "Epoch 24/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 0.9436 - loss: 0.1350 \n",
      "Epoch 25/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - accuracy: 0.9799 - loss: 0.0627\n",
      "Epoch 26/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - accuracy: 0.9782 - loss: 0.0644\n",
      "Epoch 27/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 0.9733 - loss: 0.0933 \n",
      "Epoch 28/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543us/step - accuracy: 0.9697 - loss: 0.0712\n",
      "Epoch 29/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - accuracy: 0.9758 - loss: 0.0638 \n",
      "Epoch 30/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - accuracy: 0.9785 - loss: 0.0717\n",
      "Epoch 31/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543us/step - accuracy: 0.9607 - loss: 0.1461\n",
      "Epoch 32/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - accuracy: 0.9769 - loss: 0.0692 \n",
      "Epoch 33/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548us/step - accuracy: 0.9769 - loss: 0.0794\n",
      "Epoch 34/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 550us/step - accuracy: 0.9846 - loss: 0.0619 \n",
      "Epoch 35/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - accuracy: 0.9728 - loss: 0.0543 \n",
      "Epoch 36/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - accuracy: 0.9876 - loss: 0.0482\n",
      "Epoch 37/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - accuracy: 0.9817 - loss: 0.0800\n",
      "Epoch 38/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.9755 - loss: 0.0811\n",
      "Epoch 39/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - accuracy: 0.9881 - loss: 0.0420\n",
      "Epoch 40/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571us/step - accuracy: 0.9778 - loss: 0.0638 \n",
      "Epoch 41/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571us/step - accuracy: 0.9963 - loss: 0.0283 \n",
      "Epoch 42/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - accuracy: 0.9835 - loss: 0.0518\n",
      "Epoch 43/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step - accuracy: 0.9926 - loss: 0.0329 \n",
      "Epoch 44/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 550us/step - accuracy: 0.9858 - loss: 0.0430\n",
      "Epoch 45/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607us/step - accuracy: 0.9869 - loss: 0.0431 \n",
      "Epoch 46/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - accuracy: 0.9821 - loss: 0.0460\n",
      "Epoch 47/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - accuracy: 0.9872 - loss: 0.0410\n",
      "Epoch 48/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - accuracy: 0.9821 - loss: 0.0415\n",
      "Epoch 49/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - accuracy: 0.9991 - loss: 0.0193 \n",
      "Epoch 50/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543us/step - accuracy: 0.9853 - loss: 0.0377\n",
      "Epoch 51/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - accuracy: 0.9960 - loss: 0.0214 \n",
      "Epoch 52/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - accuracy: 0.9868 - loss: 0.0584\n",
      "Epoch 53/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - accuracy: 0.9828 - loss: 0.0714\n",
      "Epoch 54/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - accuracy: 0.9867 - loss: 0.0450\n",
      "Epoch 55/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step - accuracy: 0.9841 - loss: 0.0422 \n",
      "Epoch 56/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605us/step - accuracy: 0.9950 - loss: 0.0272\n",
      "Epoch 57/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566us/step - accuracy: 0.9820 - loss: 0.0377 \n",
      "Epoch 58/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548us/step - accuracy: 0.9931 - loss: 0.0296\n",
      "Epoch 59/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - accuracy: 0.9910 - loss: 0.0381\n",
      "Epoch 60/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - accuracy: 0.9888 - loss: 0.0374 \n",
      "Epoch 61/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - accuracy: 0.9861 - loss: 0.0402\n",
      "Epoch 62/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step - accuracy: 0.9756 - loss: 0.0636\n",
      "Epoch 63/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step - accuracy: 0.9605 - loss: 0.1211\n",
      "Epoch 64/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - accuracy: 0.9714 - loss: 0.0729 \n",
      "Epoch 65/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - accuracy: 0.9822 - loss: 0.0467\n",
      "Epoch 66/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - accuracy: 0.9963 - loss: 0.0283\n",
      "Epoch 67/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574us/step - accuracy: 0.9952 - loss: 0.0157\n",
      "Epoch 68/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561us/step - accuracy: 0.9947 - loss: 0.0295\n",
      "Epoch 69/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step - accuracy: 0.9899 - loss: 0.0353 \n",
      "Epoch 70/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - accuracy: 0.9956 - loss: 0.0237\n",
      "Epoch 71/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 549us/step - accuracy: 0.9923 - loss: 0.0214\n",
      "Epoch 72/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - accuracy: 0.9852 - loss: 0.0247 \n",
      "Epoch 73/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593us/step - accuracy: 0.9827 - loss: 0.0527 \n",
      "Epoch 74/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574us/step - accuracy: 0.9953 - loss: 0.0207\n",
      "Epoch 75/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586us/step - accuracy: 0.9925 - loss: 0.0284\n",
      "Epoch 76/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565us/step - accuracy: 0.9886 - loss: 0.0385\n",
      "Epoch 77/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - accuracy: 0.9952 - loss: 0.0289 \n",
      "Epoch 78/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - accuracy: 0.9969 - loss: 0.0254\n",
      "Epoch 79/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569us/step - accuracy: 0.9961 - loss: 0.0169\n",
      "Epoch 80/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - accuracy: 0.9872 - loss: 0.0409\n",
      "Epoch 81/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - accuracy: 0.9955 - loss: 0.0206 \n",
      "Epoch 82/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574us/step - accuracy: 0.9874 - loss: 0.0378\n",
      "Epoch 83/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - accuracy: 0.9862 - loss: 0.0375\n",
      "Epoch 84/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - accuracy: 0.9807 - loss: 0.0416\n",
      "Epoch 85/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - accuracy: 0.9926 - loss: 0.0167 \n",
      "Epoch 86/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - accuracy: 0.9918 - loss: 0.0256\n",
      "Epoch 87/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - accuracy: 0.9974 - loss: 0.0132 \n",
      "Epoch 88/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - accuracy: 0.9948 - loss: 0.0169 \n",
      "Epoch 89/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step - accuracy: 0.9932 - loss: 0.0191\n",
      "Epoch 90/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - accuracy: 0.9844 - loss: 0.0333 \n",
      "Epoch 91/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - accuracy: 0.9773 - loss: 0.0494 \n",
      "Epoch 92/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - accuracy: 0.9924 - loss: 0.0170\n",
      "Epoch 93/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.9907 - loss: 0.0164 \n",
      "Epoch 94/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - accuracy: 0.9936 - loss: 0.0159 \n",
      "Epoch 95/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574us/step - accuracy: 0.9971 - loss: 0.0147 \n",
      "Epoch 96/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - accuracy: 0.9934 - loss: 0.0197\n",
      "Epoch 97/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - accuracy: 0.9975 - loss: 0.0153\n",
      "Epoch 98/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step - accuracy: 0.9930 - loss: 0.0164\n",
      "Epoch 99/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569us/step - accuracy: 0.9970 - loss: 0.0125 \n",
      "Epoch 100/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540us/step - accuracy: 0.9755 - loss: 0.0732\n",
      "Epoch 101/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554us/step - accuracy: 0.9966 - loss: 0.0164 \n",
      "Epoch 102/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - accuracy: 0.9861 - loss: 0.0289 \n",
      "Epoch 103/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 616us/step - accuracy: 0.9930 - loss: 0.0234 \n",
      "Epoch 104/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - accuracy: 0.9824 - loss: 0.1103\n",
      "Epoch 105/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542us/step - accuracy: 0.9896 - loss: 0.0221 \n",
      "Epoch 106/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593us/step - accuracy: 0.9907 - loss: 0.0294 \n",
      "Epoch 107/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step - accuracy: 0.9894 - loss: 0.0543 \n",
      "Epoch 108/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579us/step - accuracy: 0.9738 - loss: 0.0817 \n",
      "Epoch 109/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627us/step - accuracy: 0.9940 - loss: 0.0224\n",
      "Epoch 110/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step - accuracy: 0.9991 - loss: 0.0094\n",
      "Epoch 111/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - accuracy: 0.9864 - loss: 0.0443\n",
      "Epoch 112/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step - accuracy: 0.9887 - loss: 0.0486 \n",
      "Epoch 113/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - accuracy: 0.9906 - loss: 0.0262\n",
      "Epoch 114/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591us/step - accuracy: 0.9902 - loss: 0.0255\n",
      "Epoch 115/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607us/step - accuracy: 0.9981 - loss: 0.0090\n",
      "Epoch 116/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - accuracy: 0.9927 - loss: 0.0144\n",
      "Epoch 117/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step - accuracy: 0.9895 - loss: 0.0355\n",
      "Epoch 118/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - accuracy: 0.9879 - loss: 0.0193\n",
      "Epoch 119/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - accuracy: 0.9957 - loss: 0.0203\n",
      "Epoch 120/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - accuracy: 0.9886 - loss: 0.0366\n",
      "Epoch 121/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step - accuracy: 0.9816 - loss: 0.0469 \n",
      "Epoch 122/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - accuracy: 0.9859 - loss: 0.0268 \n",
      "Epoch 123/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - accuracy: 0.9944 - loss: 0.0298\n",
      "Epoch 124/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566us/step - accuracy: 0.9931 - loss: 0.0152\n",
      "Epoch 125/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - accuracy: 0.9871 - loss: 0.0365 \n",
      "Epoch 126/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577us/step - accuracy: 0.9911 - loss: 0.0176\n",
      "Epoch 127/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - accuracy: 0.9876 - loss: 0.0372 \n",
      "Epoch 128/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578us/step - accuracy: 0.9986 - loss: 0.0114 \n",
      "Epoch 129/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591us/step - accuracy: 0.9851 - loss: 0.0330\n",
      "Epoch 130/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598us/step - accuracy: 0.9776 - loss: 0.0553\n",
      "Epoch 131/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step - accuracy: 0.9944 - loss: 0.0172 \n",
      "Epoch 132/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559us/step - accuracy: 0.9916 - loss: 0.0219 \n",
      "Epoch 133/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548us/step - accuracy: 0.9840 - loss: 0.0336\n",
      "Epoch 134/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621us/step - accuracy: 0.9868 - loss: 0.0482 \n",
      "Epoch 135/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - accuracy: 0.9961 - loss: 0.0294 \n",
      "Epoch 136/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579us/step - accuracy: 0.9902 - loss: 0.0279\n",
      "Epoch 137/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 547us/step - accuracy: 0.9854 - loss: 0.0194\n",
      "Epoch 138/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571us/step - accuracy: 0.9972 - loss: 0.0115\n",
      "Epoch 139/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586us/step - accuracy: 0.9988 - loss: 0.0077 \n",
      "Epoch 140/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - accuracy: 0.9980 - loss: 0.0125\n",
      "Epoch 141/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - accuracy: 0.9964 - loss: 0.0219 \n",
      "Epoch 142/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592us/step - accuracy: 0.9965 - loss: 0.0139 \n",
      "Epoch 143/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - accuracy: 0.9991 - loss: 0.0097 \n",
      "Epoch 144/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - accuracy: 0.9947 - loss: 0.0179\n",
      "Epoch 145/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - accuracy: 0.9949 - loss: 0.0130\n",
      "Epoch 146/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - accuracy: 0.9934 - loss: 0.0281\n",
      "Epoch 147/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566us/step - accuracy: 0.9943 - loss: 0.0289\n",
      "Epoch 148/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569us/step - accuracy: 0.9942 - loss: 0.0210\n",
      "Epoch 149/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step - accuracy: 0.9954 - loss: 0.0098 \n",
      "Epoch 150/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - accuracy: 0.9858 - loss: 0.0305 \n",
      "Epoch 151/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627us/step - accuracy: 0.9945 - loss: 0.0261 \n",
      "Epoch 152/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586us/step - accuracy: 0.9951 - loss: 0.0122 \n",
      "Epoch 153/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576us/step - accuracy: 0.9989 - loss: 0.0079 \n",
      "Epoch 154/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571us/step - accuracy: 0.9931 - loss: 0.0189 \n",
      "Epoch 155/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586us/step - accuracy: 0.9986 - loss: 0.0078 \n",
      "Epoch 156/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - accuracy: 0.9936 - loss: 0.0133 \n",
      "Epoch 157/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578us/step - accuracy: 0.9900 - loss: 0.0284 \n",
      "Epoch 158/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548us/step - accuracy: 0.9953 - loss: 0.0087 \n",
      "Epoch 159/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571us/step - accuracy: 0.9942 - loss: 0.0172 \n",
      "Epoch 160/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - accuracy: 0.9989 - loss: 0.0099 \n",
      "Epoch 161/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 545us/step - accuracy: 0.9856 - loss: 0.0376\n",
      "Epoch 162/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - accuracy: 0.9998 - loss: 0.0086 \n",
      "Epoch 163/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - accuracy: 0.9951 - loss: 0.0117 \n",
      "Epoch 164/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553us/step - accuracy: 1.0000 - loss: 0.0081 \n",
      "Epoch 165/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577us/step - accuracy: 0.9915 - loss: 0.0196\n",
      "Epoch 166/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579us/step - accuracy: 0.9937 - loss: 0.0100\n",
      "Epoch 167/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - accuracy: 0.9919 - loss: 0.0207\n",
      "Epoch 168/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 552us/step - accuracy: 0.9994 - loss: 0.0102 \n",
      "Epoch 169/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - accuracy: 0.9993 - loss: 0.0105 \n",
      "Epoch 170/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - accuracy: 0.9847 - loss: 0.0332\n",
      "Epoch 171/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 552us/step - accuracy: 0.9987 - loss: 0.0045 \n",
      "Epoch 172/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - accuracy: 0.9955 - loss: 0.0194 \n",
      "Epoch 173/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - accuracy: 0.9969 - loss: 0.0085 \n",
      "Epoch 174/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566us/step - accuracy: 0.9969 - loss: 0.0079 \n",
      "Epoch 175/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 550us/step - accuracy: 1.0000 - loss: 0.0058 \n",
      "Epoch 176/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - accuracy: 0.9998 - loss: 0.0032 \n",
      "Epoch 177/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548us/step - accuracy: 0.9991 - loss: 0.0099\n",
      "Epoch 178/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540us/step - accuracy: 1.0000 - loss: 0.0055\n",
      "Epoch 179/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 545us/step - accuracy: 0.9941 - loss: 0.0176 \n",
      "Epoch 180/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - accuracy: 0.9922 - loss: 0.0218\n",
      "Epoch 181/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - accuracy: 0.9859 - loss: 0.0465 \n",
      "Epoch 182/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561us/step - accuracy: 1.0000 - loss: 0.0035 \n",
      "Epoch 183/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.9977 - loss: 0.0104\n",
      "Epoch 184/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541us/step - accuracy: 0.9990 - loss: 0.0054 \n",
      "Epoch 185/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576us/step - accuracy: 0.9880 - loss: 0.0236\n",
      "Epoch 186/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - accuracy: 0.9950 - loss: 0.0143\n",
      "Epoch 187/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - accuracy: 0.9850 - loss: 0.0442\n",
      "Epoch 188/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 552us/step - accuracy: 0.9937 - loss: 0.0253 \n",
      "Epoch 189/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566us/step - accuracy: 0.9962 - loss: 0.0153 \n",
      "Epoch 190/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596us/step - accuracy: 0.9920 - loss: 0.0341 \n",
      "Epoch 191/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578us/step - accuracy: 0.9966 - loss: 0.0099 \n",
      "Epoch 192/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561us/step - accuracy: 0.9991 - loss: 0.0073 \n",
      "Epoch 193/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566us/step - accuracy: 1.0000 - loss: 0.0043\n",
      "Epoch 194/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - accuracy: 0.9984 - loss: 0.0152\n",
      "Epoch 195/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - accuracy: 0.9967 - loss: 0.0090 \n",
      "Epoch 196/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step - accuracy: 0.9962 - loss: 0.0162\n",
      "Epoch 197/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540us/step - accuracy: 0.9930 - loss: 0.0190 \n",
      "Epoch 198/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - accuracy: 0.9953 - loss: 0.0100\n",
      "Epoch 199/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step - accuracy: 0.9981 - loss: 0.0051 \n",
      "Epoch 200/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - accuracy: 0.9984 - loss: 0.0080 \n",
      "found in bag: ``\n",
      "found in bag: bye-by\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: may\n",
      "found in bag: i\n",
      "found in bag: cal\n",
      "found in bag: a\n",
      "found in bag: refil\n",
      "found in bag: of\n",
      "found in bag: my\n",
      "found in bag: prescrib\n",
      "found in bag: ,\n",
      "found in bag: pleas\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: 'd\n",
      "found in bag: lik\n",
      "found in bag: to\n",
      "found in bag: ord\n",
      "found in bag: a\n",
      "found in bag: batch\n",
      "found in bag: of\n",
      "found in bag: my\n",
      "found in bag: med\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: uh\n",
      "found in bag: ar\n",
      "found in bag: yo\n",
      "found in bag: tal\n",
      "found in bag: and\n",
      "found in bag: skil\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: hav\n",
      "found in bag: a\n",
      "found in bag: persistnet\n",
      "found in bag: headach\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: loc\n",
      "found in bag: a\n",
      "found in bag: hospit\n",
      "found in bag: that\n",
      "found in bag: acceiv\n",
      "found in bag: my\n",
      "found in bag: ins\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: wher\n",
      "found in bag: can\n",
      "found in bag: i\n",
      "found in bag: fil\n",
      "found in bag: a\n",
      "found in bag: pfrescription\n",
      "found in bag: nearby\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: find\n",
      "found in bag: pharm\n",
      "found in bag: near\n",
      "found in bag: me\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: whereof\n",
      "found in bag: you\n",
      "found in bag: can\n",
      "found in bag: do\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: hav\n",
      "found in bag: a\n",
      "found in bag: gogd\n",
      "found in bag: on\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: healo\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: nic\n",
      "found in bag: to\n",
      "found in bag: dee\n",
      "found in bag: you\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: found\n",
      "found in bag: a\n",
      "found in bag: 24-hour\n",
      "found in bag: pharm\n",
      "found in bag: near\n",
      "found in bag: me\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: can\n",
      "found in bag: you\n",
      "found in bag: contribut\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: wher\n",
      "found in bag: can\n",
      "found in bag: i\n",
      "found in bag: found\n",
      "found in bag: hospit\n",
      "found in bag: with\n",
      "found in bag: surgery\n",
      "found in bag: facil\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: so\n",
      "found in bag: long\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: search\n",
      "found in bag: for\n",
      "found in bag: pharm\n",
      "found in bag: with\n",
      "found in bag: flu\n",
      "found in bag: shot\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: bye-bxy\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: unear\n",
      "found in bag: hospit\n",
      "found in bag: with\n",
      "found in bag: spec\n",
      "found in bag: special\n",
      "found in bag: (\n",
      "found in bag: e.g.\n",
      "found in bag: ,\n",
      "found in bag: cardiolog\n",
      "found in bag: ,\n",
      "found in bag: pedy\n",
      "found in bag: )\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: loc\n",
      "found in bag: hospit\n",
      "found in bag: in\n",
      "found in bag: [\n",
      "found in bag: neighb\n",
      "found in bag: ]\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: hav\n",
      "found in bag: a\n",
      "found in bag: eczem\n",
      "found in bag: or\n",
      "found in bag: skin\n",
      "found in bag: irrit\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: ar\n",
      "found in bag: the\n",
      "found in bag: risk\n",
      "found in bag: or\n",
      "found in bag: gap\n",
      "found in bag: of\n",
      "found in bag: thi\n",
      "found in bag: med\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: 'm\n",
      "found in bag: expery\n",
      "found in bag: nause\n",
      "found in bag: and\n",
      "found in bag: vomit\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: ar\n",
      "found in bag: ther\n",
      "found in bag: any\n",
      "found in bag: common\n",
      "found in bag: sid\n",
      "found in bag: effect\n",
      "found in bag: assocy\n",
      "found in bag: with\n",
      "found in bag: thi\n",
      "found in bag: tre\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: thank\n",
      "found in bag: yo\n",
      "found in bag: help\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: 'd\n",
      "found in bag: lik\n",
      "found in bag: to\n",
      "found in bag: ord\n",
      "found in bag: a\n",
      "found in bag: batch\n",
      "found in bag: of\n",
      "found in bag: my\n",
      "found in bag: medicin\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: is\n",
      "found in bag: it\n",
      "found in bag: achiev\n",
      "found in bag: to\n",
      "found in bag: get\n",
      "found in bag: a\n",
      "found in bag: prescrib\n",
      "found in bag: fil\n",
      "found in bag: today\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: how\n",
      "found in bag: is\n",
      "found in bag: my\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: doing\n",
      "found in bag: overal\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: out\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: thank\n",
      "found in bag: a\n",
      "found in bag: mil\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: good\n",
      "found in bag: morn\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: 'm\n",
      "found in bag: thank\n",
      "found in bag: for\n",
      "found in bag: yo\n",
      "found in bag: support\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: thank\n",
      "found in bag: a\n",
      "found in bag: bunch\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: hey\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: 's\n",
      "found in bag: my\n",
      "found in bag: systolic/diastol\n",
      "found in bag: press\n",
      "found in bag: right\n",
      "found in bag: now\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: is\n",
      "found in bag: ther\n",
      "found in bag: a\n",
      "found in bag: chant\n",
      "found in bag: of\n",
      "found in bag: expery\n",
      "found in bag: any\n",
      "found in bag: unw\n",
      "found in bag: effect\n",
      "found in bag: with\n",
      "found in bag: thi\n",
      "found in bag: med\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: see\n",
      "found in bag: you\n",
      "found in bag: around\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: loc\n",
      "found in bag: pharm\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: list\n",
      "found in bag: of\n",
      "found in bag: pharm\n",
      "found in bag: nearby\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: hyw\n",
      "found in bag: ar\n",
      "found in bag: you\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: ar\n",
      "found in bag: yo\n",
      "found in bag: cap\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: efel\n",
      "found in bag: fatigu\n",
      "found in bag: and\n",
      "found in bag: weak\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: pharm\n",
      "found in bag: clos\n",
      "found in bag: to\n",
      "found in bag: my\n",
      "found in bag: loc\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: skil\n",
      "found in bag: do\n",
      "found in bag: you\n",
      "found in bag: bring\n",
      "found in bag: to\n",
      "found in bag: the\n",
      "found in bag: tabl\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: see\n",
      "found in bag: you\n",
      "found in bag: soon\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: want\n",
      "found in bag: to\n",
      "found in bag: log\n",
      "found in bag: blood\n",
      "found in bag: result\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: 'm\n",
      "found in bag: expery\n",
      "found in bag: sensit\n",
      "found in bag: to\n",
      "found in bag: light/noise\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: hav\n",
      "found in bag: chest\n",
      "found in bag: tight\n",
      "found in bag: and\n",
      "found in bag: discomfort\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: look\n",
      "found in bag: for\n",
      "found in bag: a\n",
      "found in bag: pharm\n",
      "found in bag: that\n",
      "found in bag: 's\n",
      "found in bag: op\n",
      "found in bag: dlat\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: ,\n",
      "found in bag: how\n",
      "found in bag: hav\n",
      "found in bag: you\n",
      "found in bag: been\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: goodnighl\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: nee\n",
      "found in bag: to\n",
      "found in bag: consult\n",
      "found in bag: with\n",
      "found in bag: a\n",
      "found in bag: med\n",
      "found in bag: doct\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: dat\n",
      "found in bag: entry\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: ar\n",
      "found in bag: ther\n",
      "found in bag: any\n",
      "found in bag: comply\n",
      "found in bag: i\n",
      "found in bag: should\n",
      "found in bag: anticip\n",
      "found in bag: from\n",
      "found in bag: us\n",
      "found in bag: thi\n",
      "found in bag: med\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: loc\n",
      "found in bag: drugst\n",
      "found in bag: in\n",
      "found in bag: [\n",
      "found in bag: neighb\n",
      "found in bag: ]\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: thank\n",
      "found in bag: a\n",
      "found in bag: batch\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: is\n",
      "found in bag: ther\n",
      "found in bag: a\n",
      "found in bag: physc\n",
      "found in bag: i\n",
      "found in bag: can\n",
      "found in bag: speak\n",
      "found in bag: with\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: find\n",
      "found in bag: an\n",
      "found in bag: emerg\n",
      "found in bag: hospit\n",
      "found in bag: near\n",
      "found in bag: me\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: ar\n",
      "found in bag: the\n",
      "found in bag: unintend\n",
      "found in bag: consequ\n",
      "found in bag: i\n",
      "found in bag: might\n",
      "found in bag: fac\n",
      "found in bag: whil\n",
      "found in bag: tak\n",
      "found in bag: thi\n",
      "found in bag: medicinq\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: is\n",
      "found in bag: my\n",
      "found in bag: prescrib\n",
      "found in bag: ready\n",
      "found in bag: for\n",
      "found in bag: pickup\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: can\n",
      "found in bag: i\n",
      "found in bag: mak\n",
      "found in bag: an\n",
      "found in bag: appoint\n",
      "found in bag: to\n",
      "found in bag: see\n",
      "found in bag: a\n",
      "found in bag: doct\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: wlecom\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: 'm\n",
      "found in bag: her\n",
      "found in bag: to\n",
      "found in bag: collect\n",
      "found in bag: my\n",
      "found in bag: prescripg\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: goodnight\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: can\n",
      "found in bag: you\n",
      "found in bag: describ\n",
      "found in bag: any\n",
      "found in bag: undesir\n",
      "found in bag: effect\n",
      "found in bag: that\n",
      "found in bag: could\n",
      "found in bag: occ\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: loc\n",
      "found in bag: hospit\n",
      "found in bag: with\n",
      "found in bag: intend\n",
      "found in bag: healthc\n",
      "found in bag: unit\n",
      "found in bag: (\n",
      "found in bag: icu\n",
      "found in bag: )\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: search\n",
      "found in bag: up\n",
      "found in bag: hospit\n",
      "found in bag: detail\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: can\n",
      "found in bag: i\n",
      "found in bag: mak\n",
      "found in bag: an\n",
      "found in bag: appoint\n",
      "found in bag: to\n",
      "found in bag: sbe\n",
      "found in bag: a\n",
      "found in bag: doct\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: thansk\n",
      "found in bag: a\n",
      "found in bag: mil\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: look\n",
      "found in bag: for\n",
      "found in bag: a\n",
      "found in bag: pharm\n",
      "found in bag: that\n",
      "found in bag: 's\n",
      "found in bag: op\n",
      "found in bag: lat\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: can\n",
      "found in bag: you\n",
      "found in bag: fil\n",
      "found in bag: my\n",
      "found in bag: prescrib\n",
      "found in bag: for\n",
      "found in bag: me\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: skil\n",
      "found in bag: do\n",
      "found in bag: you\n",
      "found in bag: hav\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: 's\n",
      "found in bag: the\n",
      "found in bag: stat\n",
      "found in bag: of\n",
      "found in bag: my\n",
      "found in bag: press\n",
      "found in bag: today\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: hello\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: 'm\n",
      "found in bag: deeplry\n",
      "found in bag: thank\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: you\n",
      "found in bag: 're\n",
      "found in bag: a\n",
      "found in bag: lifeskv\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: could\n",
      "found in bag: you\n",
      "found in bag: help\n",
      "found in bag: me\n",
      "found in bag: book\n",
      "found in bag: an\n",
      "found in bag: appoint\n",
      "found in bag: with\n",
      "found in bag: a\n",
      "found in bag: doct\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: real\n",
      "found in bag: apprecy\n",
      "found in bag: it\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: find\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: result\n",
      "found in bag: by\n",
      "found in bag: id\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: find\n",
      "found in bag: pharm\n",
      "found in bag: near\n",
      "found in bag: me\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: hav\n",
      "found in bag: a\n",
      "found in bag: buen\n",
      "found in bag: on\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: 'm\n",
      "found in bag: thank\n",
      "found in bag: for\n",
      "found in bag: yo\n",
      "found in bag: aid\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: thank\n",
      "found in bag: you\n",
      "found in bag: so\n",
      "found in bag: much\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: is\n",
      "found in bag: a\n",
      "found in bag: phys\n",
      "found in bag: avail\n",
      "found in bag: to\n",
      "found in bag: see\n",
      "found in bag: me\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: is\n",
      "found in bag: everyon\n",
      "found in bag: ther\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: ar\n",
      "found in bag: the\n",
      "found in bag: poss\n",
      "found in bag: advers\n",
      "found in bag: outcom\n",
      "found in bag: of\n",
      "found in bag: thi\n",
      "found in bag: reat\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: kind\n",
      "found in bag: of\n",
      "found in bag: answ\n",
      "found in bag: might\n",
      "found in bag: i\n",
      "found in bag: expery\n",
      "found in bag: from\n",
      "found in bag: thi\n",
      "found in bag: med\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: hav\n",
      "found in bag: a\n",
      "found in bag: runny\n",
      "found in bag: nos\n",
      "found in bag: and\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: want\n",
      "found in bag: to\n",
      "found in bag: search\n",
      "found in bag: for\n",
      "found in bag: bood\n",
      "found in bag: press\n",
      "found in bag: result\n",
      "found in bag: hist\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: is\n",
      "found in bag: my\n",
      "found in bag: cur\n",
      "found in bag: transfus\n",
      "found in bag: press\n",
      "found in bag: read\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: ar\n",
      "found in bag: yo\n",
      "found in bag: proficy\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: adio\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: much\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: 'm\n",
      "found in bag: very\n",
      "found in bag: grat\n",
      "found in bag: for\n",
      "found in bag: yo\n",
      "found in bag: assist\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: can\n",
      "found in bag: you\n",
      "found in bag: fil\n",
      "found in bag: my\n",
      "found in bag: oprescrib\n",
      "found in bag: for\n",
      "found in bag: me\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: ar\n",
      "found in bag: ther\n",
      "found in bag: any\n",
      "found in bag: comply\n",
      "found in bag: i\n",
      "found in bag: should\n",
      "found in bag: anticip\n",
      "found in bag: from\n",
      "found in bag: usng\n",
      "found in bag: thi\n",
      "found in bag: med\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: hello\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: could\n",
      "found in bag: you\n",
      "found in bag: let\n",
      "found in bag: me\n",
      "found in bag: know\n",
      "found in bag: my\n",
      "found in bag: cur\n",
      "found in bag: bp\n",
      "found in bag: numb\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: feel\n",
      "found in bag: short\n",
      "found in bag: of\n",
      "found in bag: ebrea\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: hav\n",
      "found in bag: a\n",
      "found in bag: gre\n",
      "found in bag: day\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: thank\n",
      "found in bag: you\n",
      "found in bag: so\n",
      "found in bag: much\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: kidn\n",
      "found in bag: of\n",
      "found in bag: task\n",
      "found in bag: ar\n",
      "found in bag: you\n",
      "found in bag: good\n",
      "found in bag: at\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: is\n",
      "found in bag: anyon\n",
      "found in bag: ther\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: look\n",
      "found in bag: for\n",
      "found in bag: a\n",
      "found in bag: hospit\n",
      "found in bag: that\n",
      "found in bag: 's\n",
      "found in bag: op\n",
      "found in bag: 24/7\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: is\n",
      "found in bag: my\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: within\n",
      "found in bag: a\n",
      "found in bag: healthy\n",
      "found in bag: rnge\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: could\n",
      "found in bag: you\n",
      "found in bag: list\n",
      "found in bag: the\n",
      "found in bag: pot\n",
      "found in bag: drawback\n",
      "found in bag: or\n",
      "found in bag: downsid\n",
      "found in bag: of\n",
      "found in bag: util\n",
      "found in bag: thi\n",
      "found in bag: drug\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: want\n",
      "found in bag: to\n",
      "found in bag: search\n",
      "found in bag: hospit\n",
      "found in bag: dat\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: tranquil\n",
      "found in bag: out\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: ar\n",
      "found in bag: yo\n",
      "found in bag: strong\n",
      "found in bag: point\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: can\n",
      "found in bag: you\n",
      "found in bag: explain\n",
      "found in bag: the\n",
      "found in bag: poss\n",
      "found in bag: advers\n",
      "found in bag: react\n",
      "found in bag: of\n",
      "found in bag: thi\n",
      "found in bag: med\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: could\n",
      "found in bag: you\n",
      "found in bag: dispens\n",
      "found in bag: my\n",
      "found in bag: med\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: you\n",
      "found in bag: hav\n",
      "found in bag: my\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: hopsit\n",
      "found in bag: clos\n",
      "found in bag: to\n",
      "found in bag: my\n",
      "found in bag: loc\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: wher\n",
      "found in bag: can\n",
      "found in bag: i\n",
      "found in bag: finyd\n",
      "found in bag: a\n",
      "found in bag: hospit\n",
      "found in bag: emerg\n",
      "found in bag: room\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: thank\n",
      "found in bag: you\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: tak\n",
      "found in bag: it\n",
      "found in bag: easy\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: wher\n",
      "found in bag: can\n",
      "found in bag: i\n",
      "found in bag: find\n",
      "found in bag: a\n",
      "found in bag: phrmacy\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: can\n",
      "found in bag: you\n",
      "found in bag: tel\n",
      "found in bag: me\n",
      "found in bag: what\n",
      "found in bag: my\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: numb\n",
      "found in bag: ar\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: op\n",
      "found in bag: unfavo\n",
      "found in bag: drug\n",
      "found in bag: mod\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: whac\n",
      "found in bag: do\n",
      "found in bag: you\n",
      "found in bag: excel\n",
      "found in bag: at\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: mfy\n",
      "found in bag: i\n",
      "found in bag: reord\n",
      "found in bag: my\n",
      "found in bag: prescrib\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: waht\n",
      "found in bag: ar\n",
      "found in bag: my\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: level\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: ow\n",
      "found in bag: you\n",
      "found in bag: on\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: hwody\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: 'm\n",
      "found in bag: expery\n",
      "found in bag: nause\n",
      "found in bag: and\n",
      "found in bag: vomit\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: hav\n",
      "found in bag: digest\n",
      "found in bag: issu\n",
      "found in bag: such\n",
      "found in bag: as\n",
      "found in bag: blo\n",
      "found in bag: or\n",
      "found in bag: heartburn\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: ar\n",
      "found in bag: yo\n",
      "found in bag: profess\n",
      "found in bag: cap\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: can\n",
      "found in bag: i\n",
      "found in bag: speak\n",
      "found in bag: to\n",
      "found in bag: a\n",
      "found in bag: provid\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: 'm\n",
      "found in bag: expery\n",
      "found in bag: sensipt\n",
      "found in bag: to\n",
      "found in bag: light/noise\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: search\n",
      "found in bag: for\n",
      "found in bag: hospit\n",
      "found in bag: with\n",
      "found in bag: urg\n",
      "found in bag: car\n",
      "found in bag: serv\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: hav\n",
      "found in bag: a\n",
      "found in bag: rash\n",
      "found in bag: or\n",
      "found in bag: skin\n",
      "found in bag: irrit\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: ar\n",
      "found in bag: the\n",
      "found in bag: pot\n",
      "found in bag: sid\n",
      "found in bag: effect\n",
      "found in bag: of\n",
      "found in bag: thi\n",
      "found in bag: med\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: wher\n",
      "found in bag: can\n",
      "found in bag: i\n",
      "found in bag: find\n",
      "found in bag: hospit\n",
      "found in bag: with\n",
      "found in bag: surgery\n",
      "found in bag: facil\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: adio\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: search\n",
      "found in bag: for\n",
      "found in bag: drugst\n",
      "found in bag: nearby\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: nearby\n",
      "found in bag: hospit\n",
      "found in bag: op\n",
      "found in bag: now\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: ahoy\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: should\n",
      "found in bag: i\n",
      "found in bag: know\n",
      "found in bag: about\n",
      "found in bag: my\n",
      "found in bag: transfus\n",
      "found in bag: press\n",
      "found in bag: level\n",
      "found in bag: right\n",
      "found in bag: now\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: nee\n",
      "found in bag: to\n",
      "found in bag: chos\n",
      "found in bag: up\n",
      "found in bag: my\n",
      "found in bag: med\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: can\n",
      "found in bag: i\n",
      "found in bag: mak\n",
      "found in bag: an\n",
      "found in bag: nomin\n",
      "found in bag: to\n",
      "found in bag: see\n",
      "found in bag: a\n",
      "found in bag: doct\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: a\n",
      "found in bag: hospit\n",
      "found in bag: in\n",
      "found in bag: [\n",
      "found in bag: city/town\n",
      "found in bag: ]\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: look\n",
      "found in bag: up\n",
      "found in bag: hospit\n",
      "found in bag: detil\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: ar\n",
      "found in bag: the\n",
      "found in bag: unintend\n",
      "found in bag: consequ\n",
      "found in bag: i\n",
      "found in bag: might\n",
      "found in bag: fac\n",
      "found in bag: whil\n",
      "found in bag: pick\n",
      "found in bag: thi\n",
      "found in bag: medicin\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: requir\n",
      "found in bag: to\n",
      "found in bag: refil\n",
      "found in bag: my\n",
      "found in bag: med\n",
      "found in bag: supply\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: do\n",
      "found in bag: you\n",
      "found in bag: spec\n",
      "found in bag: in\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: catch\n",
      "found in bag: you\n",
      "found in bag: lateb\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: find\n",
      "found in bag: a\n",
      "found in bag: pharm\n",
      "found in bag: in\n",
      "found in bag: [\n",
      "found in bag: city/town\n",
      "found in bag: ]\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: good\n",
      "found in bag: afternoon\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: bye-by\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: you\n",
      "found in bag: 've\n",
      "found in bag: been\n",
      "found in bag: so\n",
      "found in bag: kind\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: pinpoint\n",
      "found in bag: pharm\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: ar\n",
      "found in bag: ther\n",
      "found in bag: any\n",
      "found in bag: comply\n",
      "found in bag: i\n",
      "found in bag: should\n",
      "found in bag: anticip\n",
      "found in bag: from\n",
      "found in bag: us\n",
      "found in bag: thi\n",
      "found in bag: med\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: could\n",
      "found in bag: i\n",
      "found in bag: get\n",
      "found in bag: a\n",
      "found in bag: refil\n",
      "found in bag: on\n",
      "found in bag: my\n",
      "found in bag: prescrib\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: want\n",
      "found in bag: to\n",
      "found in bag: search\n",
      "found in bag: hospit\n",
      "found in bag: dat\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: how\n",
      "found in bag: you\n",
      "found in bag: can\n",
      "found in bag: be\n",
      "found in bag: help\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: pharm\n",
      "found in bag: her\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: ar\n",
      "found in bag: ther\n",
      "found in bag: any\n",
      "found in bag: doct\n",
      "found in bag: in\n",
      "found in bag: the\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "636 documents\n",
      "12 intents ['adverse_drug', 'blood_pressure', 'blood_pressure_search', 'doctor', 'goodbye', 'greeting', 'hospital_search', 'medication', 'options', 'pharmacy_search', 'symptoms', 'thanks']\n",
      "663 unique stemmed words ['!', \"'\", \"''\", \"'d\", \"'im\", \"'m\", \"'re\", \"'s\", \"'ve\", '(', ')', ',', '.', '24-hour', '24/7', '[', ']', '``', 'a', 'abdoin', 'abl', 'about', 'acceiv', 'ach', 'achiev', 'acknowledg', 'acn', 'acquisit', 'act', 'adio', 'adiso', 'admin', 'advers', 'afternoon', 'afterward', 'ahoy', 'ahv', 'aid', 'al', 'almost', 'alright', 'an', 'and', 'answ', 'anticip', 'any', 'anyon', 'appoint', 'apprec', 'apprecy', 'ar', 'area', 'arotnd', 'around', 'arrang', 'as', 'ask', 'assist', 'assocy', 'at', 'avail', 'aw', 'awesom', 'batch', 'bby', 'be', 'been', 'behavy', 'behold', 'bheavy', 'blat', 'blo', 'blod', 'blohod', 'blood', 'bloow', 'blota', 'bolod', 'bonjo', 'bood', 'book', 'bp', 'brea', 'breath', 'bring', 'bu', 'buen', 'bunch', 'buy', 'by', 'bye', 'bye-bxy', 'bye-by', 'ca', \"caa't\", 'cad', 'cal', 'calend', 'can', 'cap', 'car', 'cardiolog', 'catch', 'caus', 'cent', 'chant', 'chat', 'check', 'chek', 'chest', 'chil', 'chos', 'chrissakes', 'ciao', 'ciold', 'city/municipal', 'city/town', 'clear', 'clin', 'clinfc/hospital', 'clinic/hospital', 'clinically/hospital', 'clos', 'cold', 'collect', 'common', 'comp', 'compet', 'comply', 'concern', 'congest', 'congestio', 'consequ', 'consult', 'cont', 'contribu', 'contribut', 'coudl', 'cough', 'could', 'coulk', 'coulnd', 'couzld', 'covid-19', 'cramp', 'crowd', 'cur', 'dat', 'day', 'dctor', 'dee', 'deeplry', 'deeply', 'del', 'delight', 'describ', 'detail', 'detcail', 'detil', 'dext', 'dgay', 'diarrhe', 'did', 'digest', 'direct', 'discomfort', 'dispens', 'dizzy', 'dlat', 'do', 'doabl', 'doct', 'doe', 'doing', 'dokt', 'dont', 'dort', 'downsid', 'drawbac', 'drawback', 'drive-thru', 'drug', 'drugst', 'drugstorf', 'duty', 'e.g.', 'easy', 'ebrea', 'eczem', 'edict', 'efel', 'effdct', 'effect', 'emerg', 'encount', 'enough', 'entir', 'entry', 'epharm', 'esult', 'etrength', 'ev', 'everyon', 'evfect', 'excel', 'exery', 'exhibit', 'expect', 'expert', 'experty', 'expery', 'explain', 'extrem', 'fac', 'facil', 'facilit', 'fatigu', 'feel', 'fev', 'fil', 'find', 'finsd', 'finyd', 'flu', 'fnd', 'for', 'found', 'frisk', 'from', 'fulfil', 'furn', 'gap', 'gath', 'gaz', 'geet', 'gest', 'get', 'giv', 'go', 'gogd', 'going', 'gokod', 'good', 'goodby', 'goodbyt', 'goodnighl', 'goodnight', 'gookby', 'gosod', 'got', 'grat', 'gratitud', 'gre', 'greet', 'gye', 'has', 'hav', 'headach', 'heal', 'healo', 'healthc', 'healthy', 'heartburn', 'heh', 'hello', 'help', 'helrp', 'hemy', 'her', 'hey', 'hi', 'high', 'hist', 'hiy', 'hlelo', 'hopit', 'hopsit', 'hosit', 'hosp', 'hospiot', 'hospit', 'hospt', 'hot', 'how', 'howdy', 'hoxw', 'hoy', 'hwody', 'hyw', 'i', 'icu', 'id', 'im', 'impact', 'impend', 'in', 'inauspicy', 'indigest', 'influ', 'inform', 'ins', 'intend', 'irrit', 'is', 'issu', 'it', 'jad', 'jash', 'joint', 'kidn', 'kind', 'kisnd', 'know', 'known', 'knvwn', 'kwhat', 'largo', 'lat', 'lateb', 'latest', 'lco', 'leav', 'let', 'letharg', 'lethmarg', 'level', 'levesl', 'lgst', 'liabl', 'lifesav', 'lifeskv', 'light/noise', 'lighthead', 'lik', 'lind', 'list', 'liyghthead', 'load', 'loc', 'loch', 'locn', 'locta', 'log', 'long', 'loo', 'look', 'lookup', 'lookut', 'lot', 'ltim', 'maggio', 'magn', 'mak', 'man', 'many', 'may', 'me', 'mean', 'meas', 'med', 'medicc', 'medicin', 'medicinq', 'meet', 'mer', 'mfy', 'might', 'migt', 'mil', 'mod', 'modlu', 'morn', 'mte', 'much', 'musc', 'must', 'my', \"n't\", 'nar', 'narby', 'nause', 'near', 'nearby', 'nearest', 'nee', 'neg', 'neharby', 'neighb', 'neighbo', 'new', 'next', 'nic', 'nicq', 'noe', 'noee', 'nomin', 'norm', 'nos', 'now', 'noxy', 'num', 'numb', 'oblgy', 'oblig', 'occ', 'occup', 'oct', 'of', 'off', 'ogod', 'oing', 'ok', 'on', 'op', 'opn', 'oprescrib', 'or', 'ord', 'oson', 'out', 'outcom', 'outlin', 'over-the-count', 'overal', 'ow', 'pain', 'painb', 'pat', 'paty', 'pbin', 'peac', 'pedy', 'peharm', 'persistnet', 'pfrescription', 'pharm', 'pharmac', 'pharmaceut', 'pharmahcy', 'phharmacy', 'phospit', 'phrmacy', 'phys', 'physc', 'physy', 'pick', 'pickk', 'pickup', 'pinpoint', 'pkckup', 'pleas', 'poharm', 'point', 'pois', 'poss', 'possbl', 'pot', 'ppharmacies', 'pqtient', 'prep', 'preqss', 'prescrib', 'prescrip', 'prescripg', 'presrib', 'press', 'profess', 'proficy', 'profound', 'project', 'provid', 'providevr', 'ps', 'puffy', 'pyleas', 'quo', 'rang', 'rash', 'react', 'read', 'readihg', 'ready', 'real', 'rearrang', 'reat', 'rec', 'recogn', 'refil', 'reflil', 'refresh', 'reg', 'rel', 'reord', 'reoult', 'repl', 'report', 'request', 'requir', 'result', 'right', 'risk', 'rnge', 'room', 'rpescrib', 'rplenish', 'rpovid', 'rul', 'runny', 'salut', 'savio', 'sbe', 'sce', 'schedule', 'scratchy', 'se', 'searah', 'search', 'searhc', 'see', 'seh', 'sens', 'sensipt', 'sensit', 'serv', 'sharm', 'shiv', 'short', 'shot', 'should', 'show', 'sid', 'sign', 'sik', 'simpl', 'skil', 'skils', 'skin', 'smight', 'so', 'soon', 'sor', 'spe', 'speak', 'spec', 'special', 'spezc', 'sress', 'stabl', 'stat', 'strengths', 'strong', 'stubborn', 'such', 'suit', 'supply', 'support', 'surgery', 'surround', 'swol', 'systolic/diastol', 'ta', 'tabl', 'tae', 'tahnk', 'tak', 'tal', 'talk', 'task', 'techn', 'technicd', 'tel', 'telemedicin', 'term', 'thank', 'thansk', 'thantk', 'thanv', 'that', 'the', 'ther', 'thi', 'think', 'thinmk', 'thnk', 'throat', 'thvnks', 'tier', 'tight', 'tighvt', 'til', 'tim', 'tir', 'to', 'today', 'town/town', 'trail', 'tranquil', 'transf', 'transfus', 'tranusf', 'tre', 'trhoat', 'troubl', 'typ', 'uh', 'undesir', 'unear', 'unearth', 'unfavo', 'unintend', 'uninvit', 'unit', 'until', 'unus', 'unw', 'unwante', 'up', 'upd', 'urg', 'us', 'usng', 'util', 'vaccin', 'vaccy', 'ver', 'vertigo', 'very', 'vomit', 'waht', 'want', 'wat', 'watch', 'weak', 'wel', 'welcom', 'wha', 'whab', 'whac', 'whaot', 'whar', 'what', 'wheez', 'wher', 'whereof', 'wheru', 'whez', 'which', 'whil', 'whmt', 'whnt', 'whta', 'wit', 'with', 'within', 'wlecom', 'wo', 'wond', 'would', 'xthanks', 'ya', 'yfev', 'yo', 'you']\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mist861/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n",
      "/home/mist861/anaconda3/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py:33: UserWarning:\n",
      "\n",
      "Argument `decay` is no longer supported and will be ignored.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1745 - loss: 2.3772   \n",
      "Epoch 2/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - accuracy: 0.4709 - loss: 1.6429\n",
      "Epoch 3/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - accuracy: 0.6546 - loss: 1.0424\n",
      "Epoch 4/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606us/step - accuracy: 0.7553 - loss: 0.7182\n",
      "Epoch 5/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - accuracy: 0.8105 - loss: 0.5492\n",
      "Epoch 6/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586us/step - accuracy: 0.8050 - loss: 0.5286\n",
      "Epoch 7/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579us/step - accuracy: 0.8151 - loss: 0.5030\n",
      "Epoch 8/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - accuracy: 0.8783 - loss: 0.3242\n",
      "Epoch 9/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574us/step - accuracy: 0.8974 - loss: 0.3113\n",
      "Epoch 10/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - accuracy: 0.8589 - loss: 0.3462\n",
      "Epoch 11/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - accuracy: 0.8764 - loss: 0.2833\n",
      "Epoch 12/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - accuracy: 0.9084 - loss: 0.2377\n",
      "Epoch 13/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - accuracy: 0.9316 - loss: 0.2165\n",
      "Epoch 14/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541us/step - accuracy: 0.9170 - loss: 0.2255\n",
      "Epoch 15/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548us/step - accuracy: 0.9372 - loss: 0.1998\n",
      "Epoch 16/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553us/step - accuracy: 0.9017 - loss: 0.2863\n",
      "Epoch 17/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565us/step - accuracy: 0.9517 - loss: 0.1444\n",
      "Epoch 18/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 545us/step - accuracy: 0.9390 - loss: 0.2048\n",
      "Epoch 19/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - accuracy: 0.9536 - loss: 0.1328\n",
      "Epoch 20/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step - accuracy: 0.9518 - loss: 0.1327\n",
      "Epoch 21/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - accuracy: 0.9741 - loss: 0.1086 \n",
      "Epoch 22/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 550us/step - accuracy: 0.9552 - loss: 0.1242\n",
      "Epoch 23/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561us/step - accuracy: 0.9389 - loss: 0.1401\n",
      "Epoch 24/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565us/step - accuracy: 0.9554 - loss: 0.1105\n",
      "Epoch 25/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571us/step - accuracy: 0.9654 - loss: 0.0991\n",
      "Epoch 26/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558us/step - accuracy: 0.9614 - loss: 0.1079\n",
      "Epoch 27/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - accuracy: 0.9464 - loss: 0.1444 \n",
      "Epoch 28/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - accuracy: 0.9705 - loss: 0.0844\n",
      "Epoch 29/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - accuracy: 0.9709 - loss: 0.0955 \n",
      "Epoch 30/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578us/step - accuracy: 0.9697 - loss: 0.0799\n",
      "Epoch 31/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - accuracy: 0.9517 - loss: 0.1221\n",
      "Epoch 32/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - accuracy: 0.9796 - loss: 0.0703\n",
      "Epoch 33/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - accuracy: 0.9632 - loss: 0.1163 \n",
      "Epoch 34/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - accuracy: 0.9526 - loss: 0.1517\n",
      "Epoch 35/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592us/step - accuracy: 0.9433 - loss: 0.1653\n",
      "Epoch 36/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step - accuracy: 0.9832 - loss: 0.0726\n",
      "Epoch 37/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - accuracy: 0.9742 - loss: 0.0757 \n",
      "Epoch 38/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - accuracy: 0.9694 - loss: 0.0800\n",
      "Epoch 39/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step - accuracy: 0.9774 - loss: 0.0623\n",
      "Epoch 40/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544us/step - accuracy: 0.9796 - loss: 0.0740\n",
      "Epoch 41/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - accuracy: 0.9709 - loss: 0.0752\n",
      "Epoch 42/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577us/step - accuracy: 0.9848 - loss: 0.0536 \n",
      "Epoch 43/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566us/step - accuracy: 0.9823 - loss: 0.0553 \n",
      "Epoch 44/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - accuracy: 0.9756 - loss: 0.0660\n",
      "Epoch 45/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 547us/step - accuracy: 0.9789 - loss: 0.0469 \n",
      "Epoch 46/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558us/step - accuracy: 0.9758 - loss: 0.0517 \n",
      "Epoch 47/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558us/step - accuracy: 0.9739 - loss: 0.0945\n",
      "Epoch 48/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 545us/step - accuracy: 0.9874 - loss: 0.0350\n",
      "Epoch 49/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559us/step - accuracy: 0.9893 - loss: 0.0344\n",
      "Epoch 50/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - accuracy: 0.9816 - loss: 0.0401\n",
      "Epoch 51/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - accuracy: 0.9911 - loss: 0.0496 \n",
      "Epoch 52/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571us/step - accuracy: 0.9842 - loss: 0.0846\n",
      "Epoch 53/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574us/step - accuracy: 0.9950 - loss: 0.0206\n",
      "Epoch 54/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 545us/step - accuracy: 0.9888 - loss: 0.0490\n",
      "Epoch 55/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - accuracy: 0.9883 - loss: 0.0681\n",
      "Epoch 56/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - accuracy: 0.9807 - loss: 0.0691\n",
      "Epoch 57/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 551us/step - accuracy: 0.9800 - loss: 0.0404\n",
      "Epoch 58/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 549us/step - accuracy: 0.9887 - loss: 0.0454\n",
      "Epoch 59/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - accuracy: 0.9928 - loss: 0.0289 \n",
      "Epoch 60/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574us/step - accuracy: 0.9972 - loss: 0.0209\n",
      "Epoch 61/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 545us/step - accuracy: 0.9922 - loss: 0.0379 \n",
      "Epoch 62/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - accuracy: 0.9924 - loss: 0.0266\n",
      "Epoch 63/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621us/step - accuracy: 0.9870 - loss: 0.0312 \n",
      "Epoch 64/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - accuracy: 0.9872 - loss: 0.0329 \n",
      "Epoch 65/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - accuracy: 0.9910 - loss: 0.0305 \n",
      "Epoch 66/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593us/step - accuracy: 0.9862 - loss: 0.0392 \n",
      "Epoch 67/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - accuracy: 0.9947 - loss: 0.0202 \n",
      "Epoch 68/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - accuracy: 0.9769 - loss: 0.0341 \n",
      "Epoch 69/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541us/step - accuracy: 0.9871 - loss: 0.0403 \n",
      "Epoch 70/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - accuracy: 0.9909 - loss: 0.0423\n",
      "Epoch 71/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - accuracy: 0.9959 - loss: 0.0175\n",
      "Epoch 72/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - accuracy: 0.9809 - loss: 0.0550 \n",
      "Epoch 73/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - accuracy: 0.9845 - loss: 0.0404\n",
      "Epoch 74/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542us/step - accuracy: 0.9881 - loss: 0.0368 \n",
      "Epoch 75/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608us/step - accuracy: 0.9930 - loss: 0.0213 \n",
      "Epoch 76/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - accuracy: 0.9903 - loss: 0.0263 \n",
      "Epoch 77/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544us/step - accuracy: 0.9962 - loss: 0.0176\n",
      "Epoch 78/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - accuracy: 0.9900 - loss: 0.0276\n",
      "Epoch 79/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543us/step - accuracy: 0.9898 - loss: 0.0347\n",
      "Epoch 80/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step - accuracy: 0.9946 - loss: 0.0197 \n",
      "Epoch 81/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - accuracy: 0.9881 - loss: 0.0234\n",
      "Epoch 82/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553us/step - accuracy: 0.9919 - loss: 0.0274\n",
      "Epoch 83/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548us/step - accuracy: 0.9912 - loss: 0.0362\n",
      "Epoch 84/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - accuracy: 0.9932 - loss: 0.0353 \n",
      "Epoch 85/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - accuracy: 0.9949 - loss: 0.0212 \n",
      "Epoch 86/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566us/step - accuracy: 0.9867 - loss: 0.0488\n",
      "Epoch 87/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596us/step - accuracy: 0.9895 - loss: 0.0437\n",
      "Epoch 88/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - accuracy: 0.9976 - loss: 0.0155\n",
      "Epoch 89/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553us/step - accuracy: 0.9916 - loss: 0.0239 \n",
      "Epoch 90/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554us/step - accuracy: 0.9852 - loss: 0.0387\n",
      "Epoch 91/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - accuracy: 0.9865 - loss: 0.0379 \n",
      "Epoch 92/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - accuracy: 0.9896 - loss: 0.0363 \n",
      "Epoch 93/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615us/step - accuracy: 0.9929 - loss: 0.0268 \n",
      "Epoch 94/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - accuracy: 0.9968 - loss: 0.0144\n",
      "Epoch 95/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - accuracy: 0.9826 - loss: 0.0628\n",
      "Epoch 96/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579us/step - accuracy: 0.9868 - loss: 0.0283\n",
      "Epoch 97/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591us/step - accuracy: 0.9943 - loss: 0.0407\n",
      "Epoch 98/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594us/step - accuracy: 0.9924 - loss: 0.0177 \n",
      "Epoch 99/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - accuracy: 0.9832 - loss: 0.0378 \n",
      "Epoch 100/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 551us/step - accuracy: 0.9929 - loss: 0.0168 \n",
      "Epoch 101/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561us/step - accuracy: 0.9984 - loss: 0.0192 \n",
      "Epoch 102/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - accuracy: 0.9817 - loss: 0.0483\n",
      "Epoch 103/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - accuracy: 0.9935 - loss: 0.0339\n",
      "Epoch 104/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - accuracy: 0.9877 - loss: 0.0369\n",
      "Epoch 105/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - accuracy: 0.9929 - loss: 0.0261\n",
      "Epoch 106/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627us/step - accuracy: 0.9857 - loss: 0.0292 \n",
      "Epoch 107/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - accuracy: 0.9786 - loss: 0.0406\n",
      "Epoch 108/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571us/step - accuracy: 0.9957 - loss: 0.0166 \n",
      "Epoch 109/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566us/step - accuracy: 0.9958 - loss: 0.0158 \n",
      "Epoch 110/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604us/step - accuracy: 0.9861 - loss: 0.0698\n",
      "Epoch 111/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594us/step - accuracy: 0.9846 - loss: 0.0466 \n",
      "Epoch 112/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - accuracy: 0.9898 - loss: 0.0291 \n",
      "Epoch 113/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - accuracy: 0.9938 - loss: 0.0206\n",
      "Epoch 114/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step - accuracy: 0.9926 - loss: 0.0231 \n",
      "Epoch 115/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622us/step - accuracy: 0.9955 - loss: 0.0143\n",
      "Epoch 116/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - accuracy: 0.9878 - loss: 0.0267 \n",
      "Epoch 117/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - accuracy: 0.9782 - loss: 0.0423\n",
      "Epoch 118/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558us/step - accuracy: 0.9878 - loss: 0.0484 \n",
      "Epoch 119/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - accuracy: 0.9979 - loss: 0.0142 \n",
      "Epoch 120/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566us/step - accuracy: 0.9887 - loss: 0.0286\n",
      "Epoch 121/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598us/step - accuracy: 0.9877 - loss: 0.0345\n",
      "Epoch 122/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - accuracy: 0.9972 - loss: 0.0130 \n",
      "Epoch 123/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576us/step - accuracy: 0.9852 - loss: 0.0268\n",
      "Epoch 124/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step - accuracy: 0.9862 - loss: 0.0317 \n",
      "Epoch 125/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - accuracy: 0.9951 - loss: 0.0139 \n",
      "Epoch 126/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594us/step - accuracy: 0.9955 - loss: 0.0319\n",
      "Epoch 127/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - accuracy: 0.9930 - loss: 0.0176 \n",
      "Epoch 128/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - accuracy: 0.9813 - loss: 0.0463\n",
      "Epoch 129/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - accuracy: 0.9973 - loss: 0.0194 \n",
      "Epoch 130/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - accuracy: 0.9988 - loss: 0.0119\n",
      "Epoch 131/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step - accuracy: 0.9926 - loss: 0.0131\n",
      "Epoch 132/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - accuracy: 0.9989 - loss: 0.0076\n",
      "Epoch 133/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596us/step - accuracy: 0.9963 - loss: 0.0187 \n",
      "Epoch 134/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - accuracy: 0.9996 - loss: 0.0066\n",
      "Epoch 135/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - accuracy: 0.9952 - loss: 0.0182\n",
      "Epoch 136/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - accuracy: 0.9940 - loss: 0.0233 \n",
      "Epoch 137/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - accuracy: 0.9883 - loss: 0.0333 \n",
      "Epoch 138/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - accuracy: 0.9986 - loss: 0.0200\n",
      "Epoch 139/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - accuracy: 0.9867 - loss: 0.0314 \n",
      "Epoch 140/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571us/step - accuracy: 0.9847 - loss: 0.0449\n",
      "Epoch 141/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592us/step - accuracy: 0.9909 - loss: 0.0288 \n",
      "Epoch 142/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - accuracy: 0.9821 - loss: 0.0336\n",
      "Epoch 143/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 655us/step - accuracy: 0.9958 - loss: 0.0144\n",
      "Epoch 144/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 636us/step - accuracy: 0.9891 - loss: 0.0223 \n",
      "Epoch 145/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step - accuracy: 0.9925 - loss: 0.0235 \n",
      "Epoch 146/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - accuracy: 0.9985 - loss: 0.0103 \n",
      "Epoch 147/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577us/step - accuracy: 0.9912 - loss: 0.0176 \n",
      "Epoch 148/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - accuracy: 0.9982 - loss: 0.0081 \n",
      "Epoch 149/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - accuracy: 0.9954 - loss: 0.0224 \n",
      "Epoch 150/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - accuracy: 0.9965 - loss: 0.0127 \n",
      "Epoch 151/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565us/step - accuracy: 0.9928 - loss: 0.0156 \n",
      "Epoch 152/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 664us/step - accuracy: 0.9917 - loss: 0.0224 \n",
      "Epoch 153/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - accuracy: 0.9927 - loss: 0.0155 \n",
      "Epoch 154/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - accuracy: 0.9959 - loss: 0.0158\n",
      "Epoch 155/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594us/step - accuracy: 0.9981 - loss: 0.0153\n",
      "Epoch 156/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569us/step - accuracy: 0.9814 - loss: 0.0552\n",
      "Epoch 157/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - accuracy: 0.9847 - loss: 0.0560 \n",
      "Epoch 158/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - accuracy: 0.9838 - loss: 0.0355 \n",
      "Epoch 159/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step - accuracy: 0.9894 - loss: 0.0278 \n",
      "Epoch 160/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621us/step - accuracy: 0.9929 - loss: 0.0280 \n",
      "Epoch 161/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - accuracy: 0.9979 - loss: 0.0154 \n",
      "Epoch 162/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step - accuracy: 0.9927 - loss: 0.0168 \n",
      "Epoch 163/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - accuracy: 0.9927 - loss: 0.0158\n",
      "Epoch 164/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step - accuracy: 0.9960 - loss: 0.0145 \n",
      "Epoch 165/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625us/step - accuracy: 0.9946 - loss: 0.0222 \n",
      "Epoch 166/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - accuracy: 0.9934 - loss: 0.0201 \n",
      "Epoch 167/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - accuracy: 0.9932 - loss: 0.0217\n",
      "Epoch 168/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606us/step - accuracy: 0.9958 - loss: 0.0147\n",
      "Epoch 169/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606us/step - accuracy: 0.9964 - loss: 0.0092 \n",
      "Epoch 170/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - accuracy: 0.9994 - loss: 0.0041 \n",
      "Epoch 171/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - accuracy: 0.9914 - loss: 0.0245 \n",
      "Epoch 172/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - accuracy: 0.9979 - loss: 0.0101\n",
      "Epoch 173/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627us/step - accuracy: 0.9923 - loss: 0.0213\n",
      "Epoch 174/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 616us/step - accuracy: 0.9892 - loss: 0.0365 \n",
      "Epoch 175/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - accuracy: 0.9825 - loss: 0.0635 \n",
      "Epoch 176/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 636us/step - accuracy: 0.9933 - loss: 0.0214 \n",
      "Epoch 177/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579us/step - accuracy: 0.9895 - loss: 0.0232 \n",
      "Epoch 178/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - accuracy: 0.9880 - loss: 0.0235\n",
      "Epoch 179/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592us/step - accuracy: 0.9922 - loss: 0.0213 \n",
      "Epoch 180/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553us/step - accuracy: 0.9964 - loss: 0.0085 \n",
      "Epoch 181/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - accuracy: 0.9954 - loss: 0.0111 \n",
      "Epoch 182/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561us/step - accuracy: 0.9965 - loss: 0.0114\n",
      "Epoch 183/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542us/step - accuracy: 0.9929 - loss: 0.0210\n",
      "Epoch 184/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574us/step - accuracy: 0.9976 - loss: 0.0088 \n",
      "Epoch 185/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592us/step - accuracy: 0.9899 - loss: 0.0254 \n",
      "Epoch 186/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576us/step - accuracy: 0.9944 - loss: 0.0187 \n",
      "Epoch 187/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608us/step - accuracy: 0.9930 - loss: 0.0173 \n",
      "Epoch 188/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step - accuracy: 0.9941 - loss: 0.0156 \n",
      "Epoch 189/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - accuracy: 0.9976 - loss: 0.0090\n",
      "Epoch 190/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - accuracy: 0.9956 - loss: 0.0172\n",
      "Epoch 191/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - accuracy: 0.9959 - loss: 0.0154\n",
      "Epoch 192/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565us/step - accuracy: 0.9887 - loss: 0.0408 \n",
      "Epoch 193/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577us/step - accuracy: 0.9983 - loss: 0.0113\n",
      "Epoch 194/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598us/step - accuracy: 0.9867 - loss: 0.0195\n",
      "Epoch 195/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - accuracy: 0.9987 - loss: 0.0085 \n",
      "Epoch 196/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553us/step - accuracy: 0.9986 - loss: 0.0085\n",
      "Epoch 197/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577us/step - accuracy: 0.9896 - loss: 0.0221 \n",
      "Epoch 198/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step - accuracy: 0.9978 - loss: 0.0113 \n",
      "Epoch 199/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - accuracy: 0.9998 - loss: 0.0038\n",
      "Epoch 200/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - accuracy: 0.9955 - loss: 0.0150 \n",
      "found in bag: ``\n",
      "found in bag: tak\n",
      "found in bag: cvar\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: hspital\n",
      "found in bag: lookup\n",
      "found in bag: for\n",
      "found in bag: paty\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: tha'ts\n",
      "found in bag: help\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: nee\n",
      "found in bag: to\n",
      "found in bag: pick\n",
      "found in bag: up\n",
      "found in bag: my\n",
      "found in bag: med\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: aid\n",
      "found in bag: is\n",
      "found in bag: off\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: is\n",
      "found in bag: ther\n",
      "found in bag: a\n",
      "found in bag: phys\n",
      "found in bag: i\n",
      "found in bag: can\n",
      "found in bag: speak\n",
      "found in bag: with\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: ar\n",
      "found in bag: ther\n",
      "found in bag: any\n",
      "found in bag: effect\n",
      "found in bag: i\n",
      "found in bag: should\n",
      "found in bag: watch\n",
      "found in bag: out\n",
      "found in bag: for\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: thank\n",
      "found in bag: you\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: can\n",
      "found in bag: i\n",
      "found in bag: speak\n",
      "found in bag: to\n",
      "found in bag: a\n",
      "found in bag: healthc\n",
      "found in bag: provid\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: ca\n",
      "found in bag: n't\n",
      "found in bag: apprecy\n",
      "found in bag: you\n",
      "found in bag: enough\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: cheerio\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: how\n",
      "found in bag: 's\n",
      "found in bag: it\n",
      "found in bag: going\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: pharm\n",
      "found in bag: around\n",
      "found in bag: her\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: wthat\n",
      "found in bag: should\n",
      "found in bag: i\n",
      "found in bag: know\n",
      "found in bag: about\n",
      "found in bag: my\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: level\n",
      "found in bag: right\n",
      "found in bag: now\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: help\n",
      "found in bag: you\n",
      "found in bag: provid\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: can\n",
      "found in bag: you\n",
      "found in bag: me\n",
      "found in bag: about\n",
      "found in bag: the\n",
      "found in bag: poss\n",
      "found in bag: sid\n",
      "found in bag: effect\n",
      "found in bag: of\n",
      "found in bag: tak\n",
      "found in bag: thi\n",
      "found in bag: drug\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "found in bag: ``\n",
      "found in bag: list\n",
      "found in bag: of\n",
      "found in bag: pharm\n",
      "found in bag: nearby\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: should\n",
      "found in bag: i\n",
      "found in bag: expect\n",
      "found in bag: in\n",
      "found in bag: term\n",
      "found in bag: of\n",
      "found in bag: sid\n",
      "found in bag: influ\n",
      "found in bag: from\n",
      "found in bag: thi\n",
      "found in bag: med\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: hav\n",
      "found in bag: troubl\n",
      "found in bag: cont\n",
      "found in bag: or\n",
      "found in bag: think\n",
      "found in bag: clear\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: aston\n",
      "found in bag: ,\n",
      "found in bag: thank\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: many\n",
      "found in bag: thank\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: ar\n",
      "found in bag: the\n",
      "found in bag: pot\n",
      "found in bag: sid\n",
      "found in bag: repercuss\n",
      "found in bag: of\n",
      "found in bag: thi\n",
      "found in bag: med\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: loc\n",
      "found in bag: pharm\n",
      "found in bag: with\n",
      "found in bag: a\n",
      "found in bag: pharm\n",
      "found in bag: techn\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: hello\n",
      "found in bag: ,\n",
      "found in bag: good\n",
      "found in bag: to\n",
      "found in bag: see\n",
      "found in bag: you\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: find\n",
      "found in bag: pharm\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: should\n",
      "found in bag: i\n",
      "found in bag: expect\n",
      "found in bag: in\n",
      "found in bag: term\n",
      "found in bag: of\n",
      "found in bag: sid\n",
      "found in bag: effect\n",
      "found in bag: from\n",
      "found in bag: thi\n",
      "found in bag: medicaton\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: wher\n",
      "found in bag: can\n",
      "found in bag: i\n",
      "found in bag: fil\n",
      "found in bag: a\n",
      "found in bag: prescrib\n",
      "found in bag: neighbo\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: ther\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: ar\n",
      "found in bag: ther\n",
      "found in bag: any\n",
      "found in bag: common\n",
      "found in bag: sid\n",
      "found in bag: effect\n",
      "found in bag: assocy\n",
      "found in bag: with\n",
      "found in bag: thi\n",
      "found in bag: cur\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: research\n",
      "found in bag: for\n",
      "found in bag: hospit\n",
      "found in bag: to\n",
      "found in bag: transf\n",
      "found in bag: paty\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: hyi\n",
      "found in bag: ther\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: must\n",
      "found in bag: be\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: can\n",
      "found in bag: you\n",
      "found in bag: describ\n",
      "found in bag: any\n",
      "found in bag: undesir\n",
      "found in bag: effect\n",
      "found in bag: that\n",
      "found in bag: could\n",
      "found in bag: occ\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: can\n",
      "found in bag: i\n",
      "found in bag: find\n",
      "found in bag: a\n",
      "found in bag: hospit\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: cjan\n",
      "found in bag: you\n",
      "found in bag: giv\n",
      "found in bag: me\n",
      "found in bag: an\n",
      "found in bag: upd\n",
      "found in bag: on\n",
      "found in bag: my\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: is\n",
      "found in bag: my\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: within\n",
      "found in bag: a\n",
      "found in bag: health\n",
      "found in bag: rang\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: loc\n",
      "found in bag: pharm\n",
      "found in bag: with\n",
      "found in bag: a\n",
      "found in bag: pharm\n",
      "found in bag: techn\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: is\n",
      "found in bag: it\n",
      "found in bag: poss\n",
      "found in bag: to\n",
      "found in bag: meet\n",
      "found in bag: with\n",
      "found in bag: a\n",
      "found in bag: phys\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: 'm\n",
      "found in bag: expery\n",
      "found in bag: diarrhoe\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: the\n",
      "found in bag: verdict\n",
      "found in bag: on\n",
      "found in bag: my\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: today\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: nee\n",
      "found in bag: to\n",
      "found in bag: speak\n",
      "found in bag: with\n",
      "found in bag: a\n",
      "found in bag: doct\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: you\n",
      "found in bag: 've\n",
      "found in bag: been\n",
      "found in bag: so\n",
      "found in bag: kidn\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: welcom\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: nic\n",
      "found in bag: to\n",
      "found in bag: see\n",
      "found in bag: you\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: vay\n",
      "found in bag: i\n",
      "found in bag: request\n",
      "found in bag: a\n",
      "found in bag: refil\n",
      "found in bag: of\n",
      "found in bag: my\n",
      "found in bag: prescrib\n",
      "found in bag: ,\n",
      "found in bag: pleas\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: that\n",
      "found in bag: mean\n",
      "found in bag: a\n",
      "found in bag: ot\n",
      "found in bag: to\n",
      "found in bag: me\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: should\n",
      "found in bag: i\n",
      "found in bag: know\n",
      "found in bag: about\n",
      "found in bag: my\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: level\n",
      "found in bag: right\n",
      "found in bag: now\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: quo\n",
      "found in bag: ar\n",
      "found in bag: yo\n",
      "found in bag: proficy\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: is\n",
      "found in bag: ther\n",
      "found in bag: a\n",
      "found in bag: doct\n",
      "found in bag: avail\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: quo\n",
      "found in bag: ar\n",
      "found in bag: yo\n",
      "found in bag: compet\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: bye\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: greet\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: want\n",
      "found in bag: to\n",
      "found in bag: brows\n",
      "found in bag: for\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: result\n",
      "found in bag: hist\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: farewel\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: which\n",
      "found in bag: drug\n",
      "found in bag: dont\n",
      "found in bag: hav\n",
      "found in bag: advers\n",
      "found in bag: react\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: od\n",
      "found in bag: you\n",
      "found in bag: hav\n",
      "found in bag: the\n",
      "found in bag: latest\n",
      "found in bag: read\n",
      "found in bag: of\n",
      "found in bag: my\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: an\n",
      "found in bag: you\n",
      "found in bag: tel\n",
      "found in bag: me\n",
      "found in bag: what\n",
      "found in bag: my\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: numb\n",
      "found in bag: ar\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: bye\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: could\n",
      "found in bag: you\n",
      "found in bag: outlin\n",
      "found in bag: the\n",
      "found in bag: pot\n",
      "found in bag: sid\n",
      "found in bag: effect\n",
      "found in bag: i\n",
      "found in bag: might\n",
      "found in bag: encount\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: requir\n",
      "found in bag: the\n",
      "found in bag: attenty\n",
      "found in bag: of\n",
      "found in bag: a\n",
      "found in bag: doct\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: ar\n",
      "found in bag: the\n",
      "found in bag: chant\n",
      "found in bag: of\n",
      "found in bag: expery\n",
      "found in bag: sid\n",
      "found in bag: fefect\n",
      "found in bag: with\n",
      "found in bag: thi\n",
      "found in bag: drug\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: see\n",
      "found in bag: ta\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: himy\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: good\n",
      "found in bag: afteroon\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: ar\n",
      "found in bag: the\n",
      "found in bag: poss\n",
      "found in bag: advers\n",
      "found in bag: outcom\n",
      "found in bag: of\n",
      "found in bag: thi\n",
      "found in bag: tre\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: load\n",
      "found in bag: paty\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: result\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: see\n",
      "found in bag: ya\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: yo\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: how\n",
      "found in bag: you\n",
      "found in bag: could\n",
      "found in bag: hel\n",
      "found in bag: me\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: hey\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: may\n",
      "found in bag: i\n",
      "found in bag: schedule\n",
      "found in bag: a\n",
      "found in bag: consult\n",
      "found in bag: with\n",
      "found in bag: a\n",
      "found in bag: doctro\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: how\n",
      "found in bag: you\n",
      "found in bag: could\n",
      "found in bag: support\n",
      "found in bag: me\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: alright\n",
      "found in bag: day\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: hiy\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: find\n",
      "found in bag: hospit\n",
      "found in bag: with\n",
      "found in bag: tre\n",
      "found in bag: facil\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: nee\n",
      "found in bag: med\n",
      "found in bag: support\n",
      "found in bag: from\n",
      "found in bag: a\n",
      "found in bag: doct\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: find\n",
      "found in bag: hospit\n",
      "found in bag: near\n",
      "found in bag: me\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: unear\n",
      "found in bag: an\n",
      "found in bag: emerg\n",
      "found in bag: hospit\n",
      "found in bag: near\n",
      "found in bag: me\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: wher\n",
      "found in bag: is\n",
      "found in bag: the\n",
      "found in bag: closest\n",
      "found in bag: hospit\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: list\n",
      "found in bag: al\n",
      "found in bag: pharmaceut\n",
      "found in bag: suit\n",
      "found in bag: for\n",
      "found in bag: paty\n",
      "found in bag: with\n",
      "found in bag: advers\n",
      "found in bag: react\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: meac\n",
      "found in bag: out\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: 's\n",
      "found in bag: up\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: nee\n",
      "found in bag: to\n",
      "found in bag: reil\n",
      "found in bag: my\n",
      "found in bag: med\n",
      "found in bag: supply\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: could\n",
      "found in bag: i\n",
      "found in bag: see\n",
      "found in bag: a\n",
      "found in bag: med\n",
      "found in bag: ,\n",
      "found in bag: pleas\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: hey\n",
      "found in bag: ,\n",
      "found in bag: how\n",
      "found in bag: ar\n",
      "found in bag: you\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: task\n",
      "found in bag: to\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: yao\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: blood\n",
      "found in bag: cpressure\n",
      "found in bag: dat\n",
      "found in bag: man\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: kind\n",
      "found in bag: of\n",
      "found in bag: react\n",
      "found in bag: might\n",
      "found in bag: i\n",
      "found in bag: expery\n",
      "found in bag: from\n",
      "found in bag: thi\n",
      "found in bag: med\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: can\n",
      "found in bag: you\n",
      "found in bag: bring\n",
      "found in bag: to\n",
      "found in bag: thi\n",
      "found in bag: porject\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: ar\n",
      "found in bag: yo\n",
      "found in bag: tech\n",
      "found in bag: skil\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: hav\n",
      "found in bag: musc\n",
      "found in bag: pain\n",
      "found in bag: and\n",
      "found in bag: pain\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: thnk\n",
      "found in bag: you\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: find\n",
      "found in bag: phramacies\n",
      "found in bag: near\n",
      "found in bag: me\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: research\n",
      "found in bag: for\n",
      "found in bag: drugst\n",
      "found in bag: nearby\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: nearby\n",
      "found in bag: pharm\n",
      "found in bag: op\n",
      "found in bag: now\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: ar\n",
      "found in bag: ther\n",
      "found in bag: any\n",
      "found in bag: effect\n",
      "found in bag: i\n",
      "found in bag: should\n",
      "found in bag: be\n",
      "found in bag: aw\n",
      "found in bag: of\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: want\n",
      "found in bag: to\n",
      "found in bag: search\n",
      "found in bag: for\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: result\n",
      "found in bag: hist\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: hav\n",
      "found in bag: you\n",
      "found in bag: checekd\n",
      "found in bag: my\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: rec\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: hav\n",
      "found in bag: pain\n",
      "found in bag: and\n",
      "found in bag: cramp\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: task\n",
      "found in bag: rel\n",
      "found in bag: to\n",
      "found in bag: blocd\n",
      "found in bag: press\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: 'm\n",
      "found in bag: epxery\n",
      "found in bag: nause\n",
      "found in bag: and\n",
      "found in bag: vomit\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: thank\n",
      "found in bag: a\n",
      "found in bag: lot\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: could\n",
      "found in bag: you\n",
      "found in bag: refil\n",
      "found in bag: my\n",
      "found in bag: prescrib\n",
      "found in bag: for\n",
      "found in bag: me\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: requir\n",
      "found in bag: to\n",
      "found in bag: consult\n",
      "found in bag: with\n",
      "found in bag: a\n",
      "found in bag: med\n",
      "found in bag: doct\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: search\n",
      "found in bag: for\n",
      "found in bag: pharm\n",
      "found in bag: that\n",
      "found in bag: mak\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: whgt\n",
      "found in bag: ar\n",
      "found in bag: the\n",
      "found in bag: pot\n",
      "found in bag: sid\n",
      "found in bag: effect\n",
      "found in bag: of\n",
      "found in bag: thi\n",
      "found in bag: med\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: ar\n",
      "found in bag: yo\n",
      "found in bag: cap\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: 'm\n",
      "found in bag: apprecy\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: see\n",
      "found in bag: you\n",
      "found in bag: aft\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: okp\n",
      "found in bag: advers\n",
      "found in bag: drug\n",
      "found in bag: mod\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: my\n",
      "found in bag: larynx\n",
      "found in bag: is\n",
      "found in bag: sor\n",
      "found in bag: and\n",
      "found in bag: scratchy\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: is\n",
      "found in bag: my\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: stabl\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: see\n",
      "found in bag: you\n",
      "found in bag: quick\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: can\n",
      "found in bag: you\n",
      "found in bag: do\n",
      "found in bag: good\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: wher\n",
      "found in bag: can\n",
      "found in bag: i\n",
      "found in bag: find\n",
      "found in bag: a\n",
      "found in bag: pharm\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: search\n",
      "found in bag: for\n",
      "found in bag: pharm\n",
      "found in bag: that\n",
      "found in bag: del\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: hepy\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: list\n",
      "found in bag: al\n",
      "found in bag: drug\n",
      "found in bag: suit\n",
      "found in bag: for\n",
      "found in bag: paty\n",
      "found in bag: with\n",
      "found in bag: advers\n",
      "found in bag: react\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "found in bag: ``\n",
      "found in bag: seach\n",
      "found in bag: pharm\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: is\n",
      "found in bag: my\n",
      "found in bag: med\n",
      "found in bag: avail\n",
      "found in bag: for\n",
      "found in bag: pickup\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: would\n",
      "found in bag: lik\n",
      "found in bag: to\n",
      "found in bag: reqeust\n",
      "found in bag: a\n",
      "found in bag: doct\n",
      "found in bag: 's\n",
      "found in bag: appoint\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: wha\n",
      "found in bag: ar\n",
      "found in bag: yo\n",
      "found in bag: abl\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: 'd\n",
      "found in bag: lik\n",
      "found in bag: to\n",
      "found in bag: ord\n",
      "found in bag: a\n",
      "found in bag: batch\n",
      "found in bag: of\n",
      "found in bag: my\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: 's\n",
      "found in bag: my\n",
      "found in bag: systolic/diastol\n",
      "found in bag: press\n",
      "found in bag: right\n",
      "found in bag: now\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: do\n",
      "found in bag: you\n",
      "found in bag: hav\n",
      "found in bag: the\n",
      "found in bag: newest\n",
      "found in bag: read\n",
      "found in bag: of\n",
      "found in bag: my\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: wel\n",
      "found in bag: morn\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: wel\n",
      "found in bag: met\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: skil\n",
      "found in bag: do\n",
      "found in bag: you\n",
      "found in bag: bring\n",
      "found in bag: to\n",
      "found in bag: the\n",
      "found in bag: tableau\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: can\n",
      "found in bag: you\n",
      "found in bag: direct\n",
      "found in bag: me\n",
      "found in bag: to\n",
      "found in bag: a\n",
      "found in bag: doct\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: mod\n",
      "found in bag: ar\n",
      "found in bag: you\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i'n\n",
      "found in bag: very\n",
      "found in bag: grat\n",
      "found in bag: for\n",
      "found in bag: yo\n",
      "found in bag: assist\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: 'm\n",
      "found in bag: feel\n",
      "found in bag: cold\n",
      "found in bag: or\n",
      "found in bag: hot\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: hey\n",
      "found in bag: ,\n",
      "found in bag: good\n",
      "found in bag: to\n",
      "found in bag: seg\n",
      "found in bag: you\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: find\n",
      "found in bag: a\n",
      "found in bag: hospit\n",
      "found in bag: in\n",
      "found in bag: [\n",
      "found in bag: city/town\n",
      "found in bag: ]\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: whaut\n",
      "found in bag: do\n",
      "found in bag: you\n",
      "found in bag: spec\n",
      "found in bag: in\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: how\n",
      "found in bag: you\n",
      "found in bag: can\n",
      "found in bag: be\n",
      "found in bag: help\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: kind\n",
      "found in bag: of\n",
      "found in bag: react\n",
      "found in bag: should\n",
      "found in bag: i\n",
      "found in bag: be\n",
      "found in bag: prep\n",
      "found in bag: for\n",
      "found in bag: with\n",
      "found in bag: thi\n",
      "found in bag: drug\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: hav\n",
      "found in bag: bel\n",
      "found in bag: pain\n",
      "found in bag: and\n",
      "found in bag: cramp\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: 'm\n",
      "found in bag: grat\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: 's\n",
      "found in bag: the\n",
      "found in bag: verdict\n",
      "found in bag: on\n",
      "found in bag: my\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: today\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: til\n",
      "found in bag: nnxt\n",
      "found in bag: tim\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: hav\n",
      "found in bag: chest\n",
      "found in bag: tight\n",
      "found in bag: and\n",
      "found in bag: malay\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: hi\n",
      "found in bag: ther\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: see\n",
      "found in bag: you\n",
      "found in bag: near\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: rev\n",
      "found in bag: apprecy\n",
      "found in bag: it\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: salutatoin\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: may\n",
      "found in bag: i\n",
      "found in bag: request\n",
      "found in bag: a\n",
      "found in bag: refil\n",
      "found in bag: of\n",
      "found in bag: my\n",
      "found in bag: prescrib\n",
      "found in bag: ,\n",
      "found in bag: pleas\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: hav\n",
      "found in bag: a\n",
      "found in bag: persist\n",
      "found in bag: headach\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: can\n",
      "found in bag: you\n",
      "found in bag: told\n",
      "found in bag: me\n",
      "found in bag: what\n",
      "found in bag: my\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: numb\n",
      "found in bag: ar\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: ar\n",
      "found in bag: yo\n",
      "found in bag: strengths\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: search\n",
      "found in bag: for\n",
      "found in bag: hospit\n",
      "found in bag: with\n",
      "found in bag: car\n",
      "found in bag: serv\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: that\n",
      "found in bag: 's\n",
      "found in bag: handy\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: is\n",
      "found in bag: my\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: mtabl\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: than\n",
      "found in bag: you\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: nearby\n",
      "found in bag: pharmacio\n",
      "found in bag: op\n",
      "found in bag: now\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: hospitasl\n",
      "found in bag: around\n",
      "found in bag: her\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: is\n",
      "found in bag: my\n",
      "found in bag: cur\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: read\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "636 documents\n",
      "12 intents ['adverse_drug', 'blood_pressure', 'blood_pressure_search', 'doctor', 'goodbye', 'greeting', 'hospital_search', 'medication', 'options', 'pharmacy_search', 'symptoms', 'thanks']\n",
      "659 unique stemmed words ['!', \"'\", \"''\", \"'d\", \"'im\", \"'m\", \"'re\", \"'s\", \"'ve\", '(', ')', ',', '.', '24-hour', '24/7', '[', ']', '``', 'a', 'abdoin', 'abdomin', 'abl', 'about', 'acceiv', 'ach', 'achiev', 'acknowledg', 'acn', 'acquisit', 'adio', 'admin', 'advers', 'advesr', 'aft', 'afternoon', 'afteroon', 'afterward', 'ahoy', 'ahv', 'aid', 'al', 'almost', 'alright', 'an', 'and', 'answ', 'anticip', 'any', 'anyon', 'appoint', 'apprec', 'apprecy', 'ar', 'area', 'around', 'arrang', 'as', 'ask', 'assist', 'assocy', 'aston', 'at', 'attenty', 'avail', 'aw', 'awesom', 'batch', 'bby', 'be', 'been', 'behavy', 'behold', 'bel', 'blat', 'blo', 'blocd', 'blod', 'blohod', 'blood', 'bloow', 'bolod', 'bood', 'book', 'bound', 'bp', 'brea', 'breath', 'bring', 'brows', 'bu', 'buen', 'bunch', 'by', 'bye', 'bye-bxy', 'bye-by', 'ca', \"caa't\", 'cad', 'cal', 'can', 'cap', 'car', 'cardiolog', 'catch', 'caus', 'cent', 'chant', 'chat', 'checekd', 'check', 'cheerio', 'chest', 'chil', 'chos', 'chrissakes', 'ciao', 'city/municipal', 'city/town', 'cjan', 'clear', 'clin', 'clinically/hospital', 'clos', 'closest', 'cold', 'collect', 'common', 'compet', 'comply', 'concern', 'congest', 'consequ', 'consult', 'cont', 'contribut', 'coudl', 'cough', 'could', 'covid-19', 'covid-k19', 'cpressure', 'cramp', 'cur', 'cvar', 'dat', 'day', 'dee', 'deeplry', 'deeply', 'del', 'delight', 'describ', 'detail', 'detil', 'dext', 'diarrhe', 'diarrhoe', 'did', 'digest', 'direct', 'discomfort', 'dispens', 'dizzy', 'dlat', 'do', 'doabl', 'doct', 'doctro', 'doing', 'dont', 'dort', 'downsid', 'drawback', 'drive-thru', 'drug', 'drugst', 'duty', 'e.g.', 'easy', 'ebrea', 'eczem', 'efel', 'effect', 'emerg', 'encount', 'enough', 'entir', 'entry', 'epharm', 'epxery', 'esult', 'ev', 'everyon', 'evfect', 'excel', 'exery', 'expect', 'experty', 'expery', 'explain', 'extrem', 'fac', 'facil', 'facilit', 'farewel', 'farewelql', 'fatigu', 'feel', 'fefect', 'fev', 'fil', 'find', 'finsd', 'finyd', 'flu', 'fnd', 'for', 'found', 'frisk', 'from', 'fulfil', 'furn', 'gap', 'gath', 'gaz', 'geet', 'gest', 'get', 'giv', 'go', 'gogd', 'going', 'gokod', 'gonig', 'good', 'goodby', 'goodbyt', 'goodnighl', 'goodnight', 'gookby', 'got', 'grat', 'gre', 'greet', 'gye', 'h', 'handy', 'hav', 'headach', 'heal', 'healo', 'health', 'healthc', 'healthy', 'heartburn', 'heh', 'hel', 'hello', 'help', 'helrp', 'hemy', 'hepy', 'her', 'hey', 'hi', 'high', 'himy', 'hist', 'hiy', 'hopit', 'hopsit', 'hosit', 'hosp', 'hospit', 'hospitasl', 'hospt', 'hot', 'how', 'howdy', 'hoy', 'hspital', 'hwat', 'hwody', 'hyi', 'hyw', 'i', \"i'n\", 'icu', 'id', 'im', 'impend', 'in', 'inauspicy', 'incred', 'indigest', 'influ', 'inform', 'ins', 'intend', 'irrit', 'is', 'issu', 'it', 'jash', 'joint', 'kidn', 'kind', 'know', 'known', 'knvwn', 'largo', 'larynx', 'lat', 'lateb', 'latest', 'lco', 'leav', 'let', 'letharg', 'level', 'lifeskv', 'light/noise', 'lighthead', 'lik', 'lind', 'list', 'liyghthead', 'load', 'loc', 'loch', 'locn', 'locta', 'log', 'long', 'loo', 'look', 'lookup', 'lot', 'ltim', 'maggio', 'magn', 'mak', 'malay', 'man', 'many', 'may', 'me', 'meac', 'mean', 'meas', 'med', 'medicatifon', 'medicaton', 'medicc', 'medicin', 'medicinq', 'meet', 'met', 'mfy', 'might', 'migt', 'mil', 'mod', 'modlu', 'morn', 'mtabl', 'mte', 'much', 'musc', 'must', 'my', \"n't\", 'nar', 'nause', 'near', 'nearby', 'nearest', 'nee', 'neg', 'neharby', 'neighb', 'neighbo', 'new', 'newest', 'next', 'nic', 'nneg', 'nnxt', 'noe', 'noee', 'nomin', 'nos', 'now', 'noxy', 'numb', 'oblgy', 'occ', 'occup', 'oct', 'od', 'of', 'off', 'ogod', 'oing', 'ok', 'okp', 'on', 'op', 'opn', 'oprescrib', 'or', 'ord', 'ot', 'out', 'outcom', 'outlin', 'over-the-count', 'overal', 'ow', 'pain', 'painb', 'paty', 'pbin', 'peac', 'pedy', 'persist', 'persistnet', 'pfrescription', 'pharm', 'pharmac', 'pharmaceut', 'pharmacio', 'phharmacy', 'phospit', 'phramacies', 'phrmacy', 'phys', 'physc', 'physy', 'pick', 'pickup', 'pinpoint', 'pkckup', 'pleas', 'poharm', 'point', 'pois', 'porject', 'poss', 'possbl', 'pot', 'ppharmacies', 'prep', 'prescrib', 'prescrip', 'prescripg', 'presrib', 'press', 'profess', 'proficy', 'profound', 'provid', 'providevr', 'ps', 'puffy', 'pyleas', 'quick', 'quo', 'rang', 'rash', 'react', 'read', 'ready', 'real', 'rearrang', 'reat', 'rec', 'recogn', 'refil', 'reflil', 'refresh', 'reil', 'rel', 'reord', 'reoult', 'repercuss', 'repl', 'report', 'reqeust', 'request', 'requir', 'research', 'result', 'rev', 'right', 'risk', 'rnge', 'room', 'rpescrib', 'rplenish', 'rpovid', 'rul', 'runny', 'salut', 'salutatoin', 'savio', 'say', 'sbe', 'schedule', 'scratchy', 'se', 'seach', 'searah', 'search', 'see', 'seg', 'seh', 'sens', 'sensipt', 'sensit', 'serv', 'sharm', 'short', 'shot', 'should', 'show', 'sid', 'sign', 'skil', 'skils', 'skin', 'so', 'soon', 'sor', 'spe', 'speak', 'spec', 'special', 'sress', 'stabl', 'stat', 'strengths', 'strong', 'stubborn', 'such', 'suit', 'supply', 'support', 'surgery', 'surround', 'swol', 'systolic/diastol', 'ta', 'tabl', 'tableau', 'tae', 'tahnk', 'tak', 'tal', 'talk', 'task', 'tech', 'techn', 'technicd', 'tel', 'telemedicin', 'term', \"tha'ts\", 'than', 'thank', 'thansk', 'thantk', 'that', 'the', 'ther', 'thi', 'think', 'thnk', 'throat', 'tight', 'tighvt', 'til', 'tim', 'tir', 'to', 'today', 'told', 'town/town', 'trail', 'tranquil', 'transf', 'transfus', 'tranusf', 'tre', 'trhoat', 'troubl', 'typ', 'uh', 'undesir', 'unear', 'unearth', 'unfav', 'unfavo', 'unintend', 'uninvit', 'unit', 'until', 'unus', 'unw', 'up', 'upd', 'uregnt', 'urg', 'us', 'usng', 'util', 'vaccin', 'vaccy', 'vay', 'ver', 'verdict', 'vertigo', 'very', 'vomit', 'waht', 'want', 'wat', 'watch', 'weak', 'wel', 'welcom', 'wha', 'whab', 'whac', 'whar', 'what', 'whaut', 'wheez', 'wher', 'whereby', 'whereof', 'whgt', 'which', 'whil', 'whmt', 'whnt', 'wit', 'with', 'within', 'wlecom', 'wond', 'would', 'wthat', 'xthanks', 'ya', 'yao', 'yo', 'you']\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mist861/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n",
      "/home/mist861/anaconda3/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py:33: UserWarning:\n",
      "\n",
      "Argument `decay` is no longer supported and will be ignored.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1316 - loss: 2.4062   \n",
      "Epoch 2/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591us/step - accuracy: 0.4743 - loss: 1.7191\n",
      "Epoch 3/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - accuracy: 0.6024 - loss: 1.1511 \n",
      "Epoch 4/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 614us/step - accuracy: 0.7100 - loss: 0.8369\n",
      "Epoch 5/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608us/step - accuracy: 0.7475 - loss: 0.6884\n",
      "Epoch 6/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - accuracy: 0.8050 - loss: 0.5507\n",
      "Epoch 7/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627us/step - accuracy: 0.8187 - loss: 0.5174\n",
      "Epoch 8/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586us/step - accuracy: 0.8603 - loss: 0.4295\n",
      "Epoch 9/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 741us/step - accuracy: 0.8660 - loss: 0.3640\n",
      "Epoch 10/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 614us/step - accuracy: 0.8655 - loss: 0.3471\n",
      "Epoch 11/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - accuracy: 0.8977 - loss: 0.2574\n",
      "Epoch 12/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569us/step - accuracy: 0.8699 - loss: 0.3506\n",
      "Epoch 13/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578us/step - accuracy: 0.9216 - loss: 0.2501\n",
      "Epoch 14/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577us/step - accuracy: 0.9130 - loss: 0.2207\n",
      "Epoch 15/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step - accuracy: 0.9282 - loss: 0.1865\n",
      "Epoch 16/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598us/step - accuracy: 0.9315 - loss: 0.1821\n",
      "Epoch 17/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - accuracy: 0.9374 - loss: 0.1849\n",
      "Epoch 18/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598us/step - accuracy: 0.9559 - loss: 0.1363\n",
      "Epoch 19/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step - accuracy: 0.9459 - loss: 0.1579\n",
      "Epoch 20/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - accuracy: 0.9603 - loss: 0.1557\n",
      "Epoch 21/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.9607 - loss: 0.1178\n",
      "Epoch 22/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569us/step - accuracy: 0.9769 - loss: 0.0963 \n",
      "Epoch 23/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627us/step - accuracy: 0.9564 - loss: 0.1003\n",
      "Epoch 24/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step - accuracy: 0.9650 - loss: 0.1115\n",
      "Epoch 25/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - accuracy: 0.9736 - loss: 0.0834\n",
      "Epoch 26/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - accuracy: 0.9736 - loss: 0.0974\n",
      "Epoch 27/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565us/step - accuracy: 0.9667 - loss: 0.1096\n",
      "Epoch 28/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615us/step - accuracy: 0.9545 - loss: 0.1235\n",
      "Epoch 29/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591us/step - accuracy: 0.9697 - loss: 0.1000\n",
      "Epoch 30/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step - accuracy: 0.9734 - loss: 0.0624\n",
      "Epoch 31/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - accuracy: 0.9648 - loss: 0.1124\n",
      "Epoch 32/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - accuracy: 0.9558 - loss: 0.1231\n",
      "Epoch 33/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - accuracy: 0.9567 - loss: 0.1198\n",
      "Epoch 34/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593us/step - accuracy: 0.9819 - loss: 0.0689\n",
      "Epoch 35/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604us/step - accuracy: 0.9668 - loss: 0.0852\n",
      "Epoch 36/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579us/step - accuracy: 0.9423 - loss: 0.1591\n",
      "Epoch 37/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579us/step - accuracy: 0.9874 - loss: 0.0478\n",
      "Epoch 38/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - accuracy: 0.9789 - loss: 0.0618\n",
      "Epoch 39/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561us/step - accuracy: 0.9837 - loss: 0.0662 \n",
      "Epoch 40/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594us/step - accuracy: 0.9806 - loss: 0.0656 \n",
      "Epoch 41/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - accuracy: 0.9674 - loss: 0.0894\n",
      "Epoch 42/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569us/step - accuracy: 0.9789 - loss: 0.0800\n",
      "Epoch 43/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - accuracy: 0.9918 - loss: 0.0418\n",
      "Epoch 44/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - accuracy: 0.9734 - loss: 0.0581\n",
      "Epoch 45/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.9556 - loss: 0.1273\n",
      "Epoch 46/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 549us/step - accuracy: 0.9756 - loss: 0.1098\n",
      "Epoch 47/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540us/step - accuracy: 0.9583 - loss: 0.0917 \n",
      "Epoch 48/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - accuracy: 0.9762 - loss: 0.0649\n",
      "Epoch 49/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - accuracy: 0.9659 - loss: 0.1065 \n",
      "Epoch 50/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - accuracy: 0.9851 - loss: 0.0487 \n",
      "Epoch 51/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 633us/step - accuracy: 0.9800 - loss: 0.0684 \n",
      "Epoch 52/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795us/step - accuracy: 0.9883 - loss: 0.0617 \n",
      "Epoch 53/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step - accuracy: 0.9849 - loss: 0.0573 \n",
      "Epoch 54/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - accuracy: 0.9717 - loss: 0.0644\n",
      "Epoch 55/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step - accuracy: 0.9861 - loss: 0.0478 \n",
      "Epoch 56/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - accuracy: 0.9824 - loss: 0.0743\n",
      "Epoch 57/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610us/step - accuracy: 0.9728 - loss: 0.0897\n",
      "Epoch 58/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - accuracy: 0.9690 - loss: 0.0805 \n",
      "Epoch 59/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - accuracy: 0.9914 - loss: 0.0374\n",
      "Epoch 60/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - accuracy: 0.9848 - loss: 0.0459 \n",
      "Epoch 61/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598us/step - accuracy: 0.9889 - loss: 0.0394\n",
      "Epoch 62/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - accuracy: 0.9768 - loss: 0.0677 \n",
      "Epoch 63/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592us/step - accuracy: 0.9816 - loss: 0.0582\n",
      "Epoch 64/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - accuracy: 0.9785 - loss: 0.0493\n",
      "Epoch 65/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - accuracy: 0.9908 - loss: 0.0514\n",
      "Epoch 66/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - accuracy: 0.9846 - loss: 0.0606\n",
      "Epoch 67/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569us/step - accuracy: 0.9813 - loss: 0.0682\n",
      "Epoch 68/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593us/step - accuracy: 0.9895 - loss: 0.0460 \n",
      "Epoch 69/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627us/step - accuracy: 0.9861 - loss: 0.0547 \n",
      "Epoch 70/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565us/step - accuracy: 0.9812 - loss: 0.0354 \n",
      "Epoch 71/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591us/step - accuracy: 0.9804 - loss: 0.0450\n",
      "Epoch 72/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605us/step - accuracy: 0.9874 - loss: 0.0354\n",
      "Epoch 73/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598us/step - accuracy: 0.9832 - loss: 0.0341\n",
      "Epoch 74/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step - accuracy: 0.9911 - loss: 0.0292\n",
      "Epoch 75/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - accuracy: 0.9912 - loss: 0.0278\n",
      "Epoch 76/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - accuracy: 0.9888 - loss: 0.0246 \n",
      "Epoch 77/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - accuracy: 0.9887 - loss: 0.0331\n",
      "Epoch 78/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - accuracy: 0.9825 - loss: 0.0521\n",
      "Epoch 79/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566us/step - accuracy: 0.9880 - loss: 0.0367\n",
      "Epoch 80/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - accuracy: 0.9922 - loss: 0.0308\n",
      "Epoch 81/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - accuracy: 0.9826 - loss: 0.0438 \n",
      "Epoch 82/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - accuracy: 0.9947 - loss: 0.0224\n",
      "Epoch 83/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 552us/step - accuracy: 0.9903 - loss: 0.0432 \n",
      "Epoch 84/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566us/step - accuracy: 0.9921 - loss: 0.0235\n",
      "Epoch 85/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - accuracy: 0.9803 - loss: 0.0543\n",
      "Epoch 86/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559us/step - accuracy: 0.9934 - loss: 0.0250\n",
      "Epoch 87/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - accuracy: 0.9916 - loss: 0.0212\n",
      "Epoch 88/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - accuracy: 0.9921 - loss: 0.0233 \n",
      "Epoch 89/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 552us/step - accuracy: 0.9890 - loss: 0.0513 \n",
      "Epoch 90/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576us/step - accuracy: 0.9867 - loss: 0.0391 \n",
      "Epoch 91/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - accuracy: 0.9890 - loss: 0.0282 \n",
      "Epoch 92/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - accuracy: 0.9932 - loss: 0.0196 \n",
      "Epoch 93/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574us/step - accuracy: 0.9850 - loss: 0.0410\n",
      "Epoch 94/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596us/step - accuracy: 0.9942 - loss: 0.0242\n",
      "Epoch 95/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593us/step - accuracy: 0.9914 - loss: 0.0303\n",
      "Epoch 96/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - accuracy: 0.9915 - loss: 0.0286\n",
      "Epoch 97/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - accuracy: 0.9908 - loss: 0.0362 \n",
      "Epoch 98/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607us/step - accuracy: 0.9778 - loss: 0.0512\n",
      "Epoch 99/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step - accuracy: 0.9921 - loss: 0.0211 \n",
      "Epoch 100/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604us/step - accuracy: 0.9901 - loss: 0.0255\n",
      "Epoch 101/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - accuracy: 0.9892 - loss: 0.0271 \n",
      "Epoch 102/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step - accuracy: 0.9941 - loss: 0.0226\n",
      "Epoch 103/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559us/step - accuracy: 0.9889 - loss: 0.0489 \n",
      "Epoch 104/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - accuracy: 0.9862 - loss: 0.0457\n",
      "Epoch 105/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577us/step - accuracy: 0.9962 - loss: 0.0165\n",
      "Epoch 106/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - accuracy: 0.9889 - loss: 0.0277 \n",
      "Epoch 107/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - accuracy: 0.9868 - loss: 0.0299\n",
      "Epoch 108/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571us/step - accuracy: 0.9851 - loss: 0.0329 \n",
      "Epoch 109/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606us/step - accuracy: 0.9805 - loss: 0.0666\n",
      "Epoch 110/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - accuracy: 0.9862 - loss: 0.0506\n",
      "Epoch 111/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - accuracy: 0.9903 - loss: 0.0165 \n",
      "Epoch 112/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - accuracy: 0.9945 - loss: 0.0230 \n",
      "Epoch 113/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579us/step - accuracy: 0.9939 - loss: 0.0284\n",
      "Epoch 114/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - accuracy: 0.9990 - loss: 0.0115\n",
      "Epoch 115/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566us/step - accuracy: 0.9932 - loss: 0.0292\n",
      "Epoch 116/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - accuracy: 0.9937 - loss: 0.0316\n",
      "Epoch 117/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step - accuracy: 0.9938 - loss: 0.0188 \n",
      "Epoch 118/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608us/step - accuracy: 0.9953 - loss: 0.0257 \n",
      "Epoch 119/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 635us/step - accuracy: 0.9958 - loss: 0.0177\n",
      "Epoch 120/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step - accuracy: 0.9947 - loss: 0.0231 \n",
      "Epoch 121/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615us/step - accuracy: 0.9934 - loss: 0.0142 \n",
      "Epoch 122/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - accuracy: 0.9898 - loss: 0.0305 \n",
      "Epoch 123/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 550us/step - accuracy: 0.9914 - loss: 0.0262 \n",
      "Epoch 124/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - accuracy: 0.9949 - loss: 0.0168\n",
      "Epoch 125/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step - accuracy: 0.9899 - loss: 0.0177\n",
      "Epoch 126/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - accuracy: 0.9894 - loss: 0.0245\n",
      "Epoch 127/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565us/step - accuracy: 0.9902 - loss: 0.0373\n",
      "Epoch 128/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - accuracy: 0.9948 - loss: 0.0166 \n",
      "Epoch 129/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577us/step - accuracy: 0.9846 - loss: 0.0283\n",
      "Epoch 130/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593us/step - accuracy: 0.9853 - loss: 0.0381 \n",
      "Epoch 131/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540us/step - accuracy: 0.9904 - loss: 0.0314 \n",
      "Epoch 132/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561us/step - accuracy: 0.9921 - loss: 0.0355 \n",
      "Epoch 133/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565us/step - accuracy: 0.9999 - loss: 0.0112 \n",
      "Epoch 134/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - accuracy: 0.9927 - loss: 0.0163 \n",
      "Epoch 135/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598us/step - accuracy: 0.9930 - loss: 0.0214 \n",
      "Epoch 136/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538us/step - accuracy: 0.9944 - loss: 0.0358 \n",
      "Epoch 137/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - accuracy: 0.9911 - loss: 0.0347\n",
      "Epoch 138/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608us/step - accuracy: 0.9906 - loss: 0.0243\n",
      "Epoch 139/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591us/step - accuracy: 0.9972 - loss: 0.0138 \n",
      "Epoch 140/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - accuracy: 0.9924 - loss: 0.0163 \n",
      "Epoch 141/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - accuracy: 0.9972 - loss: 0.0116 \n",
      "Epoch 142/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598us/step - accuracy: 0.9929 - loss: 0.0199 \n",
      "Epoch 143/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step - accuracy: 0.9971 - loss: 0.0118 \n",
      "Epoch 144/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - accuracy: 0.9953 - loss: 0.0136 \n",
      "Epoch 145/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step - accuracy: 0.9860 - loss: 0.0314 \n",
      "Epoch 146/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578us/step - accuracy: 0.9936 - loss: 0.0251 \n",
      "Epoch 147/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - accuracy: 0.9902 - loss: 0.0386\n",
      "Epoch 148/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 616us/step - accuracy: 0.9929 - loss: 0.0258\n",
      "Epoch 149/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step - accuracy: 0.9944 - loss: 0.0197\n",
      "Epoch 150/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - accuracy: 0.9943 - loss: 0.0242\n",
      "Epoch 151/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - accuracy: 0.9893 - loss: 0.0204\n",
      "Epoch 152/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.9908 - loss: 0.0245 \n",
      "Epoch 153/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step - accuracy: 0.9954 - loss: 0.0191 \n",
      "Epoch 154/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step - accuracy: 0.9987 - loss: 0.0094 \n",
      "Epoch 155/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624us/step - accuracy: 0.9901 - loss: 0.0314 \n",
      "Epoch 156/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - accuracy: 0.9897 - loss: 0.0235 \n",
      "Epoch 157/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607us/step - accuracy: 0.9963 - loss: 0.0105\n",
      "Epoch 158/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - accuracy: 0.9926 - loss: 0.0239 \n",
      "Epoch 159/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - accuracy: 0.9955 - loss: 0.0217\n",
      "Epoch 160/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - accuracy: 0.9920 - loss: 0.0116\n",
      "Epoch 161/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577us/step - accuracy: 0.9926 - loss: 0.0371\n",
      "Epoch 162/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608us/step - accuracy: 0.9953 - loss: 0.0168 \n",
      "Epoch 163/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - accuracy: 0.9957 - loss: 0.0096 \n",
      "Epoch 164/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - accuracy: 0.9985 - loss: 0.0146 \n",
      "Epoch 165/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step - accuracy: 0.9897 - loss: 0.0288\n",
      "Epoch 166/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591us/step - accuracy: 0.9955 - loss: 0.0238 \n",
      "Epoch 167/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622us/step - accuracy: 0.9999 - loss: 0.0130\n",
      "Epoch 168/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - accuracy: 0.9933 - loss: 0.0129 \n",
      "Epoch 169/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571us/step - accuracy: 0.9914 - loss: 0.0174\n",
      "Epoch 170/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - accuracy: 0.9988 - loss: 0.0054 \n",
      "Epoch 171/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565us/step - accuracy: 0.9949 - loss: 0.0162\n",
      "Epoch 172/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592us/step - accuracy: 0.9930 - loss: 0.0246 \n",
      "Epoch 173/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - accuracy: 0.9895 - loss: 0.0243\n",
      "Epoch 174/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596us/step - accuracy: 0.9984 - loss: 0.0103\n",
      "Epoch 175/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593us/step - accuracy: 0.9944 - loss: 0.0134 \n",
      "Epoch 176/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - accuracy: 0.9961 - loss: 0.0167\n",
      "Epoch 177/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543us/step - accuracy: 0.9845 - loss: 0.0483\n",
      "Epoch 178/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step - accuracy: 0.9878 - loss: 0.0477 \n",
      "Epoch 179/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - accuracy: 0.9889 - loss: 0.0326 \n",
      "Epoch 180/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step - accuracy: 0.9928 - loss: 0.0329\n",
      "Epoch 181/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576us/step - accuracy: 0.9946 - loss: 0.0165\n",
      "Epoch 182/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - accuracy: 0.9944 - loss: 0.0143 \n",
      "Epoch 183/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593us/step - accuracy: 0.9960 - loss: 0.0156 \n",
      "Epoch 184/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - accuracy: 0.9912 - loss: 0.0250\n",
      "Epoch 185/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566us/step - accuracy: 0.9933 - loss: 0.0134\n",
      "Epoch 186/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - accuracy: 0.9938 - loss: 0.0305\n",
      "Epoch 187/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - accuracy: 0.9821 - loss: 0.0367\n",
      "Epoch 188/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - accuracy: 0.9902 - loss: 0.0239 \n",
      "Epoch 189/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - accuracy: 0.9882 - loss: 0.0368 \n",
      "Epoch 190/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576us/step - accuracy: 0.9953 - loss: 0.0157 \n",
      "Epoch 191/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step - accuracy: 0.9916 - loss: 0.0367 \n",
      "Epoch 192/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579us/step - accuracy: 0.9919 - loss: 0.0299 \n",
      "Epoch 193/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - accuracy: 0.9885 - loss: 0.0280 \n",
      "Epoch 194/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554us/step - accuracy: 0.9902 - loss: 0.0410 \n",
      "Epoch 195/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - accuracy: 0.9936 - loss: 0.0199\n",
      "Epoch 196/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step - accuracy: 0.9919 - loss: 0.0391\n",
      "Epoch 197/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step - accuracy: 0.9970 - loss: 0.0133 \n",
      "Epoch 198/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 550us/step - accuracy: 0.9903 - loss: 0.0214 \n",
      "Epoch 199/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - accuracy: 0.9826 - loss: 0.0375 \n",
      "Epoch 200/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - accuracy: 0.9813 - loss: 0.0301\n",
      "found in bag: ``\n",
      "found in bag: may\n",
      "found in bag: i\n",
      "found in bag: hav\n",
      "found in bag: a\n",
      "found in bag: dctor\n",
      "found in bag: 's\n",
      "found in bag: consult\n",
      "found in bag: ,\n",
      "found in bag: pleas\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: search\n",
      "found in bag: pharmaceut\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: you\n",
      "found in bag: 're\n",
      "found in bag: a\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: ar\n",
      "found in bag: yo\n",
      "found in bag: area\n",
      "found in bag: of\n",
      "found in bag: expert\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: 'd\n",
      "found in bag: lik\n",
      "found in bag: to\n",
      "found in bag: request\n",
      "found in bag: a\n",
      "found in bag: prescrib\n",
      "found in bag: refil\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: can\n",
      "found in bag: i\n",
      "found in bag: pick\n",
      "found in bag: up\n",
      "found in bag: my\n",
      "found in bag: med\n",
      "found in bag: ord\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: coulnd\n",
      "found in bag: you\n",
      "found in bag: arrang\n",
      "found in bag: for\n",
      "found in bag: me\n",
      "found in bag: to\n",
      "found in bag: see\n",
      "found in bag: a\n",
      "found in bag: doct\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: that\n",
      "found in bag: mean\n",
      "found in bag: a\n",
      "found in bag: lot\n",
      "found in bag: to\n",
      "found in bag: me\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: hav\n",
      "found in bag: a\n",
      "found in bag: fev\n",
      "found in bag: and\n",
      "found in bag: shiv\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: see\n",
      "found in bag: you\n",
      "found in bag: oson\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: ar\n",
      "found in bag: yo\n",
      "found in bag: compet\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: is\n",
      "found in bag: my\n",
      "found in bag: cur\n",
      "found in bag: blood\n",
      "found in bag: preqss\n",
      "found in bag: read\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: skil\n",
      "found in bag: do\n",
      "found in bag: you\n",
      "found in bag: hav\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: exhibit\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: result\n",
      "found in bag: for\n",
      "found in bag: paty\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: may\n",
      "found in bag: i\n",
      "found in bag: schedule\n",
      "found in bag: a\n",
      "found in bag: consult\n",
      "found in bag: with\n",
      "found in bag: a\n",
      "found in bag: doct\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: could\n",
      "found in bag: you\n",
      "found in bag: outlin\n",
      "found in bag: the\n",
      "found in bag: pot\n",
      "found in bag: sid\n",
      "found in bag: effect\n",
      "found in bag: i\n",
      "found in bag: smight\n",
      "found in bag: encount\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: how\n",
      "found in bag: doe\n",
      "found in bag: my\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: comp\n",
      "found in bag: to\n",
      "found in bag: norm\n",
      "found in bag: level\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: 's\n",
      "found in bag: the\n",
      "found in bag: stat\n",
      "found in bag: of\n",
      "found in bag: my\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: today\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: is\n",
      "found in bag: anyon\n",
      "found in bag: ther\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: hav\n",
      "found in bag: a\n",
      "found in bag: runny\n",
      "found in bag: nos\n",
      "found in bag: and\n",
      "found in bag: congestio\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: you\n",
      "found in bag: can\n",
      "found in bag: do\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: adiso\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: thank\n",
      "found in bag: for\n",
      "found in bag: assist\n",
      "found in bag: me\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: find\n",
      "found in bag: hospit\n",
      "found in bag: with\n",
      "found in bag: covid-19\n",
      "found in bag: tre\n",
      "found in bag: facil\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: wo\n",
      "found in bag: you\n",
      "found in bag: detail\n",
      "found in bag: the\n",
      "found in bag: sid\n",
      "found in bag: effect\n",
      "found in bag: that\n",
      "found in bag: us\n",
      "found in bag: common\n",
      "found in bag: report\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: for\n",
      "found in bag: hospit\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: see\n",
      "found in bag: you\n",
      "found in bag: lat\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: is\n",
      "found in bag: it\n",
      "found in bag: poss\n",
      "found in bag: to\n",
      "found in bag: get\n",
      "found in bag: a\n",
      "found in bag: prescrib\n",
      "found in bag: fil\n",
      "found in bag: today\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: loc\n",
      "found in bag: a\n",
      "found in bag: pharm\n",
      "found in bag: that\n",
      "found in bag: cont\n",
      "found in bag: my\n",
      "found in bag: ins\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: could\n",
      "found in bag: you\n",
      "found in bag: check\n",
      "found in bag: my\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: ,\n",
      "found in bag: pleas\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: is\n",
      "found in bag: ther\n",
      "found in bag: a\n",
      "found in bag: doct\n",
      "found in bag: on\n",
      "found in bag: right\n",
      "found in bag: now\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: ar\n",
      "found in bag: ther\n",
      "found in bag: any\n",
      "found in bag: neg\n",
      "found in bag: consequ\n",
      "found in bag: i\n",
      "found in bag: should\n",
      "found in bag: watch\n",
      "found in bag: out\n",
      "found in bag: for\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: may\n",
      "found in bag: i\n",
      "found in bag: calend\n",
      "found in bag: a\n",
      "found in bag: consult\n",
      "found in bag: with\n",
      "found in bag: a\n",
      "found in bag: doct\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: that\n",
      "found in bag: 's\n",
      "found in bag: help\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: is\n",
      "found in bag: my\n",
      "found in bag: medicin\n",
      "found in bag: avail\n",
      "found in bag: for\n",
      "found in bag: pickup\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: see\n",
      "found in bag: you\n",
      "found in bag: lat\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: how\n",
      "found in bag: doe\n",
      "found in bag: my\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: comp\n",
      "found in bag: to\n",
      "found in bag: norm\n",
      "found in bag: level\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: nee\n",
      "found in bag: to\n",
      "found in bag: my\n",
      "found in bag: supply\n",
      "found in bag: of\n",
      "found in bag: med\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: whta\n",
      "found in bag: ar\n",
      "found in bag: yo\n",
      "found in bag: proficy\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: ar\n",
      "found in bag: my\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: giv\n",
      "found in bag: me\n",
      "found in bag: a\n",
      "found in bag: list\n",
      "found in bag: of\n",
      "found in bag: pharmaceut\n",
      "found in bag: caus\n",
      "found in bag: advers\n",
      "found in bag: behavy\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: pharm\n",
      "found in bag: arotnd\n",
      "found in bag: her\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: task\n",
      "found in bag: rel\n",
      "found in bag: to\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: how\n",
      "found in bag: to\n",
      "found in bag: check\n",
      "found in bag: advers\n",
      "found in bag: drug\n",
      "found in bag: react\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: hospit\n",
      "found in bag: clos\n",
      "found in bag: to\n",
      "found in bag: my\n",
      "found in bag: loc\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: loc\n",
      "found in bag: a\n",
      "found in bag: peharm\n",
      "found in bag: that\n",
      "found in bag: acceiv\n",
      "found in bag: my\n",
      "found in bag: ins\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: search\n",
      "found in bag: for\n",
      "found in bag: hospit\n",
      "found in bag: that\n",
      "found in bag: off\n",
      "found in bag: telemedicin\n",
      "found in bag: serv\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: can\n",
      "found in bag: you\n",
      "found in bag: tel\n",
      "found in bag: me\n",
      "found in bag: about\n",
      "found in bag: the\n",
      "found in bag: poss\n",
      "found in bag: sid\n",
      "found in bag: effdct\n",
      "found in bag: of\n",
      "found in bag: tak\n",
      "found in bag: thi\n",
      "found in bag: drug\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: hav\n",
      "found in bag: a\n",
      "found in bag: gre\n",
      "found in bag: dgay\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: gosod\n",
      "found in bag: day\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: hlelo\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: ar\n",
      "found in bag: the\n",
      "found in bag: risk\n",
      "found in bag: or\n",
      "found in bag: drawbac\n",
      "found in bag: of\n",
      "found in bag: thi\n",
      "found in bag: med\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: nicq\n",
      "found in bag: chat\n",
      "found in bag: to\n",
      "found in bag: you\n",
      "found in bag: ,\n",
      "found in bag: bye\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: couzld\n",
      "found in bag: you\n",
      "found in bag: dispens\n",
      "found in bag: my\n",
      "found in bag: med\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: could\n",
      "found in bag: you\n",
      "found in bag: detcail\n",
      "found in bag: the\n",
      "found in bag: sid\n",
      "found in bag: effect\n",
      "found in bag: that\n",
      "found in bag: us\n",
      "found in bag: common\n",
      "found in bag: report\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: hav\n",
      "found in bag: troubl\n",
      "found in bag: cont\n",
      "found in bag: or\n",
      "found in bag: clear\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: find\n",
      "found in bag: hospit\n",
      "found in bag: with\n",
      "found in bag: spezc\n",
      "found in bag: special\n",
      "found in bag: (\n",
      "found in bag: e.g.\n",
      "found in bag: ,\n",
      "found in bag: cardiolog\n",
      "found in bag: ,\n",
      "found in bag: pedy\n",
      "found in bag: )\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: whereof\n",
      "found in bag: can\n",
      "found in bag: you\n",
      "found in bag: bring\n",
      "found in bag: to\n",
      "found in bag: thi\n",
      "found in bag: project\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: is\n",
      "found in bag: ther\n",
      "found in bag: a\n",
      "found in bag: dokt\n",
      "found in bag: avail\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: kisnd\n",
      "found in bag: of\n",
      "found in bag: neg\n",
      "found in bag: react\n",
      "found in bag: should\n",
      "found in bag: i\n",
      "found in bag: be\n",
      "found in bag: prep\n",
      "found in bag: for\n",
      "found in bag: with\n",
      "found in bag: thi\n",
      "found in bag: drug\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: can\n",
      "found in bag: you\n",
      "found in bag: bring\n",
      "found in bag: to\n",
      "found in bag: thi\n",
      "found in bag: project\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: 'm\n",
      "found in bag: feel\n",
      "found in bag: unus\n",
      "found in bag: ciold\n",
      "found in bag: or\n",
      "found in bag: hot\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: how\n",
      "found in bag: doe\n",
      "found in bag: my\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: comp\n",
      "found in bag: to\n",
      "found in bag: norm\n",
      "found in bag: levesl\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: ar\n",
      "found in bag: ther\n",
      "found in bag: any\n",
      "found in bag: concern\n",
      "found in bag: with\n",
      "found in bag: my\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: read\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: can\n",
      "found in bag: you\n",
      "found in bag: do\n",
      "found in bag: wel\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: loc\n",
      "found in bag: pharmahcy\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: loc\n",
      "found in bag: a\n",
      "found in bag: nearby\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: is\n",
      "found in bag: my\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: within\n",
      "found in bag: a\n",
      "found in bag: healthy\n",
      "found in bag: rang\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: yo\n",
      "found in bag: hav\n",
      "found in bag: my\n",
      "found in bag: gratitud\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: how\n",
      "found in bag: ar\n",
      "found in bag: you\n",
      "found in bag: doing\n",
      "found in bag: today\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: ar\n",
      "found in bag: ther\n",
      "found in bag: any\n",
      "found in bag: concern\n",
      "found in bag: with\n",
      "found in bag: my\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: readihg\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: can\n",
      "found in bag: you\n",
      "found in bag: contribut\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: wher\n",
      "found in bag: can\n",
      "found in bag: i\n",
      "found in bag: find\n",
      "found in bag: a\n",
      "found in bag: hospit\n",
      "found in bag: emerg\n",
      "found in bag: room\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: hav\n",
      "found in bag: a\n",
      "found in bag: yfev\n",
      "found in bag: and\n",
      "found in bag: chil\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: which\n",
      "found in bag: drug\n",
      "found in bag: doct\n",
      "found in bag: hav\n",
      "found in bag: advers\n",
      "found in bag: react\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: how\n",
      "found in bag: to\n",
      "found in bag: chek\n",
      "found in bag: advers\n",
      "found in bag: drug\n",
      "found in bag: react\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: mod\n",
      "found in bag: ar\n",
      "found in bag: you\n",
      "found in bag: doing\n",
      "found in bag: today\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: coulk\n",
      "found in bag: you\n",
      "found in bag: get\n",
      "found in bag: my\n",
      "found in bag: prescrib\n",
      "found in bag: ready\n",
      "found in bag: for\n",
      "found in bag: me\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: hav\n",
      "found in bag: you\n",
      "found in bag: check\n",
      "found in bag: my\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: rec\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: nee\n",
      "found in bag: the\n",
      "found in bag: at\n",
      "found in bag: of\n",
      "found in bag: a\n",
      "found in bag: doct\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: hav\n",
      "found in bag: a\n",
      "found in bag: good\n",
      "found in bag: on\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: ar\n",
      "found in bag: you\n",
      "found in bag: doing\n",
      "found in bag: today\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: ar\n",
      "found in bag: yo\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: hav\n",
      "found in bag: musc\n",
      "found in bag: ach\n",
      "found in bag: and\n",
      "found in bag: pain\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: see\n",
      "found in bag: ya\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: thvnks\n",
      "found in bag: a\n",
      "found in bag: bunch\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: bonjo\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: good\n",
      "found in bag: day\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: could\n",
      "found in bag: you\n",
      "found in bag: inform\n",
      "found in bag: me\n",
      "found in bag: of\n",
      "found in bag: my\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: result\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: ar\n",
      "found in bag: yo\n",
      "found in bag: profess\n",
      "found in bag: skil\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: ciao\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: waht\n",
      "found in bag: skil\n",
      "found in bag: do\n",
      "found in bag: you\n",
      "found in bag: bring\n",
      "found in bag: to\n",
      "found in bag: the\n",
      "found in bag: tabl\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: salut\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: ar\n",
      "found in bag: yo\n",
      "found in bag: compet\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: how\n",
      "found in bag: is\n",
      "found in bag: my\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: look\n",
      "found in bag: today\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: 'm\n",
      "found in bag: cough\n",
      "found in bag: and\n",
      "found in bag: whez\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: sce\n",
      "found in bag: you\n",
      "found in bag: lat\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: nic\n",
      "found in bag: chat\n",
      "found in bag: to\n",
      "found in bag: you\n",
      "found in bag: ,\n",
      "found in bag: bye\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: loc\n",
      "found in bag: a\n",
      "found in bag: pharm\n",
      "found in bag: nearby\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: wha\n",
      "found in bag: support\n",
      "found in bag: is\n",
      "found in bag: off\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: hav\n",
      "found in bag: digest\n",
      "found in bag: issu\n",
      "found in bag: such\n",
      "found in bag: as\n",
      "found in bag: blota\n",
      "found in bag: or\n",
      "found in bag: indigest\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: feel\n",
      "found in bag: jad\n",
      "found in bag: and\n",
      "found in bag: weak\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: ar\n",
      "found in bag: ther\n",
      "found in bag: any\n",
      "found in bag: doct\n",
      "found in bag: in\n",
      "found in bag: the\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: 'm\n",
      "found in bag: her\n",
      "found in bag: to\n",
      "found in bag: collect\n",
      "found in bag: my\n",
      "found in bag: prescrib\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: could\n",
      "found in bag: you\n",
      "found in bag: lgst\n",
      "found in bag: the\n",
      "found in bag: pot\n",
      "found in bag: drawback\n",
      "found in bag: or\n",
      "found in bag: downsid\n",
      "found in bag: of\n",
      "found in bag: us\n",
      "found in bag: thi\n",
      "found in bag: drug\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: you\n",
      "found in bag: hav\n",
      "found in bag: my\n",
      "found in bag: gratitud\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: so\n",
      "found in bag: long\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: 'm\n",
      "found in bag: very\n",
      "found in bag: grat\n",
      "found in bag: for\n",
      "found in bag: yo\n",
      "found in bag: help\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: giv\n",
      "found in bag: me\n",
      "found in bag: a\n",
      "found in bag: list\n",
      "found in bag: of\n",
      "found in bag: drug\n",
      "found in bag: caus\n",
      "found in bag: advers\n",
      "found in bag: bheavy\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: can\n",
      "found in bag: you\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: may\n",
      "found in bag: i\n",
      "found in bag: hav\n",
      "found in bag: a\n",
      "found in bag: doct\n",
      "found in bag: 's\n",
      "found in bag: consult\n",
      "found in bag: ,\n",
      "found in bag: pleas\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: ar\n",
      "found in bag: ther\n",
      "found in bag: any\n",
      "found in bag: advers\n",
      "found in bag: effect\n",
      "found in bag: i\n",
      "found in bag: should\n",
      "found in bag: be\n",
      "found in bag: aw\n",
      "found in bag: of\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: could\n",
      "found in bag: you\n",
      "found in bag: let\n",
      "found in bag: me\n",
      "found in bag: know\n",
      "found in bag: my\n",
      "found in bag: cur\n",
      "found in bag: bp\n",
      "found in bag: num\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: nee\n",
      "found in bag: to\n",
      "found in bag: pickk\n",
      "found in bag: up\n",
      "found in bag: my\n",
      "found in bag: med\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: quo\n",
      "found in bag: ar\n",
      "found in bag: yo\n",
      "found in bag: tal\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: until\n",
      "found in bag: next\n",
      "found in bag: tim\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: how\n",
      "found in bag: you\n",
      "found in bag: can\n",
      "found in bag: be\n",
      "found in bag: act\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: has\n",
      "found in bag: a\n",
      "found in bag: good\n",
      "found in bag: on\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: wheru\n",
      "found in bag: can\n",
      "found in bag: i\n",
      "found in bag: find\n",
      "found in bag: a\n",
      "found in bag: hospit\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: hiy\n",
      "found in bag: ther\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: 'm\n",
      "found in bag: look\n",
      "found in bag: to\n",
      "found in bag: see\n",
      "found in bag: a\n",
      "found in bag: healthc\n",
      "found in bag: profess\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: loc\n",
      "found in bag: a\n",
      "found in bag: hospit\n",
      "found in bag: nearby\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: whaot\n",
      "found in bag: can\n",
      "found in bag: you\n",
      "found in bag: do\n",
      "found in bag: wel\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: nearby\n",
      "found in bag: drugst\n",
      "found in bag: op\n",
      "found in bag: now\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: support\n",
      "found in bag: is\n",
      "found in bag: off\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: ar\n",
      "found in bag: the\n",
      "found in bag: chant\n",
      "found in bag: of\n",
      "found in bag: expery\n",
      "found in bag: sid\n",
      "found in bag: effect\n",
      "found in bag: with\n",
      "found in bag: thi\n",
      "found in bag: drug\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: much\n",
      "found in bag: oblig\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: would\n",
      "found in bag: lik\n",
      "found in bag: to\n",
      "found in bag: request\n",
      "found in bag: a\n",
      "found in bag: doct\n",
      "found in bag: 's\n",
      "found in bag: appoint\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: search\n",
      "found in bag: for\n",
      "found in bag: med\n",
      "found in bag: cent\n",
      "found in bag: nearby\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: nee\n",
      "found in bag: to\n",
      "found in bag: consult\n",
      "found in bag: with\n",
      "found in bag: a\n",
      "found in bag: mer\n",
      "found in bag: doct\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: tak\n",
      "found in bag: it\n",
      "found in bag: simpl\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: feel\n",
      "found in bag: extrem\n",
      "found in bag: tir\n",
      "found in bag: and\n",
      "found in bag: lethmarg\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: hav\n",
      "found in bag: a\n",
      "found in bag: runny\n",
      "found in bag: nos\n",
      "found in bag: and\n",
      "found in bag: crowd\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: is\n",
      "found in bag: ther\n",
      "found in bag: a\n",
      "found in bag: chant\n",
      "found in bag: of\n",
      "found in bag: expery\n",
      "found in bag: any\n",
      "found in bag: unwante\n",
      "found in bag: effect\n",
      "found in bag: with\n",
      "found in bag: thi\n",
      "found in bag: med\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: for\n",
      "found in bag: pharm\n",
      "found in bag: that\n",
      "found in bag: del\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: find\n",
      "found in bag: pharm\n",
      "found in bag: with\n",
      "found in bag: drive-thru\n",
      "found in bag: serv\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: adio\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: ar\n",
      "found in bag: ther\n",
      "found in bag: any\n",
      "found in bag: known\n",
      "found in bag: sid\n",
      "found in bag: effect\n",
      "found in bag: i\n",
      "found in bag: should\n",
      "found in bag: be\n",
      "found in bag: concern\n",
      "found in bag: about\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: loc\n",
      "found in bag: a\n",
      "found in bag: pharm\n",
      "found in bag: that\n",
      "found in bag: acceiv\n",
      "found in bag: my\n",
      "found in bag: ins\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: for\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: wher\n",
      "found in bag: can\n",
      "found in bag: i\n",
      "found in bag: buy\n",
      "found in bag: over-the-count\n",
      "found in bag: med\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: could\n",
      "found in bag: you\n",
      "found in bag: outlin\n",
      "found in bag: the\n",
      "found in bag: pot\n",
      "found in bag: sid\n",
      "found in bag: impact\n",
      "found in bag: i\n",
      "found in bag: might\n",
      "found in bag: encount\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: ar\n",
      "found in bag: ther\n",
      "found in bag: any\n",
      "found in bag: common\n",
      "found in bag: sik\n",
      "found in bag: effect\n",
      "found in bag: assocy\n",
      "found in bag: with\n",
      "found in bag: thi\n",
      "found in bag: tre\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: list\n",
      "found in bag: al\n",
      "found in bag: drug\n",
      "found in bag: suit\n",
      "found in bag: for\n",
      "found in bag: pqtient\n",
      "found in bag: with\n",
      "found in bag: advers\n",
      "found in bag: react\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: could\n",
      "found in bag: you\n",
      "found in bag: get\n",
      "found in bag: my\n",
      "found in bag: prescrib\n",
      "found in bag: ready\n",
      "found in bag: for\n",
      "found in bag: me\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: goodnight\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: nee\n",
      "found in bag: med\n",
      "found in bag: assist\n",
      "found in bag: from\n",
      "found in bag: a\n",
      "found in bag: doct\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: wher\n",
      "found in bag: can\n",
      "found in bag: i\n",
      "found in bag: find\n",
      "found in bag: a\n",
      "found in bag: hospit\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: can\n",
      "found in bag: i\n",
      "found in bag: pick\n",
      "found in bag: up\n",
      "found in bag: my\n",
      "found in bag: med\n",
      "found in bag: edict\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: whereof\n",
      "found in bag: ar\n",
      "found in bag: yo\n",
      "found in bag: strengths\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: many\n",
      "found in bag: thanv\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: ar\n",
      "found in bag: ther\n",
      "found in bag: any\n",
      "found in bag: doct\n",
      "found in bag: in\n",
      "found in bag: the\n",
      "found in bag: clinfc/hospital\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: find\n",
      "found in bag: hospit\n",
      "found in bag: with\n",
      "found in bag: covid-19\n",
      "found in bag: tre\n",
      "found in bag: facil\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: can\n",
      "found in bag: you\n",
      "found in bag: prep\n",
      "found in bag: my\n",
      "found in bag: prescrib\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: could\n",
      "found in bag: you\n",
      "found in bag: fil\n",
      "found in bag: my\n",
      "found in bag: prescrib\n",
      "found in bag: for\n",
      "found in bag: me\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: list\n",
      "found in bag: of\n",
      "found in bag: pharm\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: search\n",
      "found in bag: for\n",
      "found in bag: drugstorf\n",
      "found in bag: nearby\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "636 documents\n",
      "12 intents ['adverse_drug', 'blood_pressure', 'blood_pressure_search', 'doctor', 'goodbye', 'greeting', 'hospital_search', 'medication', 'options', 'pharmacy_search', 'symptoms', 'thanks']\n",
      "665 unique stemmed words ['!', \"'\", \"''\", \"'d\", \"'im\", \"'m\", \"'re\", \"'s\", \"'ve\", '(', ')', ',', '.', '24-hour', '24/7', '[', ']', '``', 'a', 'abdoin', 'abdomin', 'abl', 'about', 'acceiv', 'ach', 'achiev', 'acknowledg', 'acquisit', 'act', 'adio', 'adiso', 'admin', 'advers', 'advesr', 'aft', 'afternoon', 'afteroon', 'ahoy', 'aid', 'al', 'almost', 'alright', 'an', 'and', 'answ', 'anticip', 'any', 'anyon', 'appoint', 'apprecy', 'ar', 'area', 'arotnd', 'around', 'arrang', 'as', 'ask', 'assist', 'assocy', 'aston', 'at', 'attenty', 'avail', 'aw', 'awesom', 'batch', 'be', 'been', 'behavy', 'behold', 'bel', 'bheavy', 'blat', 'blo', 'blocd', 'blohod', 'blood', 'blota', 'bolod', 'bonjo', 'bood', 'book', 'bound', 'bp', 'brea', 'bring', 'brows', 'buen', 'bunch', 'buy', 'by', 'bye', 'bye-bxy', 'bye-by', 'ca', \"caa't\", 'cal', 'calend', 'can', 'cap', 'car', 'cardiolog', 'catch', 'caus', 'cent', 'chant', 'chat', 'checekd', 'check', 'cheerio', 'chek', 'chest', 'chil', 'chos', 'chrissakes', 'ciao', 'ciold', 'city/municipal', 'city/town', 'cjan', 'clear', 'clinfc/hospital', 'clinic/hospital', 'clinically/hospital', 'clos', 'closest', 'cold', 'collect', 'common', 'comp', 'compet', 'comply', 'concern', 'congest', 'congestio', 'consequ', 'consult', 'cont', 'contribu', 'contribut', 'cough', 'could', 'coulk', 'coulnd', 'couzld', 'covid-19', 'covid-k19', 'cpressure', 'cramp', 'crowd', 'cur', 'cvar', 'dat', 'day', 'dctor', 'dee', 'deeplry', 'del', 'delight', 'describ', 'detail', 'detcail', 'detil', 'dext', 'dgay', 'diarrhe', 'diarrhoe', 'digest', 'direct', 'discomfort', 'dispens', 'dlat', 'do', 'doct', 'doctro', 'doe', 'doing', 'dokt', 'dont', 'downsid', 'drawbac', 'drawback', 'drive-thru', 'drug', 'drugst', 'drugstorf', 'e.g.', 'easy', 'ebrea', 'eczem', 'edict', 'efel', 'effdct', 'effect', 'emerg', 'encount', 'enough', 'entry', 'epharm', 'epxery', 'esult', 'etrength', 'ev', 'everyon', 'excel', 'exery', 'exhibit', 'expect', 'expert', 'experty', 'expery', 'explain', 'extrem', 'fac', 'facil', 'farewel', 'farewelql', 'fatigu', 'feel', 'fefect', 'fev', 'fil', 'find', 'finsd', 'finyd', 'flu', 'for', 'found', 'frisk', 'from', 'fulfil', 'furn', 'gap', 'geet', 'gest', 'get', 'giv', 'gogd', 'going', 'gonig', 'good', 'goodby', 'goodbyt', 'goodnighl', 'goodnight', 'gookby', 'gosod', 'got', 'grat', 'gratitud', 'gre', 'greet', 'gye', 'h', 'handy', 'has', 'hav', 'headach', 'heal', 'healo', 'health', 'healthc', 'healthy', 'heartburn', 'heh', 'hel', 'hello', 'help', 'hepy', 'her', 'hey', 'hi', 'himy', 'hist', 'hiy', 'hlelo', 'hopsit', 'hosp', 'hospiot', 'hospit', 'hospitasl', 'hot', 'how', 'howdy', 'hoxw', 'hoy', 'hspital', 'hwat', 'hwody', 'hyi', 'hyw', 'i', \"i'n\", 'icu', 'id', 'im', 'impact', 'in', 'inauspicy', 'incred', 'indigest', 'influ', 'inform', 'ins', 'intend', 'irrit', 'is', 'issu', 'it', 'jad', 'jash', 'joint', 'kidn', 'kind', 'kisnd', 'know', 'known', 'kwhat', 'larynx', 'lat', 'lateb', 'latest', 'lco', 'leav', 'let', 'letharg', 'lethmarg', 'level', 'levesl', 'lgst', 'liabl', 'lifesav', 'lifeskv', 'light/noise', 'lighthead', 'lik', 'lind', 'list', 'load', 'loc', 'loch', 'locta', 'log', 'long', 'loo', 'look', 'lookup', 'lookut', 'lot', 'magn', 'mak', 'malay', 'man', 'many', 'may', 'me', 'meac', 'mean', 'meas', 'med', 'medicatifon', 'medicaton', 'medicin', 'medicinq', 'meet', 'mer', 'met', 'mfy', 'might', 'migt', 'mil', 'mod', 'morn', 'mtabl', 'mte', 'much', 'musc', 'must', 'my', \"n't\", 'narby', 'nause', 'near', 'nearby', 'nearest', 'nee', 'neg', 'neharby', 'neighb', 'neighbo', 'new', 'newest', 'next', 'nic', 'nicq', 'nneg', 'nnxt', 'noe', 'noee', 'nomin', 'norm', 'nos', 'now', 'noxy', 'num', 'numb', 'oblgy', 'oblig', 'occ', 'occup', 'od', 'of', 'off', 'ogod', 'okp', 'on', 'op', 'opn', 'oprescrib', 'or', 'ord', 'oson', 'ot', 'out', 'outcom', 'outlin', 'over-the-count', 'overal', 'ow', 'pain', 'pat', 'paty', 'peac', 'pedy', 'peharm', 'persist', 'persistnet', 'pfrescription', 'pharm', 'pharmaceut', 'pharmacio', 'pharmahcy', 'phospit', 'phramacies', 'phrmacy', 'phys', 'physc', 'pick', 'pickk', 'pickup', 'pinpoint', 'pkckup', 'pleas', 'poharm', 'point', 'porject', 'poss', 'possbl', 'pot', 'ppharmacies', 'pqtient', 'prep', 'preqss', 'prescrib', 'prescrip', 'prescripg', 'presrib', 'press', 'profess', 'proficy', 'project', 'provid', 'ps', 'pyleas', 'quick', 'quo', 'rang', 'rash', 'react', 'read', 'readihg', 'ready', 'real', 'rearrang', 'reat', 'rec', 'refil', 'reflil', 'reg', 'reil', 'rel', 'reord', 'repercuss', 'report', 'reqeust', 'request', 'requir', 'research', 'result', 'rev', 'right', 'risk', 'rnge', 'room', 'rpescrib', 'rpovid', 'rul', 'runny', 'salut', 'salutatoin', 'savio', 'say', 'sbe', 'sce', 'schedule', 'scratchy', 'se', 'seach', 'search', 'searhc', 'see', 'seg', 'seh', 'sens', 'sensipt', 'sensit', 'serv', 'shiv', 'short', 'shot', 'should', 'show', 'sid', 'sik', 'simpl', 'skil', 'skils', 'skin', 'smight', 'so', 'soon', 'sor', 'spe', 'speak', 'spec', 'special', 'spezc', 'sress', 'stabl', 'stat', 'strengths', 'strong', 'such', 'suit', 'supply', 'support', 'surgery', 'surround', 'swol', 'systolic/diastol', 'ta', 'tabl', 'tableau', 'tak', 'tal', 'task', 'tech', 'techn', 'technicd', 'tel', 'telemedicin', 'term', \"tha'ts\", 'than', 'thank', 'thansk', 'thanv', 'that', 'the', 'ther', 'thi', 'think', 'thinmk', 'thnk', 'thvnks', 'tier', 'tight', 'tighvt', 'til', 'tim', 'tir', 'to', 'today', 'told', 'trail', 'tranquil', 'transf', 'transfus', 'tre', 'troubl', 'uh', 'undesir', 'unear', 'unfav', 'unfavo', 'unintend', 'unit', 'until', 'unus', 'unw', 'unwante', 'up', 'upd', 'uregnt', 'urg', 'us', 'usng', 'util', 'vaccin', 'vaccy', 'vay', 'ver', 'verdict', 'vertigo', 'very', 'vomit', 'waht', 'want', 'wat', 'watch', 'weak', 'wel', 'welcom', 'wha', 'whac', 'whaot', 'whar', 'what', 'whaut', 'wheez', 'wher', 'whereby', 'whereof', 'wheru', 'whez', 'whgt', 'which', 'whil', 'whmt', 'whnt', 'whta', 'wit', 'with', 'within', 'wlecom', 'wo', 'wond', 'would', 'wthat', 'xthanks', 'ya', 'yao', 'yfev', 'yo', 'you']\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mist861/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n",
      "/home/mist861/anaconda3/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py:33: UserWarning:\n",
      "\n",
      "Argument `decay` is no longer supported and will be ignored.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1277 - loss: 2.4044   \n",
      "Epoch 2/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - accuracy: 0.4790 - loss: 1.5722\n",
      "Epoch 3/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598us/step - accuracy: 0.6368 - loss: 1.0615\n",
      "Epoch 4/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579us/step - accuracy: 0.7239 - loss: 0.7950\n",
      "Epoch 5/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742us/step - accuracy: 0.7796 - loss: 0.6232\n",
      "Epoch 6/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step - accuracy: 0.7980 - loss: 0.4849\n",
      "Epoch 7/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621us/step - accuracy: 0.8553 - loss: 0.4493\n",
      "Epoch 8/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591us/step - accuracy: 0.8392 - loss: 0.3751\n",
      "Epoch 9/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - accuracy: 0.8926 - loss: 0.3063\n",
      "Epoch 10/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - accuracy: 0.8647 - loss: 0.3584\n",
      "Epoch 11/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609us/step - accuracy: 0.9007 - loss: 0.2859\n",
      "Epoch 12/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - accuracy: 0.9301 - loss: 0.2207\n",
      "Epoch 13/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622us/step - accuracy: 0.9280 - loss: 0.2113\n",
      "Epoch 14/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592us/step - accuracy: 0.9228 - loss: 0.2101\n",
      "Epoch 15/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step - accuracy: 0.9352 - loss: 0.2175\n",
      "Epoch 16/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609us/step - accuracy: 0.9477 - loss: 0.1609\n",
      "Epoch 17/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step - accuracy: 0.9525 - loss: 0.1500\n",
      "Epoch 18/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 613us/step - accuracy: 0.9513 - loss: 0.1336\n",
      "Epoch 19/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - accuracy: 0.9336 - loss: 0.1462\n",
      "Epoch 20/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - accuracy: 0.9505 - loss: 0.1407\n",
      "Epoch 21/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - accuracy: 0.9708 - loss: 0.0943 \n",
      "Epoch 22/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - accuracy: 0.9675 - loss: 0.1147\n",
      "Epoch 23/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 616us/step - accuracy: 0.9631 - loss: 0.1023\n",
      "Epoch 24/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - accuracy: 0.9776 - loss: 0.0990\n",
      "Epoch 25/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - accuracy: 0.9792 - loss: 0.0959\n",
      "Epoch 26/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step - accuracy: 0.9543 - loss: 0.1273\n",
      "Epoch 27/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596us/step - accuracy: 0.9720 - loss: 0.0719\n",
      "Epoch 28/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - accuracy: 0.9646 - loss: 0.1071 \n",
      "Epoch 29/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - accuracy: 0.9698 - loss: 0.1074\n",
      "Epoch 30/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step - accuracy: 0.9539 - loss: 0.1452\n",
      "Epoch 31/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - accuracy: 0.9871 - loss: 0.0528\n",
      "Epoch 32/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579us/step - accuracy: 0.9537 - loss: 0.0977\n",
      "Epoch 33/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - accuracy: 0.9800 - loss: 0.0739\n",
      "Epoch 34/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - accuracy: 0.9681 - loss: 0.0900\n",
      "Epoch 35/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578us/step - accuracy: 0.9652 - loss: 0.0890\n",
      "Epoch 36/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - accuracy: 0.9756 - loss: 0.0709\n",
      "Epoch 37/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step - accuracy: 0.9840 - loss: 0.0517\n",
      "Epoch 38/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594us/step - accuracy: 0.9932 - loss: 0.0307\n",
      "Epoch 39/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - accuracy: 0.9926 - loss: 0.0358\n",
      "Epoch 40/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - accuracy: 0.9790 - loss: 0.0692\n",
      "Epoch 41/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579us/step - accuracy: 0.9768 - loss: 0.0847 \n",
      "Epoch 42/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - accuracy: 0.9819 - loss: 0.0430\n",
      "Epoch 43/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - accuracy: 0.9685 - loss: 0.0872 \n",
      "Epoch 44/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - accuracy: 0.9928 - loss: 0.0348\n",
      "Epoch 45/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step - accuracy: 0.9851 - loss: 0.0434\n",
      "Epoch 46/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579us/step - accuracy: 0.9890 - loss: 0.0394 \n",
      "Epoch 47/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558us/step - accuracy: 0.9867 - loss: 0.0354\n",
      "Epoch 48/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - accuracy: 0.9745 - loss: 0.0522\n",
      "Epoch 49/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - accuracy: 0.9846 - loss: 0.0496\n",
      "Epoch 50/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - accuracy: 0.9866 - loss: 0.0376\n",
      "Epoch 51/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - accuracy: 0.9771 - loss: 0.0614\n",
      "Epoch 52/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - accuracy: 0.9880 - loss: 0.0625 \n",
      "Epoch 53/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - accuracy: 0.9903 - loss: 0.0376\n",
      "Epoch 54/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - accuracy: 0.9774 - loss: 0.0505 \n",
      "Epoch 55/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561us/step - accuracy: 0.9719 - loss: 0.1073\n",
      "Epoch 56/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566us/step - accuracy: 0.9812 - loss: 0.0608\n",
      "Epoch 57/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step - accuracy: 0.9980 - loss: 0.0245\n",
      "Epoch 58/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step - accuracy: 0.9941 - loss: 0.0298\n",
      "Epoch 59/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - accuracy: 0.9874 - loss: 0.0493 \n",
      "Epoch 60/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - accuracy: 0.9862 - loss: 0.0450\n",
      "Epoch 61/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step - accuracy: 0.9901 - loss: 0.0326\n",
      "Epoch 62/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 549us/step - accuracy: 0.9923 - loss: 0.0331\n",
      "Epoch 63/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554us/step - accuracy: 0.9905 - loss: 0.0333\n",
      "Epoch 64/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559us/step - accuracy: 0.9946 - loss: 0.0183\n",
      "Epoch 65/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569us/step - accuracy: 0.9904 - loss: 0.0403 \n",
      "Epoch 66/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - accuracy: 0.9748 - loss: 0.0817\n",
      "Epoch 67/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step - accuracy: 0.9829 - loss: 0.0411\n",
      "Epoch 68/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step - accuracy: 0.9953 - loss: 0.0302\n",
      "Epoch 69/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565us/step - accuracy: 0.9907 - loss: 0.0349 \n",
      "Epoch 70/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606us/step - accuracy: 0.9814 - loss: 0.0473 \n",
      "Epoch 71/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step - accuracy: 0.9891 - loss: 0.0408\n",
      "Epoch 72/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - accuracy: 0.9859 - loss: 0.0604\n",
      "Epoch 73/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - accuracy: 0.9803 - loss: 0.0465\n",
      "Epoch 74/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - accuracy: 0.9820 - loss: 0.0528\n",
      "Epoch 75/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step - accuracy: 0.9913 - loss: 0.0392\n",
      "Epoch 76/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 613us/step - accuracy: 0.9897 - loss: 0.0282\n",
      "Epoch 77/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step - accuracy: 0.9911 - loss: 0.0191 \n",
      "Epoch 78/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559us/step - accuracy: 0.9917 - loss: 0.0212\n",
      "Epoch 79/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576us/step - accuracy: 0.9849 - loss: 0.0379 \n",
      "Epoch 80/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - accuracy: 0.9940 - loss: 0.0214 \n",
      "Epoch 81/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554us/step - accuracy: 0.9955 - loss: 0.0127 \n",
      "Epoch 82/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548us/step - accuracy: 0.9907 - loss: 0.0245\n",
      "Epoch 83/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - accuracy: 0.9835 - loss: 0.0469\n",
      "Epoch 84/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step - accuracy: 0.9905 - loss: 0.0355\n",
      "Epoch 85/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548us/step - accuracy: 0.9861 - loss: 0.0516\n",
      "Epoch 86/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 616us/step - accuracy: 0.9921 - loss: 0.0249\n",
      "Epoch 87/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 550us/step - accuracy: 0.9926 - loss: 0.0222 \n",
      "Epoch 88/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - accuracy: 0.9953 - loss: 0.0173 \n",
      "Epoch 89/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - accuracy: 0.9943 - loss: 0.0188\n",
      "Epoch 90/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - accuracy: 0.9859 - loss: 0.0602\n",
      "Epoch 91/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615us/step - accuracy: 0.9752 - loss: 0.0501\n",
      "Epoch 92/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - accuracy: 0.9943 - loss: 0.0236\n",
      "Epoch 93/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578us/step - accuracy: 0.9926 - loss: 0.0331\n",
      "Epoch 94/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569us/step - accuracy: 0.9920 - loss: 0.0208 \n",
      "Epoch 95/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598us/step - accuracy: 0.9955 - loss: 0.0130 \n",
      "Epoch 96/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - accuracy: 0.9868 - loss: 0.0221\n",
      "Epoch 97/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608us/step - accuracy: 0.9981 - loss: 0.0131 \n",
      "Epoch 98/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604us/step - accuracy: 0.9934 - loss: 0.0132 \n",
      "Epoch 99/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - accuracy: 0.9969 - loss: 0.0166 \n",
      "Epoch 100/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - accuracy: 0.9925 - loss: 0.0203 \n",
      "Epoch 101/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755us/step - accuracy: 0.9998 - loss: 0.0066 \n",
      "Epoch 102/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - accuracy: 0.9985 - loss: 0.0073 \n",
      "Epoch 103/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - accuracy: 0.9840 - loss: 0.0249\n",
      "Epoch 104/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607us/step - accuracy: 0.9953 - loss: 0.0169\n",
      "Epoch 105/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 616us/step - accuracy: 0.9934 - loss: 0.0109\n",
      "Epoch 106/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - accuracy: 0.9968 - loss: 0.0123 \n",
      "Epoch 107/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598us/step - accuracy: 0.9933 - loss: 0.0240\n",
      "Epoch 108/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598us/step - accuracy: 0.9947 - loss: 0.0156 \n",
      "Epoch 109/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - accuracy: 0.9967 - loss: 0.0262\n",
      "Epoch 110/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step - accuracy: 0.9829 - loss: 0.0414 \n",
      "Epoch 111/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608us/step - accuracy: 0.9941 - loss: 0.0210 \n",
      "Epoch 112/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610us/step - accuracy: 0.9913 - loss: 0.0259\n",
      "Epoch 113/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step - accuracy: 0.9941 - loss: 0.0130\n",
      "Epoch 114/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - accuracy: 0.9916 - loss: 0.0298\n",
      "Epoch 115/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571us/step - accuracy: 0.9973 - loss: 0.0156 \n",
      "Epoch 116/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565us/step - accuracy: 0.9838 - loss: 0.0584\n",
      "Epoch 117/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step - accuracy: 0.9818 - loss: 0.0476\n",
      "Epoch 118/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step - accuracy: 0.9859 - loss: 0.0562\n",
      "Epoch 119/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - accuracy: 0.9831 - loss: 0.0343\n",
      "Epoch 120/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574us/step - accuracy: 0.9939 - loss: 0.0188 \n",
      "Epoch 121/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554us/step - accuracy: 0.9923 - loss: 0.0253\n",
      "Epoch 122/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576us/step - accuracy: 0.9915 - loss: 0.0153\n",
      "Epoch 123/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - accuracy: 0.9974 - loss: 0.0145 \n",
      "Epoch 124/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - accuracy: 0.9908 - loss: 0.0323\n",
      "Epoch 125/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554us/step - accuracy: 0.9959 - loss: 0.0128 \n",
      "Epoch 126/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571us/step - accuracy: 0.9923 - loss: 0.0194\n",
      "Epoch 127/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 666us/step - accuracy: 0.9977 - loss: 0.0076 \n",
      "Epoch 128/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - accuracy: 0.9960 - loss: 0.0088\n",
      "Epoch 129/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step - accuracy: 0.9915 - loss: 0.0132 \n",
      "Epoch 130/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609us/step - accuracy: 0.9901 - loss: 0.0239 \n",
      "Epoch 131/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - accuracy: 0.9950 - loss: 0.0183\n",
      "Epoch 132/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - accuracy: 0.9910 - loss: 0.0174 \n",
      "Epoch 133/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step - accuracy: 0.9796 - loss: 0.0686 \n",
      "Epoch 134/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step - accuracy: 0.9865 - loss: 0.0380 \n",
      "Epoch 135/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step - accuracy: 0.9992 - loss: 0.0167\n",
      "Epoch 136/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - accuracy: 0.9967 - loss: 0.0151\n",
      "Epoch 137/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592us/step - accuracy: 0.9989 - loss: 0.0039 \n",
      "Epoch 138/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571us/step - accuracy: 0.9937 - loss: 0.0190\n",
      "Epoch 139/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - accuracy: 0.9933 - loss: 0.0268\n",
      "Epoch 140/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - accuracy: 0.9948 - loss: 0.0212 \n",
      "Epoch 141/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553us/step - accuracy: 0.9941 - loss: 0.0215 \n",
      "Epoch 142/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610us/step - accuracy: 0.9908 - loss: 0.0346 \n",
      "Epoch 143/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - accuracy: 0.9985 - loss: 0.0168 \n",
      "Epoch 144/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561us/step - accuracy: 0.9994 - loss: 0.0126\n",
      "Epoch 145/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558us/step - accuracy: 0.9933 - loss: 0.0156\n",
      "Epoch 146/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571us/step - accuracy: 0.9961 - loss: 0.0163 \n",
      "Epoch 147/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - accuracy: 0.9910 - loss: 0.0131 \n",
      "Epoch 148/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - accuracy: 0.9883 - loss: 0.0222 \n",
      "Epoch 149/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - accuracy: 0.9973 - loss: 0.0104\n",
      "Epoch 150/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - accuracy: 0.9973 - loss: 0.0114 \n",
      "Epoch 151/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step - accuracy: 0.9937 - loss: 0.0244 \n",
      "Epoch 152/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569us/step - accuracy: 0.9936 - loss: 0.0145\n",
      "Epoch 153/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604us/step - accuracy: 0.9983 - loss: 0.0084 \n",
      "Epoch 154/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596us/step - accuracy: 0.9819 - loss: 0.0511\n",
      "Epoch 155/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step - accuracy: 0.9944 - loss: 0.0194 \n",
      "Epoch 156/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - accuracy: 0.9887 - loss: 0.0255 \n",
      "Epoch 157/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - accuracy: 0.9971 - loss: 0.0163 \n",
      "Epoch 158/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576us/step - accuracy: 0.9898 - loss: 0.0191 \n",
      "Epoch 159/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - accuracy: 0.9937 - loss: 0.0231 \n",
      "Epoch 160/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step - accuracy: 0.9892 - loss: 0.0330\n",
      "Epoch 161/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593us/step - accuracy: 0.9928 - loss: 0.0172\n",
      "Epoch 162/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579us/step - accuracy: 0.9775 - loss: 0.0548 \n",
      "Epoch 163/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - accuracy: 0.9879 - loss: 0.0487 \n",
      "Epoch 164/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540us/step - accuracy: 0.9911 - loss: 0.0217 \n",
      "Epoch 165/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566us/step - accuracy: 0.9917 - loss: 0.0276 \n",
      "Epoch 166/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586us/step - accuracy: 0.9919 - loss: 0.0173 \n",
      "Epoch 167/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565us/step - accuracy: 0.9999 - loss: 0.0121 \n",
      "Epoch 168/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - accuracy: 0.9988 - loss: 0.0064 \n",
      "Epoch 169/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - accuracy: 0.9960 - loss: 0.0142 \n",
      "Epoch 170/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559us/step - accuracy: 0.9898 - loss: 0.0427 \n",
      "Epoch 171/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558us/step - accuracy: 0.9986 - loss: 0.0065 \n",
      "Epoch 172/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554us/step - accuracy: 0.9943 - loss: 0.0197 \n",
      "Epoch 173/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577us/step - accuracy: 0.9956 - loss: 0.0172 \n",
      "Epoch 174/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - accuracy: 0.9955 - loss: 0.0152 \n",
      "Epoch 175/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step - accuracy: 0.9979 - loss: 0.0087 \n",
      "Epoch 176/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step - accuracy: 0.9921 - loss: 0.0249 \n",
      "Epoch 177/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step - accuracy: 0.9878 - loss: 0.0445\n",
      "Epoch 178/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 614us/step - accuracy: 0.9988 - loss: 0.0048 \n",
      "Epoch 179/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - accuracy: 0.9979 - loss: 0.0141\n",
      "Epoch 180/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - accuracy: 0.9976 - loss: 0.0167\n",
      "Epoch 181/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593us/step - accuracy: 0.9969 - loss: 0.0105 \n",
      "Epoch 182/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569us/step - accuracy: 0.9944 - loss: 0.0149 \n",
      "Epoch 183/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 547us/step - accuracy: 0.9904 - loss: 0.0225 \n",
      "Epoch 184/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592us/step - accuracy: 0.9976 - loss: 0.0135 \n",
      "Epoch 185/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586us/step - accuracy: 0.9941 - loss: 0.0263\n",
      "Epoch 186/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598us/step - accuracy: 0.9912 - loss: 0.0231\n",
      "Epoch 187/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - accuracy: 0.9984 - loss: 0.0106 \n",
      "Epoch 188/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - accuracy: 0.9908 - loss: 0.0155 \n",
      "Epoch 189/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591us/step - accuracy: 0.9990 - loss: 0.0122\n",
      "Epoch 190/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576us/step - accuracy: 0.9980 - loss: 0.0077 \n",
      "Epoch 191/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - accuracy: 0.9949 - loss: 0.0176 \n",
      "Epoch 192/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step - accuracy: 0.9975 - loss: 0.0082\n",
      "Epoch 193/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - accuracy: 1.0000 - loss: 0.0097\n",
      "Epoch 194/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step - accuracy: 0.9969 - loss: 0.0132\n",
      "Epoch 195/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - accuracy: 0.9901 - loss: 0.0315\n",
      "Epoch 196/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step - accuracy: 0.9894 - loss: 0.0418 \n",
      "Epoch 197/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548us/step - accuracy: 0.9995 - loss: 0.0051\n",
      "Epoch 198/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577us/step - accuracy: 0.9968 - loss: 0.0158 \n",
      "Epoch 199/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - accuracy: 0.9870 - loss: 0.0194 \n",
      "Epoch 200/200\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - accuracy: 0.9965 - loss: 0.0102 \n",
      "found in bag: ``\n",
      "found in bag: welcom\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: ar\n",
      "found in bag: yo\n",
      "found in bag: strong\n",
      "found in bag: point\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: want\n",
      "found in bag: to\n",
      "found in bag: search\n",
      "found in bag: hospt\n",
      "found in bag: dat\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: it\n",
      "found in bag: easy\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: can\n",
      "found in bag: i\n",
      "found in bag: get\n",
      "found in bag: a\n",
      "found in bag: prescrib\n",
      "found in bag: fil\n",
      "found in bag: ,\n",
      "found in bag: pleas\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: op\n",
      "found in bag: transfus\n",
      "found in bag: press\n",
      "found in bag: mod\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: loc\n",
      "found in bag: hospit\n",
      "found in bag: with\n",
      "found in bag: intend\n",
      "found in bag: car\n",
      "found in bag: unit\n",
      "found in bag: (\n",
      "found in bag: icu\n",
      "found in bag: )\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: feel\n",
      "found in bag: fatigu\n",
      "found in bag: and\n",
      "found in bag: weak\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: could\n",
      "found in bag: you\n",
      "found in bag: check\n",
      "found in bag: my\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: ,\n",
      "found in bag: pleas\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: hi\n",
      "found in bag: ther\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: yo\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: can\n",
      "found in bag: you\n",
      "found in bag: explain\n",
      "found in bag: the\n",
      "found in bag: doabl\n",
      "found in bag: advers\n",
      "found in bag: react\n",
      "found in bag: of\n",
      "found in bag: thi\n",
      "found in bag: med\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: find\n",
      "found in bag: hospit\n",
      "found in bag: me\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: 'm\n",
      "found in bag: cough\n",
      "found in bag: and\n",
      "found in bag: wheez\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: loc\n",
      "found in bag: a\n",
      "found in bag: hospit\n",
      "found in bag: that\n",
      "found in bag: recogn\n",
      "found in bag: my\n",
      "found in bag: ins\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: find\n",
      "found in bag: a\n",
      "found in bag: 24-hour\n",
      "found in bag: pharm\n",
      "found in bag: near\n",
      "found in bag: me\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: is\n",
      "found in bag: ther\n",
      "found in bag: a\n",
      "found in bag: oct\n",
      "found in bag: on\n",
      "found in bag: duty\n",
      "found in bag: right\n",
      "found in bag: now\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: nic\n",
      "found in bag: chat\n",
      "found in bag: to\n",
      "found in bag: you\n",
      "found in bag: ,\n",
      "found in bag: hello\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: hav\n",
      "found in bag: a\n",
      "found in bag: fev\n",
      "found in bag: and\n",
      "found in bag: chil\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: look\n",
      "found in bag: up\n",
      "found in bag: hospit\n",
      "found in bag: detail\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: until\n",
      "found in bag: next\n",
      "found in bag: ltim\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: unearth\n",
      "found in bag: me\n",
      "found in bag: a\n",
      "found in bag: pharm\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: lookup\n",
      "found in bag: for\n",
      "found in bag: hospit\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: ar\n",
      "found in bag: yo\n",
      "found in bag: tal\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: hav\n",
      "found in bag: musc\n",
      "found in bag: ach\n",
      "found in bag: and\n",
      "found in bag: pbin\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: chrissakes\n",
      "found in bag: press\n",
      "found in bag: dat\n",
      "found in bag: entry\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: feel\n",
      "found in bag: dizzy\n",
      "found in bag: and\n",
      "found in bag: lighthead\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: could\n",
      "found in bag: you\n",
      "found in bag: arrang\n",
      "found in bag: for\n",
      "found in bag: me\n",
      "found in bag: to\n",
      "found in bag: see\n",
      "found in bag: a\n",
      "found in bag: med\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: hav\n",
      "found in bag: a\n",
      "found in bag: headach\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: on\n",
      "found in bag: paty\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: result\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: help\n",
      "found in bag: you\n",
      "found in bag: provid\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: can\n",
      "found in bag: you\n",
      "found in bag: giv\n",
      "found in bag: me\n",
      "found in bag: an\n",
      "found in bag: upd\n",
      "found in bag: on\n",
      "found in bag: my\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: wel\n",
      "found in bag: ev\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: find\n",
      "found in bag: hospit\n",
      "found in bag: me\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: op\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: mod\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: bloow\n",
      "found in bag: press\n",
      "found in bag: dat\n",
      "found in bag: entry\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: how\n",
      "found in bag: 's\n",
      "found in bag: it\n",
      "found in bag: oing\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: is\n",
      "found in bag: it\n",
      "found in bag: poss\n",
      "found in bag: to\n",
      "found in bag: fulfil\n",
      "found in bag: with\n",
      "found in bag: a\n",
      "found in bag: phys\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: me\n",
      "found in bag: a\n",
      "found in bag: pharm\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: can\n",
      "found in bag: you\n",
      "found in bag: describ\n",
      "found in bag: any\n",
      "found in bag: undesir\n",
      "found in bag: evfect\n",
      "found in bag: that\n",
      "found in bag: could\n",
      "found in bag: occ\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: can\n",
      "found in bag: you\n",
      "found in bag: provid\n",
      "found in bag: me\n",
      "found in bag: with\n",
      "found in bag: my\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: meas\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: ar\n",
      "found in bag: you\n",
      "found in bag: cap\n",
      "found in bag: of\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: hospit\n",
      "found in bag: around\n",
      "found in bag: her\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: 'm\n",
      "found in bag: her\n",
      "found in bag: to\n",
      "found in bag: gath\n",
      "found in bag: my\n",
      "found in bag: prescrib\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "found in bag: ``\n",
      "found in bag: search\n",
      "found in bag: for\n",
      "found in bag: hospit\n",
      "found in bag: that\n",
      "found in bag: del\n",
      "found in bag: telemedicin\n",
      "found in bag: serv\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: op\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: modlu\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "found in bag: ``\n",
      "found in bag: is\n",
      "found in bag: ther\n",
      "found in bag: a\n",
      "found in bag: phys\n",
      "found in bag: i\n",
      "found in bag: can\n",
      "found in bag: talk\n",
      "found in bag: with\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "found in bag: ``\n",
      "found in bag: can\n",
      "found in bag: you\n",
      "found in bag: direct\n",
      "found in bag: me\n",
      "found in bag: to\n",
      "found in bag: a\n",
      "found in bag: phys\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: is\n",
      "found in bag: it\n",
      "found in bag: poss\n",
      "found in bag: to\n",
      "found in bag: meet\n",
      "found in bag: with\n",
      "found in bag: a\n",
      "found in bag: physy\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: nee\n",
      "found in bag: to\n",
      "found in bag: rplenish\n",
      "found in bag: my\n",
      "found in bag: supply\n",
      "found in bag: of\n",
      "found in bag: med\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: wel\n",
      "found in bag: afternoon\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: locn\n",
      "found in bag: a\n",
      "found in bag: hospit\n",
      "found in bag: that\n",
      "found in bag: acceiv\n",
      "found in bag: my\n",
      "found in bag: ins\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: feel\n",
      "found in bag: high\n",
      "found in bag: tir\n",
      "found in bag: and\n",
      "found in bag: letharg\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: ar\n",
      "found in bag: yo\n",
      "found in bag: tal\n",
      "found in bag: and\n",
      "found in bag: skil\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: until\n",
      "found in bag: impend\n",
      "found in bag: tim\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: thnk\n",
      "found in bag: you\n",
      "found in bag: so\n",
      "found in bag: much\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: can\n",
      "found in bag: you\n",
      "found in bag: provid\n",
      "found in bag: me\n",
      "found in bag: with\n",
      "found in bag: my\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: meas\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: searah\n",
      "found in bag: for\n",
      "found in bag: pharm\n",
      "found in bag: with\n",
      "found in bag: flu\n",
      "found in bag: shot\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: thank\n",
      "found in bag: you\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: find\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: reoult\n",
      "found in bag: by\n",
      "found in bag: id\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: load\n",
      "found in bag: paty\n",
      "found in bag: blod\n",
      "found in bag: press\n",
      "found in bag: result\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: could\n",
      "found in bag: you\n",
      "found in bag: reflil\n",
      "found in bag: my\n",
      "found in bag: prescrib\n",
      "found in bag: for\n",
      "found in bag: me\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: must\n",
      "found in bag: be\n",
      "found in bag: go\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: kind\n",
      "found in bag: of\n",
      "found in bag: task\n",
      "found in bag: ar\n",
      "found in bag: you\n",
      "found in bag: good\n",
      "found in bag: at\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: can\n",
      "found in bag: you\n",
      "found in bag: giv\n",
      "found in bag: me\n",
      "found in bag: an\n",
      "found in bag: refresh\n",
      "found in bag: on\n",
      "found in bag: my\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "found in bag: ``\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: for\n",
      "found in bag: paty\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: thantk\n",
      "found in bag: a\n",
      "found in bag: lot\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: tahnk\n",
      "found in bag: for\n",
      "found in bag: help\n",
      "found in bag: me\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "found in bag: ``\n",
      "found in bag: can\n",
      "found in bag: i\n",
      "found in bag: speak\n",
      "found in bag: to\n",
      "found in bag: a\n",
      "found in bag: healthc\n",
      "found in bag: providevr\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: wher\n",
      "found in bag: can\n",
      "found in bag: i\n",
      "found in bag: find\n",
      "found in bag: hospit\n",
      "found in bag: with\n",
      "found in bag: surgery\n",
      "found in bag: facilit\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "found in bag: ``\n",
      "found in bag: find\n",
      "found in bag: drugst\n",
      "found in bag: with\n",
      "found in bag: covid-19\n",
      "found in bag: vaccin\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: that\n",
      "found in bag: sign\n",
      "found in bag: a\n",
      "found in bag: lot\n",
      "found in bag: to\n",
      "found in bag: me\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: may\n",
      "found in bag: i\n",
      "found in bag: reord\n",
      "found in bag: my\n",
      "found in bag: prescrib\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: ar\n",
      "found in bag: the\n",
      "found in bag: risk\n",
      "found in bag: or\n",
      "found in bag: drawback\n",
      "found in bag: of\n",
      "found in bag: thi\n",
      "found in bag: med\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: look\n",
      "found in bag: for\n",
      "found in bag: a\n",
      "found in bag: hospit\n",
      "found in bag: that\n",
      "found in bag: 's\n",
      "found in bag: ok\n",
      "found in bag: 24/7\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: find\n",
      "found in bag: a\n",
      "found in bag: pharm\n",
      "found in bag: in\n",
      "found in bag: [\n",
      "found in bag: town/town\n",
      "found in bag: ]\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: maggio\n",
      "found in bag: i\n",
      "found in bag: hav\n",
      "found in bag: a\n",
      "found in bag: doct\n",
      "found in bag: 's\n",
      "found in bag: consult\n",
      "found in bag: ,\n",
      "found in bag: pleas\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: want\n",
      "found in bag: to\n",
      "found in bag: log\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: result\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "found in bag: ``\n",
      "found in bag: did\n",
      "found in bag: i\n",
      "found in bag: get\n",
      "found in bag: a\n",
      "found in bag: refil\n",
      "found in bag: on\n",
      "found in bag: my\n",
      "found in bag: prescrib\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: clin\n",
      "found in bag: lookup\n",
      "found in bag: for\n",
      "found in bag: paty\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: ar\n",
      "found in bag: ther\n",
      "found in bag: any\n",
      "found in bag: neg\n",
      "found in bag: effect\n",
      "found in bag: i\n",
      "found in bag: should\n",
      "found in bag: watch\n",
      "found in bag: out\n",
      "found in bag: for\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: see\n",
      "found in bag: you\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: show\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: result\n",
      "found in bag: for\n",
      "found in bag: paty\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: hemy\n",
      "found in bag: ,\n",
      "found in bag: how\n",
      "found in bag: ar\n",
      "found in bag: you\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: can\n",
      "found in bag: you\n",
      "found in bag: prep\n",
      "found in bag: my\n",
      "found in bag: prescrib\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: find\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: outcom\n",
      "found in bag: by\n",
      "found in bag: id\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: hi\n",
      "found in bag: ,\n",
      "found in bag: how\n",
      "found in bag: hav\n",
      "found in bag: you\n",
      "found in bag: been\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: is\n",
      "found in bag: ther\n",
      "found in bag: a\n",
      "found in bag: chant\n",
      "found in bag: of\n",
      "found in bag: expery\n",
      "found in bag: any\n",
      "found in bag: uninvit\n",
      "found in bag: effect\n",
      "found in bag: with\n",
      "found in bag: thi\n",
      "found in bag: med\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "found in bag: ``\n",
      "found in bag: thank\n",
      "found in bag: for\n",
      "found in bag: help\n",
      "found in bag: me\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: nee\n",
      "found in bag: to\n",
      "found in bag: repl\n",
      "found in bag: my\n",
      "found in bag: supply\n",
      "found in bag: of\n",
      "found in bag: med\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: could\n",
      "found in bag: you\n",
      "found in bag: helrp\n",
      "found in bag: me\n",
      "found in bag: book\n",
      "found in bag: an\n",
      "found in bag: appoint\n",
      "found in bag: with\n",
      "found in bag: a\n",
      "found in bag: doct\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: you\n",
      "found in bag: 've\n",
      "found in bag: been\n",
      "found in bag: so\n",
      "found in bag: typ\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "found in bag: ``\n",
      "found in bag: search\n",
      "found in bag: for\n",
      "found in bag: hospit\n",
      "found in bag: to\n",
      "found in bag: tranusf\n",
      "found in bag: paty\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: my\n",
      "found in bag: throat\n",
      "found in bag: is\n",
      "found in bag: sor\n",
      "found in bag: and\n",
      "found in bag: scratchy\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: do\n",
      "found in bag: you\n",
      "found in bag: spec\n",
      "found in bag: in\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: so\n",
      "found in bag: largo\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: salut\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: nee\n",
      "found in bag: to\n",
      "found in bag: speak\n",
      "found in bag: with\n",
      "found in bag: a\n",
      "found in bag: doct\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: waht\n",
      "found in bag: ar\n",
      "found in bag: you\n",
      "found in bag: cap\n",
      "found in bag: of\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: how\n",
      "found in bag: is\n",
      "found in bag: my\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: doing\n",
      "found in bag: entir\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: hospit\n",
      "found in bag: clos\n",
      "found in bag: to\n",
      "found in bag: my\n",
      "found in bag: loc\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: pick\n",
      "found in bag: up\n",
      "found in bag: my\n",
      "found in bag: med\n",
      "found in bag: ord\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: want\n",
      "found in bag: to\n",
      "found in bag: log\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: result\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: requir\n",
      "found in bag: the\n",
      "found in bag: at\n",
      "found in bag: of\n",
      "found in bag: a\n",
      "found in bag: doct\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: pleas\n",
      "found in bag: prep\n",
      "found in bag: my\n",
      "found in bag: med\n",
      "found in bag: for\n",
      "found in bag: me\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: my\n",
      "found in bag: trhoat\n",
      "found in bag: is\n",
      "found in bag: sor\n",
      "found in bag: and\n",
      "found in bag: scratchy\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: ar\n",
      "found in bag: the\n",
      "found in bag: unintend\n",
      "found in bag: consequ\n",
      "found in bag: i\n",
      "found in bag: might\n",
      "found in bag: fac\n",
      "found in bag: whil\n",
      "found in bag: tak\n",
      "found in bag: thi\n",
      "found in bag: medicin\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: could\n",
      "found in bag: you\n",
      "found in bag: get\n",
      "found in bag: my\n",
      "found in bag: prescrib\n",
      "found in bag: for\n",
      "found in bag: me\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: is\n",
      "found in bag: ther\n",
      "found in bag: a\n",
      "found in bag: doct\n",
      "found in bag: on\n",
      "found in bag: duty\n",
      "found in bag: right\n",
      "found in bag: now\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: my\n",
      "found in bag: prescrib\n",
      "found in bag: ready\n",
      "found in bag: for\n",
      "found in bag: pickup\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: wher\n",
      "found in bag: is\n",
      "found in bag: the\n",
      "found in bag: nearest\n",
      "found in bag: pharm\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: can\n",
      "found in bag: i\n",
      "found in bag: get\n",
      "found in bag: a\n",
      "found in bag: prescrib\n",
      "found in bag: fil\n",
      "found in bag: ,\n",
      "found in bag: pleas\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: loc\n",
      "found in bag: hospit\n",
      "found in bag: in\n",
      "found in bag: [\n",
      "found in bag: neighb\n",
      "found in bag: ]\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: feel\n",
      "found in bag: dizzy\n",
      "found in bag: and\n",
      "found in bag: liyghthead\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: loc\n",
      "found in bag: a\n",
      "found in bag: nearby\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: find\n",
      "found in bag: an\n",
      "found in bag: emerg\n",
      "found in bag: hopit\n",
      "found in bag: near\n",
      "found in bag: me\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: hospit\n",
      "found in bag: around\n",
      "found in bag: her\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: how\n",
      "found in bag: 's\n",
      "found in bag: it\n",
      "found in bag: go\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: 'm\n",
      "found in bag: so\n",
      "found in bag: thank\n",
      "found in bag: for\n",
      "found in bag: [\n",
      "found in bag: spec\n",
      "found in bag: gest\n",
      "found in bag: or\n",
      "found in bag: assist\n",
      "found in bag: ]\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: wher\n",
      "found in bag: can\n",
      "found in bag: i\n",
      "found in bag: unearth\n",
      "found in bag: a\n",
      "found in bag: pharm\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: could\n",
      "found in bag: you\n",
      "found in bag: dispens\n",
      "found in bag: my\n",
      "found in bag: med\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: can\n",
      "found in bag: you\n",
      "found in bag: direct\n",
      "found in bag: me\n",
      "found in bag: to\n",
      "found in bag: a\n",
      "found in bag: dort\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: 'm\n",
      "found in bag: profound\n",
      "found in bag: thank\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: hav\n",
      "found in bag: you\n",
      "found in bag: ver\n",
      "found in bag: my\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: rec\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: wher\n",
      "found in bag: can\n",
      "found in bag: i\n",
      "found in bag: unearth\n",
      "found in bag: a\n",
      "found in bag: hospit\n",
      "found in bag: emerg\n",
      "found in bag: room\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: greet\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: 'm\n",
      "found in bag: thank\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: search\n",
      "found in bag: for\n",
      "found in bag: med\n",
      "found in bag: cent\n",
      "found in bag: nearby\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: wher\n",
      "found in bag: is\n",
      "found in bag: the\n",
      "found in bag: nearest\n",
      "found in bag: hosit\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: apprecy\n",
      "found in bag: yo\n",
      "found in bag: help\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "found in bag: ``\n",
      "found in bag: unearth\n",
      "found in bag: pharm\n",
      "found in bag: with\n",
      "found in bag: drive-thru\n",
      "found in bag: serv\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: nee\n",
      "found in bag: medicc\n",
      "found in bag: assist\n",
      "found in bag: from\n",
      "found in bag: a\n",
      "found in bag: doct\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: how\n",
      "found in bag: you\n",
      "found in bag: could\n",
      "found in bag: help\n",
      "found in bag: me\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: is\n",
      "found in bag: my\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: stabl\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: wher\n",
      "found in bag: can\n",
      "found in bag: i\n",
      "found in bag: fil\n",
      "found in bag: a\n",
      "found in bag: prescrib\n",
      "found in bag: nearby\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: whab\n",
      "found in bag: 's\n",
      "found in bag: my\n",
      "found in bag: systolic/diastol\n",
      "found in bag: press\n",
      "found in bag: right\n",
      "found in bag: now\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: feel\n",
      "found in bag: short\n",
      "found in bag: of\n",
      "found in bag: breath\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "found in bag: ``\n",
      "found in bag: bby\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "found in bag: ``\n",
      "found in bag: ar\n",
      "found in bag: ther\n",
      "found in bag: any\n",
      "found in bag: advers\n",
      "found in bag: effect\n",
      "found in bag: i\n",
      "found in bag: should\n",
      "found in bag: be\n",
      "found in bag: aw\n",
      "found in bag: of\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: apprec\n",
      "found in bag: yo\n",
      "found in bag: help\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "found in bag: ``\n",
      "found in bag: thank\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: hey\n",
      "found in bag: ,\n",
      "found in bag: good\n",
      "found in bag: to\n",
      "found in bag: see\n",
      "found in bag: you\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "found in bag: ``\n",
      "found in bag: waht\n",
      "found in bag: ar\n",
      "found in bag: yo\n",
      "found in bag: tal\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: wher\n",
      "found in bag: can\n",
      "found in bag: i\n",
      "found in bag: over-the-count\n",
      "found in bag: med\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "found in bag: ``\n",
      "found in bag: ar\n",
      "found in bag: ther\n",
      "found in bag: any\n",
      "found in bag: knvwn\n",
      "found in bag: sid\n",
      "found in bag: effect\n",
      "found in bag: i\n",
      "found in bag: should\n",
      "found in bag: be\n",
      "found in bag: concern\n",
      "found in bag: about\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: 's\n",
      "found in bag: up\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: acn\n",
      "found in bag: i\n",
      "found in bag: get\n",
      "found in bag: a\n",
      "found in bag: prescrib\n",
      "found in bag: fil\n",
      "found in bag: ,\n",
      "found in bag: pleas\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "found in bag: ``\n",
      "found in bag: gaz\n",
      "found in bag: for\n",
      "found in bag: a\n",
      "found in bag: pharm\n",
      "found in bag: that\n",
      "found in bag: 's\n",
      "found in bag: op\n",
      "found in bag: lat\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: thansk\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: could\n",
      "found in bag: you\n",
      "found in bag: help\n",
      "found in bag: me\n",
      "found in bag: book\n",
      "found in bag: an\n",
      "found in bag: nomin\n",
      "found in bag: with\n",
      "found in bag: a\n",
      "found in bag: doct\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "found in bag: ``\n",
      "found in bag: my\n",
      "found in bag: joint\n",
      "found in bag: ar\n",
      "found in bag: and\n",
      "found in bag: pain\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: a\n",
      "found in bag: good\n",
      "found in bag: on\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: awesom\n",
      "found in bag: ,\n",
      "found in bag: thank\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "found in bag: ``\n",
      "found in bag: coudl\n",
      "found in bag: you\n",
      "found in bag: inform\n",
      "found in bag: me\n",
      "found in bag: of\n",
      "found in bag: my\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: result\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: hav\n",
      "found in bag: digest\n",
      "found in bag: issu\n",
      "found in bag: such\n",
      "found in bag: as\n",
      "found in bag: blo\n",
      "found in bag: or\n",
      "found in bag: indigest\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: my\n",
      "found in bag: joint\n",
      "found in bag: ar\n",
      "found in bag: swol\n",
      "found in bag: and\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: gokod\n",
      "found in bag: ev\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: wher\n",
      "found in bag: is\n",
      "found in bag: the\n",
      "found in bag: nearest\n",
      "found in bag: phharmacy\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: sharm\n",
      "found in bag: clos\n",
      "found in bag: to\n",
      "found in bag: my\n",
      "found in bag: loc\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n"
     ]
    }
   ],
   "source": [
    "nn_cross_results = generate_nn_results(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "a3e56497-c760-4c36-b049-393719d9d367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'accuracy': 0.9874213836477987,\n",
       "  'recall': 0.9888888888888889,\n",
       "  'precision': 0.9894179894179894},\n",
       " 2: {'accuracy': 0.9874213836477987,\n",
       "  'recall': 0.9912280701754387,\n",
       "  'precision': 0.9895833333333334},\n",
       " 3: {'accuracy': 0.9937106918238994,\n",
       "  'recall': 0.9935897435897436,\n",
       "  'precision': 0.9966666666666667},\n",
       " 4: {'accuracy': 0.9811320754716981,\n",
       "  'recall': 0.9470029239766081,\n",
       "  'precision': 0.9812635281385282},\n",
       " 5: {'accuracy': 1.0, 'recall': 1.0, 'precision': 1.0}}"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_cross_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "2c5b9c9a-943a-4e9c-a8fd-43ef91921da9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.987421</td>\n",
       "      <td>0.988889</td>\n",
       "      <td>0.989418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.987421</td>\n",
       "      <td>0.991228</td>\n",
       "      <td>0.989583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.993711</td>\n",
       "      <td>0.993590</td>\n",
       "      <td>0.996667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.947003</td>\n",
       "      <td>0.981264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy    recall  precision\n",
       "1  0.987421  0.988889   0.989418\n",
       "2  0.987421  0.991228   0.989583\n",
       "3  0.993711  0.993590   0.996667\n",
       "4  0.981132  0.947003   0.981264\n",
       "5  1.000000  1.000000   1.000000"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_results_df = pd.DataFrame.from_dict(nn_cross_results,orient='index')\n",
    "cross_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "dcffb3c8-6e07-4cc4-89a4-36322d87da85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "hovertemplate": "variable=accuracy<br>index=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "accuracy",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "accuracy",
         "offsetgroup": "accuracy",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          1,
          2,
          3,
          4,
          5
         ],
         "xaxis": "x",
         "y": [
          0.9874213836477987,
          0.9874213836477987,
          0.9937106918238994,
          0.9811320754716981,
          1
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "variable=recall<br>index=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "recall",
         "marker": {
          "color": "#EF553B",
          "pattern": {
           "shape": ""
          }
         },
         "name": "recall",
         "offsetgroup": "recall",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          1,
          2,
          3,
          4,
          5
         ],
         "xaxis": "x",
         "y": [
          0.9888888888888889,
          0.9912280701754387,
          0.9935897435897436,
          0.9470029239766081,
          1
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "variable=precision<br>index=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "precision",
         "marker": {
          "color": "#00cc96",
          "pattern": {
           "shape": ""
          }
         },
         "name": "precision",
         "offsetgroup": "precision",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          1,
          2,
          3,
          4,
          5
         ],
         "xaxis": "x",
         "y": [
          0.9894179894179894,
          0.9895833333333334,
          0.9966666666666667,
          0.9812635281385282,
          1
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "autosize": true,
        "barmode": "group",
        "legend": {
         "title": {
          "text": "Metric"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "<b>NN Cross-Validation Prediction Metrics</b>"
        },
        "xaxis": {
         "anchor": "y",
         "autorange": true,
         "domain": [
          0,
          1
         ],
         "range": [
          0.5,
          5.5
         ],
         "title": {
          "text": "<b>Fold</b>"
         },
         "type": "linear"
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "range": [
          0.8,
          1
         ],
         "title": {
          "text": "<b>Percentage</b>"
         },
         "type": "linear"
        }
       }
      },
      "image/png": "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",
      "text/html": [
       "<div>                            <div id=\"0be39826-04e1-4402-a5b8-ec1d7e63973e\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"0be39826-04e1-4402-a5b8-ec1d7e63973e\")) {                    Plotly.newPlot(                        \"0be39826-04e1-4402-a5b8-ec1d7e63973e\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=accuracy<br>index=%{x}<br>value=%{y}<extra></extra>\",\"legendgroup\":\"accuracy\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"accuracy\",\"offsetgroup\":\"accuracy\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[1,2,3,4,5],\"xaxis\":\"x\",\"y\":[0.9874213836477987,0.9874213836477987,0.9937106918238994,0.9811320754716981,1.0],\"yaxis\":\"y\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=recall<br>index=%{x}<br>value=%{y}<extra></extra>\",\"legendgroup\":\"recall\",\"marker\":{\"color\":\"#EF553B\",\"pattern\":{\"shape\":\"\"}},\"name\":\"recall\",\"offsetgroup\":\"recall\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[1,2,3,4,5],\"xaxis\":\"x\",\"y\":[0.9888888888888889,0.9912280701754387,0.9935897435897436,0.9470029239766081,1.0],\"yaxis\":\"y\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=precision<br>index=%{x}<br>value=%{y}<extra></extra>\",\"legendgroup\":\"precision\",\"marker\":{\"color\":\"#00cc96\",\"pattern\":{\"shape\":\"\"}},\"name\":\"precision\",\"offsetgroup\":\"precision\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[1,2,3,4,5],\"xaxis\":\"x\",\"y\":[0.9894179894179894,0.9895833333333334,0.9966666666666667,0.9812635281385282,1.0],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"<b>Fold</b>\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"<b>Percentage</b>\"},\"range\":[0.8,1]},\"legend\":{\"title\":{\"text\":\"Metric\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"group\",\"title\":{\"text\":\"<b>NN Cross-Validation Prediction Metrics</b>\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('0be39826-04e1-4402-a5b8-ec1d7e63973e');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cross_results_fig = px.bar(cross_results_df, x=cross_results_df.index, y=cross_results_df.columns, barmode='group') # Define a bar chart, using the combined overal results above except Successes\n",
    "cross_results_fig.update_layout(title_text=f\"<b>NN Cross-Validation Prediction Metrics</b>\") # Add a title to the figure\n",
    "cross_results_fig.update_xaxes(title_text=\"<b>Fold</b>\") # Add a title to the x axis\n",
    "cross_results_fig.update_yaxes(title_text=\"<b>Percentage</b>\",range=(0.8,1)) # Add a title to the primary y axis\n",
    "cross_results_fig.update_layout(legend=dict(title=\"Metric\"))\n",
    "#results_fig.update_legend(title_text=\"Metric\") # Add a title to the legend\n",
    "cross_results_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "ccdf39a6-b6f5-42e4-b207-1c2a94b3a19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_nn_accuracy = []\n",
    "cross_nn_precision = []\n",
    "cross_nn_recall = []\n",
    "for fold in nn_cross_results:\n",
    "    cross_nn_accuracy.append(nn_cross_results[fold]['accuracy'])\n",
    "    cross_nn_precision.append(nn_cross_results[fold]['precision'])\n",
    "    cross_nn_recall.append(nn_cross_results[fold]['recall'])\n",
    "cross_nn_accuracy = np.mean(cross_nn_accuracy)\n",
    "cross_nn_precision = np.mean(cross_nn_precision)\n",
    "cross_nn_recall = np.mean(cross_nn_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "7126d2f6-4c45-4cb5-9cb4-52d0924def72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NN</th>\n",
       "      <td>0.955975</td>\n",
       "      <td>0.958201</td>\n",
       "      <td>0.963329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAG</th>\n",
       "      <td>0.974843</td>\n",
       "      <td>0.896703</td>\n",
       "      <td>0.907326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     accuracy    recall  precision\n",
       "NN   0.955975  0.958201   0.963329\n",
       "RAG  0.974843  0.896703   0.907326"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "72a3d8a6-4710-42c4-a825-cf9615c9fe67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NN</th>\n",
       "      <td>0.955975</td>\n",
       "      <td>0.958201</td>\n",
       "      <td>0.963329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAG</th>\n",
       "      <td>0.974843</td>\n",
       "      <td>0.896703</td>\n",
       "      <td>0.907326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cross_NN</th>\n",
       "      <td>0.989937</td>\n",
       "      <td>0.984142</td>\n",
       "      <td>0.991386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy    recall  precision\n",
       "NN        0.955975  0.958201   0.963329\n",
       "RAG       0.974843  0.896703   0.907326\n",
       "Cross_NN  0.989937  0.984142   0.991386"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.loc['Cross_NN'] = [cross_nn_accuracy,cross_nn_recall,cross_nn_precision]\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "42aa6a3b-f5f4-4d5d-a269-142722b7dfbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "hovertemplate": "variable=accuracy<br>index=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "accuracy",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "accuracy",
         "offsetgroup": "accuracy",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "NN",
          "RAG",
          "Cross_NN"
         ],
         "xaxis": "x",
         "y": [
          0.9559748427672956,
          0.9748427672955975,
          0.989937106918239
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "variable=recall<br>index=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "recall",
         "marker": {
          "color": "#EF553B",
          "pattern": {
           "shape": ""
          }
         },
         "name": "recall",
         "offsetgroup": "recall",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "NN",
          "RAG",
          "Cross_NN"
         ],
         "xaxis": "x",
         "y": [
          0.9582010582010582,
          0.8967032967032966,
          0.9841419253261359
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "variable=precision<br>index=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "precision",
         "marker": {
          "color": "#00cc96",
          "pattern": {
           "shape": ""
          }
         },
         "name": "precision",
         "offsetgroup": "precision",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "NN",
          "RAG",
          "Cross_NN"
         ],
         "xaxis": "x",
         "y": [
          0.963328664799253,
          0.9073260073260074,
          0.9913863035113035
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "autosize": true,
        "barmode": "group",
        "legend": {
         "title": {
          "text": "Metric"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "<b>Intent Prediction Metrics</b>"
        },
        "xaxis": {
         "anchor": "y",
         "autorange": true,
         "domain": [
          0,
          1
         ],
         "range": [
          -0.5,
          2.5
         ],
         "title": {
          "text": "<b>Model</b>"
         },
         "type": "category"
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "range": [
          0.8,
          1
         ],
         "title": {
          "text": "<b>Percentage</b>"
         },
         "type": "linear"
        }
       }
      },
      "image/png": "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",
      "text/html": [
       "<div>                            <div id=\"0d5bc17b-c6a7-41b0-8f2f-df30eed8ccd7\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"0d5bc17b-c6a7-41b0-8f2f-df30eed8ccd7\")) {                    Plotly.newPlot(                        \"0d5bc17b-c6a7-41b0-8f2f-df30eed8ccd7\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=accuracy<br>index=%{x}<br>value=%{y}<extra></extra>\",\"legendgroup\":\"accuracy\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"accuracy\",\"offsetgroup\":\"accuracy\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[\"NN\",\"RAG\",\"Cross_NN\"],\"xaxis\":\"x\",\"y\":[0.9559748427672956,0.9748427672955975,0.989937106918239],\"yaxis\":\"y\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=recall<br>index=%{x}<br>value=%{y}<extra></extra>\",\"legendgroup\":\"recall\",\"marker\":{\"color\":\"#EF553B\",\"pattern\":{\"shape\":\"\"}},\"name\":\"recall\",\"offsetgroup\":\"recall\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[\"NN\",\"RAG\",\"Cross_NN\"],\"xaxis\":\"x\",\"y\":[0.9582010582010582,0.8967032967032966,0.9841419253261359],\"yaxis\":\"y\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=precision<br>index=%{x}<br>value=%{y}<extra></extra>\",\"legendgroup\":\"precision\",\"marker\":{\"color\":\"#00cc96\",\"pattern\":{\"shape\":\"\"}},\"name\":\"precision\",\"offsetgroup\":\"precision\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[\"NN\",\"RAG\",\"Cross_NN\"],\"xaxis\":\"x\",\"y\":[0.963328664799253,0.9073260073260074,0.9913863035113035],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"<b>Model</b>\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"<b>Percentage</b>\"},\"range\":[0.8,1]},\"legend\":{\"title\":{\"text\":\"Metric\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"group\",\"title\":{\"text\":\"<b>Intent Prediction Metrics</b>\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('0d5bc17b-c6a7-41b0-8f2f-df30eed8ccd7');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_results_fig = px.bar(results_df, x=results_df.index, y=results_df.columns, barmode='group') # Define a bar chart, using the combined overal results above except Successes\n",
    "full_results_fig.update_layout(title_text=f\"<b>Intent Prediction Metrics</b>\") # Add a title to the figure\n",
    "full_results_fig.update_xaxes(title_text=\"<b>Model</b>\") # Add a title to the x axis\n",
    "full_results_fig.update_yaxes(title_text=\"<b>Percentage</b>\",range=(0.8,1)) # Add a title to the primary y axis\n",
    "full_results_fig.update_layout(legend=dict(title=\"Metric\"))\n",
    "full_results_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "5ef9c426-ba50-4c3c-a316-29897a7cceb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_results_fig.write_image('../results/cross_results_fig.png')\n",
    "full_results_fig.write_image('../results/full_results_fig.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc000f9-db16-4d11-9c22-c76183019f66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
