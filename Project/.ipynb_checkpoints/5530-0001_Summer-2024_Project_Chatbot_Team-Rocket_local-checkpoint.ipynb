{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb2d4b2b-4270-48c6-9c95-aac531c7e02c",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe2758b-a6f2-4840-af5f-4b6672ffae04",
   "metadata": {},
   "source": [
    "## Prework to Generate Dataset CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2206309d-c751-4c00-a406-b865b8ceed36",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "466aff27-56da-456c-bd15-5fb7e97c5495",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "550d2ec6-76b3-4b80-93e0-9d1f02194a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/mnt/c/Users/willi/Downloads/intents.json') as json_data:\n",
    "    intents = json.load(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd937b91-b193-409f-ad1c-596887906cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intents': [{'tag': 'greeting', 'patterns': ['Hi there', 'How are you', 'Is anyone there?', 'Hello', 'Good day'], 'responses': ['Hello, thanks for asking', 'Good to see you again', 'Hi there, how can I help?'], 'context': ['']}, {'tag': 'goodbye', 'patterns': ['Bye', 'See you later', 'Goodbye', 'Nice chatting to you, bye', 'Till next time'], 'responses': ['See you!', 'Have a nice day', 'Bye! Come back again soon.'], 'context': ['']}, {'tag': 'thanks', 'patterns': ['Thanks', 'Thank you', \"That's helpful\", 'Awesome, thanks', 'Thanks for helping me'], 'responses': ['Happy to help!', 'Any time!', 'My pleasure'], 'context': ['']}, {'tag': 'noanswer', 'patterns': [], 'responses': [\"Sorry, can't understand you\", 'Please give me more info', 'Not sure I understand'], 'context': ['']}, {'tag': 'options', 'patterns': ['How you could help me?', 'What you can do?', 'What help you provide?', 'How you can be helpful?', 'What support is offered'], 'responses': ['I can guide you through Adverse drug reaction list, Blood pressure tracking, Hospitals and Pharmacies', 'Offering support for Adverse drug reaction, Blood pressure, Hospitals and Pharmacies'], 'context': ['']}, {'tag': 'adverse_drug', 'patterns': ['How to check Adverse drug reaction?', 'Open adverse drugs module', 'Give me a list of drugs causing adverse behavior', 'List all drugs suitable for patient with adverse reaction', 'Which drugs dont have adverse reaction?'], 'responses': ['Navigating to Adverse drug reaction module'], 'context': ['']}, {'tag': 'blood_pressure', 'patterns': ['Open blood pressure module', 'Task related to blood pressure', 'Blood pressure data entry', 'I want to log blood pressure results', 'Blood pressure data management'], 'responses': ['Navigating to Blood Pressure module'], 'context': ['']}, {'tag': 'blood_pressure_search', 'patterns': ['I want to search for blood pressure result history', 'Blood pressure for patient', 'Load patient blood pressure result', 'Show blood pressure results for patient', 'Find blood pressure results by ID'], 'responses': ['Please provide Patient ID', 'Patient ID?'], 'context': ['search_blood_pressure_by_patient_id']}, {'tag': 'search_blood_pressure_by_patient_id', 'patterns': [], 'responses': ['Loading Blood pressure result for Patient'], 'context': ['']}, {'tag': 'pharmacy_search', 'patterns': ['Find me a pharmacy', 'Find pharmacy', 'List of pharmacies nearby', 'Locate pharmacy', 'Search pharmacy'], 'responses': ['Please provide pharmacy name'], 'context': ['search_pharmacy_by_name']}, {'tag': 'search_pharmacy_by_name', 'patterns': [], 'responses': ['Loading pharmacy details'], 'context': ['']}, {'tag': 'hospital_search', 'patterns': ['Lookup for hospital', 'Searching for hospital to transfer patient', 'I want to search hospital data', 'Hospital lookup for patient', 'Looking up hospital details'], 'responses': ['Please provide hospital name or location'], 'context': ['search_hospital_by_params']}, {'tag': 'search_hospital_by_params', 'patterns': [], 'responses': ['Please provide hospital type'], 'context': ['search_hospital_by_type']}, {'tag': 'search_hospital_by_type', 'patterns': [], 'responses': ['Loading hospital details'], 'context': ['']}]}\n"
     ]
    }
   ],
   "source": [
    "print(intents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "339111c3-779a-475a-adaf-7c28566461d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_intent_dict = {}\n",
    "temp_utterance = []\n",
    "temp_intents = []\n",
    "for i in intents['intents']:\n",
    "    for j in i['patterns']:\n",
    "        temp_intents.append(str(i['tag']))\n",
    "        temp_utterance.append(str(j))        \n",
    "temp_intent_dict['utterance'] = temp_utterance\n",
    "temp_intent_dict['intent'] = temp_intents\n",
    "\n",
    "#for intent in intents['intents']:\n",
    "#    temp_intents[f\"{intent['tag']}\"] = intent['patterns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c1f6417e-33bb-4c74-a4c4-ef5664625ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'utterance': ['Hi there', 'How are you', 'Is anyone there?', 'Hello', 'Good day', 'Bye', 'See you later', 'Goodbye', 'Nice chatting to you, bye', 'Till next time', 'Thanks', 'Thank you', \"That's helpful\", 'Awesome, thanks', 'Thanks for helping me', 'How you could help me?', 'What you can do?', 'What help you provide?', 'How you can be helpful?', 'What support is offered', 'How to check Adverse drug reaction?', 'Open adverse drugs module', 'Give me a list of drugs causing adverse behavior', 'List all drugs suitable for patient with adverse reaction', 'Which drugs dont have adverse reaction?', 'Open blood pressure module', 'Task related to blood pressure', 'Blood pressure data entry', 'I want to log blood pressure results', 'Blood pressure data management', 'I want to search for blood pressure result history', 'Blood pressure for patient', 'Load patient blood pressure result', 'Show blood pressure results for patient', 'Find blood pressure results by ID', 'Find me a pharmacy', 'Find pharmacy', 'List of pharmacies nearby', 'Locate pharmacy', 'Search pharmacy', 'Lookup for hospital', 'Searching for hospital to transfer patient', 'I want to search hospital data', 'Hospital lookup for patient', 'Looking up hospital details'], 'intent': ['greeting', 'greeting', 'greeting', 'greeting', 'greeting', 'goodbye', 'goodbye', 'goodbye', 'goodbye', 'goodbye', 'thanks', 'thanks', 'thanks', 'thanks', 'thanks', 'options', 'options', 'options', 'options', 'options', 'adverse_drug', 'adverse_drug', 'adverse_drug', 'adverse_drug', 'adverse_drug', 'blood_pressure', 'blood_pressure', 'blood_pressure', 'blood_pressure', 'blood_pressure', 'blood_pressure_search', 'blood_pressure_search', 'blood_pressure_search', 'blood_pressure_search', 'blood_pressure_search', 'pharmacy_search', 'pharmacy_search', 'pharmacy_search', 'pharmacy_search', 'pharmacy_search', 'hospital_search', 'hospital_search', 'hospital_search', 'hospital_search', 'hospital_search']}\n"
     ]
    }
   ],
   "source": [
    "print(temp_intent_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "33baf7b8-a6ad-457f-8ca1-75004d30d302",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_intent_df = pd.DataFrame.from_dict(temp_intent_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ae487bdf-a71b-4b63-9309-1076dcf1c5c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi there</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How are you</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Is anyone there?</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hello</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Good day</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bye</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>See you later</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Goodbye</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Nice chatting to you, bye</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Till next time</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   utterance    intent\n",
       "0                   Hi there  greeting\n",
       "1                How are you  greeting\n",
       "2           Is anyone there?  greeting\n",
       "3                      Hello  greeting\n",
       "4                   Good day  greeting\n",
       "5                        Bye   goodbye\n",
       "6              See you later   goodbye\n",
       "7                    Goodbye   goodbye\n",
       "8  Nice chatting to you, bye   goodbye\n",
       "9             Till next time   goodbye"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_intent_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "21900e0b-0a91-4a26-a9d8-ce418323b15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_intent_df['utterance'] = temp_intent_df['utterance'].apply(lambda x: \"\\\"\" + str(x) + \"\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8e984eed-ea75-417b-a772-6082c92e5c8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Hi there\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"How are you\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Is anyone there?\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Hello\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Good day\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"Bye\"</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"See you later\"</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"Goodbye\"</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"Nice chatting to you, bye\"</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"Till next time\"</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     utterance    intent\n",
       "0                   \"Hi there\"  greeting\n",
       "1                \"How are you\"  greeting\n",
       "2           \"Is anyone there?\"  greeting\n",
       "3                      \"Hello\"  greeting\n",
       "4                   \"Good day\"  greeting\n",
       "5                        \"Bye\"   goodbye\n",
       "6              \"See you later\"   goodbye\n",
       "7                    \"Goodbye\"   goodbye\n",
       "8  \"Nice chatting to you, bye\"   goodbye\n",
       "9             \"Till next time\"   goodbye"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_intent_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fe36166b-e0ec-4e70-adca-85693a7b8f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_raw_df = pd.read_csv('/mnt/c/Users/willi/Downloads/intent_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1360c3f7-741f-48d9-9788-d55881a2b312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Hello!\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Hi there!\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Hey!\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Good morning!\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Good afternoon!\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"Good evening!\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"Howdy!\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"Greetings!\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"What's up?\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"How's it going?\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           utterance    intent\n",
       "0           \"Hello!\"  greeting\n",
       "1        \"Hi there!\"  greeting\n",
       "2             \"Hey!\"  greeting\n",
       "3    \"Good morning!\"  greeting\n",
       "4  \"Good afternoon!\"  greeting\n",
       "5    \"Good evening!\"  greeting\n",
       "6           \"Howdy!\"  greeting\n",
       "7       \"Greetings!\"  greeting\n",
       "8       \"What's up?\"  greeting\n",
       "9  \"How's it going?\"  greeting"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intent_raw_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ba6dbaf9-653e-40e5-98a3-aee621858b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_full_df = pd.concat([temp_intent_df,intent_raw_df],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0e52000f-40ac-4dad-bcc2-cdd871f0e2d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Hi there\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"How are you\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Is anyone there?\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Hello\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Good day\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"Bye\"</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"See you later\"</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"Goodbye\"</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"Nice chatting to you, bye\"</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"Till next time\"</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     utterance    intent\n",
       "0                   \"Hi there\"  greeting\n",
       "1                \"How are you\"  greeting\n",
       "2           \"Is anyone there?\"  greeting\n",
       "3                      \"Hello\"  greeting\n",
       "4                   \"Good day\"  greeting\n",
       "5                        \"Bye\"   goodbye\n",
       "6              \"See you later\"   goodbye\n",
       "7                    \"Goodbye\"   goodbye\n",
       "8  \"Nice chatting to you, bye\"   goodbye\n",
       "9             \"Till next time\"   goodbye"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intent_full_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d141b8cf-267c-4a3a-8550-2e2dec57bcdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(205, 2)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#temp_intent_df.shape\n",
    "#intent_raw_df.shape\n",
    "intent_full_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ff8e6e39-1af2-4068-9f6f-b348e8931279",
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_full_df.to_csv('/mnt/c/Users/willi/Downloads/intent_full_dataset.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "47451331-9b4e-4a4b-9d97-4422b391d047",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_response_dict = {}\n",
    "temp_responses = []\n",
    "temp_intents = []\n",
    "for i in intents['intents']:\n",
    "    for j in i['responses']:\n",
    "        temp_intents.append(str(i['tag']))\n",
    "        temp_responses.append(str(j))        \n",
    "temp_response_dict['responses'] = temp_responses\n",
    "temp_response_dict['intent'] = temp_intents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "73c521bd-3213-40a4-9813-812686009531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>responses</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hello, thanks for asking</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good to see you again</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hi there, how can I help?</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>See you!</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Have a nice day</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bye! Come back again soon.</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Happy to help!</td>\n",
       "      <td>thanks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Any time!</td>\n",
       "      <td>thanks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>My pleasure</td>\n",
       "      <td>thanks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sorry, can't understand you</td>\n",
       "      <td>noanswer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     responses    intent\n",
       "0     Hello, thanks for asking  greeting\n",
       "1        Good to see you again  greeting\n",
       "2    Hi there, how can I help?  greeting\n",
       "3                     See you!   goodbye\n",
       "4              Have a nice day   goodbye\n",
       "5   Bye! Come back again soon.   goodbye\n",
       "6               Happy to help!    thanks\n",
       "7                    Any time!    thanks\n",
       "8                  My pleasure    thanks\n",
       "9  Sorry, can't understand you  noanswer"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_response_df = pd.DataFrame.from_dict(temp_response_dict)\n",
    "temp_response_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e2454e91-56ce-413d-ab5a-4c2be05c3289",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_response_df.to_csv('/mnt/c/Users/willi/Downloads/responses_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939daff2-2fec-4c6a-8423-6cdb5e05d6c8",
   "metadata": {},
   "source": [
    "## Dataset Load and Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4634bb81-9a42-4c79-9690-4a13e5ea0dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_df = pd.read_csv('/mnt/c/Users/willi/Downloads/intent_full_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db7a39ad-0de3-4f83-a7da-0cd4fd9be34d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Hi there\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"How are you\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Is anyone there?\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Hello\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Good day\"</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"Bye\"</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"See you later\"</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"Goodbye\"</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"Nice chatting to you, bye\"</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"Till next time\"</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     utterance    intent\n",
       "0                   \"Hi there\"  greeting\n",
       "1                \"How are you\"  greeting\n",
       "2           \"Is anyone there?\"  greeting\n",
       "3                      \"Hello\"  greeting\n",
       "4                   \"Good day\"  greeting\n",
       "5                        \"Bye\"   goodbye\n",
       "6              \"See you later\"   goodbye\n",
       "7                    \"Goodbye\"   goodbye\n",
       "8  \"Nice chatting to you, bye\"   goodbye\n",
       "9             \"Till next time\"   goodbye"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intent_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8eeea33-e482-4bb7-8958-92a075611eaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(205, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intent_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bd59a8b-fa46-4e28-926e-5e7291e2b600",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = intent_df['utterance']\n",
    "y = intent_df['intent']\n",
    "X_train_df, X_test_df, y_train_df, y_test_df = train_test_split(X, y, random_state=42, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82fd95d2-a610-4484-9460-ccdb854026e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.concat([X_test_df,y_test_df],axis=1)\n",
    "train_df = pd.concat([X_train_df,y_train_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59ebeb94-9533-42c5-884c-2d0c3f1d21c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>\"Bye!\"</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>\"What are your areas of expertise?\"</td>\n",
       "      <td>options</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>\"What's the status of my blood pressure today?\"</td>\n",
       "      <td>blood_pressure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>\"You're a lifesaver!\"</td>\n",
       "      <td>thanks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>\"Locate pharmacy\"</td>\n",
       "      <td>pharmacy_search</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>\"Which drugs dont have adverse reaction?\"</td>\n",
       "      <td>adverse_drug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>\"Can you describe any undesirable effects that...</td>\n",
       "      <td>adverse_drug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>\"What do you specialize in?\"</td>\n",
       "      <td>options</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>\"Blood pressure data management\"</td>\n",
       "      <td>blood_pressure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>\"What support is offered\"</td>\n",
       "      <td>options</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             utterance           intent\n",
       "66                                              \"Bye!\"          goodbye\n",
       "111                \"What are your areas of expertise?\"          options\n",
       "153    \"What's the status of my blood pressure today?\"   blood_pressure\n",
       "96                               \"You're a lifesaver!\"           thanks\n",
       "38                                   \"Locate pharmacy\"  pharmacy_search\n",
       "24           \"Which drugs dont have adverse reaction?\"     adverse_drug\n",
       "139  \"Can you describe any undesirable effects that...     adverse_drug\n",
       "112                       \"What do you specialize in?\"          options\n",
       "29                    \"Blood pressure data management\"   blood_pressure\n",
       "19                           \"What support is offered\"          options"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34e42d8-d40b-441f-a556-9632a7bfa33c",
   "metadata": {},
   "source": [
    "# RAG Intent Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83475981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in ./anaconda3/lib/python3.11/site-packages (2.3.1)\n",
      "Requirement already satisfied: filelock in ./anaconda3/lib/python3.11/site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./anaconda3/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in ./anaconda3/lib/python3.11/site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in ./anaconda3/lib/python3.11/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in ./anaconda3/lib/python3.11/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in ./anaconda3/lib/python3.11/site-packages (from torch) (2024.6.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./anaconda3/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./anaconda3/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./anaconda3/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./anaconda3/lib/python3.11/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./anaconda3/lib/python3.11/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./anaconda3/lib/python3.11/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./anaconda3/lib/python3.11/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./anaconda3/lib/python3.11/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./anaconda3/lib/python3.11/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in ./anaconda3/lib/python3.11/site-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./anaconda3/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.1 in ./anaconda3/lib/python3.11/site-packages (from torch) (2.3.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./anaconda3/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.40)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./anaconda3/lib/python3.11/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./anaconda3/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: transformers in ./anaconda3/lib/python3.11/site-packages (4.41.2)\n",
      "Requirement already satisfied: filelock in ./anaconda3/lib/python3.11/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in ./anaconda3/lib/python3.11/site-packages (from transformers) (0.23.4)\n",
      "Requirement already satisfied: numpy>=1.17 in ./anaconda3/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./anaconda3/lib/python3.11/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./anaconda3/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./anaconda3/lib/python3.11/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in ./anaconda3/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in ./anaconda3/lib/python3.11/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./anaconda3/lib/python3.11/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./anaconda3/lib/python3.11/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2024.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./anaconda3/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./anaconda3/lib/python3.11/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./anaconda3/lib/python3.11/site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./anaconda3/lib/python3.11/site-packages (from requests->transformers) (2024.6.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U torch\n",
    "!pip install -U transformers\n",
    "!pip install -qU \"semantic-router[local]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7a8f807d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from semantic_router import Route\n",
    "from semantic_router import RouteLayer\n",
    "from semantic_router.encoders import HuggingFaceEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ce12466d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_device(\"cuda\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained('microsoft/phi-1_5', torch_dtype='auto')\n",
    "tokenizer = AutoTokenizer.from_pretrained('microsoft/phi-1_5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "3aa21ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Route(name='goodbye', utterances=['\"Bye!\"', '\"Bye\"', '\"Adios!\"', '\"So long!\"', '\"Have a great day!\"', '\"Bye-bye!\"', '\"See you later\"', '\"Farewell!\"', '\"See you around!\"', '\"Take it easy!\"', '\"Goodbye\"', '\"Have a good one!\"', '\"Nice chatting to you, bye\"', '\"Catch you later!\"', '\"I must be going.\"', '\"Have a good one!\"'], description=None, function_schemas=None, llm=None, score_threshold=None), Route(name='options', utterances=['\"What are your areas of expertise?\"', '\"What do you specialize in?\"', '\"What support is offered\"', '\"What kind of tasks are you good at?\"', '\"What do you excel at?\"', '\"What can you bring to this project?\"', '\"What skills do you bring to the table?\"', '\"What are your technical skills?\"', '\"What are your capabilities?\"', '\"What are your strengths?\"', '\"What are your proficiencies?\"', '\"What are your strong points?\"', '\"What are your talents?\"', '\"What can you contribute?\"', '\"What are your abilities?\"', '\"What are you capable of?\"', '\"What help you provide?\"', '\"What can you do well?\"', '\"What are your competencies?\"', '\"What are your professional skills?\"', '\"What skills do you have?\"'], description=None, function_schemas=None, llm=None, score_threshold=None), Route(name='blood_pressure', utterances=['\"What\\'s the status of my blood pressure today?\"', '\"Blood pressure data management\"', '\"Is my blood pressure stable?\"', '\"Task related to blood pressure\"', '\"Are there any concerns with my blood pressure readings?\"', '\"Blood pressure data entry\"', '\"What are my blood pressure levels?\"', '\"What\\'s my systolic/diastolic pressure right now?\"', '\"I want to log blood pressure results\"', '\"How does my blood pressure compare to normal levels?\"', '\"Could you let me know my current BP numbers?\"', '\"How is my blood pressure doing overall?\"', '\"Have you checked my blood pressure recently?\"', '\"Do you have the latest reading of my blood pressure?\"', '\"Could you check my blood pressure, please?\"', '\"Can you give me an update on my blood pressure?\"'], description=None, function_schemas=None, llm=None, score_threshold=None), Route(name='thanks', utterances=['\"You\\'re a lifesaver!\"', '\"Thanks a bunch!\"', '\"I owe you one.\"', '\"You\\'ve been so kind.\"', '\"That\\'s helpful\"', '\"Thank you!\"', '\"Thank you\"', '\"Thanks\"', '\"Much obliged!\"', '\"I can\\'t thank you enough.\"', '\"Thank you so much!\"', '\"Awesome, thanks\"', '\"I\\'m grateful.\"', '\"I\\'m so thankful for [specific gesture or help].\"', '\"Thanks a million!\"', '\"I really appreciate it.\"', '\"Thanks for helping me\"', '\"Many thanks!\"', '\"That means a lot to me.\"'], description=None, function_schemas=None, llm=None, score_threshold=None), Route(name='pharmacy_search', utterances=['\"Locate pharmacy\"', '\"Search for pharmacies with flu shots.\"', '\"Where can I find a pharmacy?\"', '\"Where is the nearest pharmacy?\"', '\"Find pharmacies with drive-thru services.\"', '\"Nearby pharmacies open now.\"', '\"Find me a pharmacy\"', '\"Locate a pharmacy nearby.\"', '\"Find pharmacy\"', '\"Search for drugstores nearby.\"', '\"Where can I buy over-the-counter medications?\"', '\"Locate pharmacies with a pharmacy technician.\"', '\"Find pharmacies near me.\"', '\"Search pharmacy\"', '\"Locate drugstores in [neighborhood].\"', '\"Find pharmacies with COVID-19 vaccines.\"', '\"Look for a pharmacy that\\'s open late.\"', '\"Where can I fill a prescription nearby?\"', '\"Find a pharmacy in [city/town].\"', '\"Pharmacies around here.\"', '\"List of pharmacies nearby\"', '\"Locate a pharmacy that accepts my insurance.\"'], description=None, function_schemas=None, llm=None, score_threshold=None), Route(name='adverse_drug', utterances=['\"Which drugs dont have adverse reaction?\"', '\"Can you describe any undesirable effects that could occur?\"', '\"What kind of reactions might I experience from this medication?\"', '\"Is there a chance of experiencing any unwanted effects with this medication?\"', '\"What are the potential side effects of this medication?\"', '\"What should I expect in terms of side effects from this medication?\"', '\"Are there any complications I should anticipate from using this medication?\"', '\"Could you list the potential drawbacks or downsides of using this drug?\"', '\"Can you tell me about the possible side effects of taking this drug?\"', '\"What are the unintended consequences I might face while taking this medicine?\"', '\"Give me a list of drugs causing adverse behavior\"', '\"Are there any known side effects I should be concerned about?\"', '\"Are there any adverse effects I should be aware of?\"', '\"What are the possible adverse outcomes of this treatment?\"', '\"List all drugs suitable for patient with adverse reaction\"', '\"Could you detail the side effects that users commonly report?\"', '\"What are the chances of experiencing side effects with this drug?\"', '\"Could you outline the potential side effects I might encounter?\"', '\"Can you explain the possible adverse reactions of this medication?\"', '\"Open adverse drugs module\"', '\"Are there any common side effects associated with this treatment?\"', '\"What are the risks or drawbacks of this medication?\"', '\"How to check Adverse drug reaction?\"'], description=None, function_schemas=None, llm=None, score_threshold=None), Route(name='greeting', utterances=['\"Hiya!\"', '\"Howdy!\"', '\"Is anyone there?\"', '\"Hi there!\"', '\"Nice to see you!\"', '\"Good day\"', '\"Welcome!\"', '\"Hi there\"', '\"How are you doing today?\"', '\"Hey!\"', '\"Hello\"', '\"What\\'s up?\"', '\"Good afternoon!\"', '\"Hey, how are you?\"', '\"Hey, good to see you!\"', '\"How\\'s it going?\"', '\"Good evening!\"', '\"Well met!\"', '\"Good morning!\"', '\"Salutations!\"', '\"How are you\"', '\"Greetings!\"'], description=None, function_schemas=None, llm=None, score_threshold=None), Route(name='blood_pressure_search', utterances=['\"Blood pressure for patient\"', '\"Show blood pressure results for patient\"', '\"Load patient blood pressure result\"', '\"Find blood pressure results by ID\"'], description=None, function_schemas=None, llm=None, score_threshold=None), Route(name='hospital_search', utterances=['\"I want to search hospital data\"', '\"Searching for hospital to transfer patient\"', '\"Where can I find a hospital emergency room?\"', '\"Locate hospitals in [neighborhood].\"', '\"Locate a hospital that accepts my insurance.\"', '\"Look for a hospital that\\'s open 24/7.\"', '\"Where is the nearest hospital?\"', '\"Locate hospitals with intensive care units (ICU).\"', '\"Looking up hospital details\"', '\"Lookup for hospital\"', '\"Hospitals around here.\"', '\"Hospital lookup for patient\"', '\"Find hospitals near me.\"', '\"Search for medical centers nearby.\"', '\"Locate a hospital nearby.\"', '\"Search for hospitals with urgent care services.\"', '\"Find hospitals with COVID-19 treatment facilities.\"', '\"Find hospitals with specific specialties (e.g., cardiology, pediatrics).\"', '\"Where can I find a hospital?\"', '\"Where can I find hospitals with surgery facilities?\"', '\"Hospital close to my location.\"'], description=None, function_schemas=None, llm=None, score_threshold=None)]\n"
     ]
    }
   ],
   "source": [
    "#adverse_drug_route = Route(\n",
    "#    name= \"adverse_drug\",\n",
    "#    utterances= [\"How to check Adverse drug reaction?\", \"Open adverse drugs module\", \"Give me a list of drugs causing adverse behavior\", \"List all drugs suitable for patient with adverse reaction\", \"Which drugs dont have adverse reaction?\" ],\n",
    "#    responses= [\"Navigating to Adverse drug reaction module\"],\n",
    "#)\n",
    "#blood_pressure_route = Route(\n",
    "#    name= \"blood_pressure\",\n",
    "#    utterances= [\"Open blood pressure module\", \"Task related to blood pressure\", \"Blood pressure data entry\", \"I want to log blood pressure results\", \"Blood pressure data management\" ],\n",
    "#    responses= [\"Navigating to Blood Pressure module\"],\n",
    "#)\n",
    "\n",
    "routes=[]\n",
    "intents = train_df['intent'].unique()\n",
    "\n",
    "for intent in intents:\n",
    "    temp_df = train_df.loc[train_df['intent'] == intent]\n",
    "    temp_utterances = temp_df['utterance'].tolist()\n",
    "    intent_name = str(intent)\n",
    "    intent_name = Route(\n",
    "        name=intent,\n",
    "        utterances=temp_utterances,\n",
    "        responses=['N/A']\n",
    "    )\n",
    "    routes.append(intent_name)\n",
    "\n",
    "print(routes)\n",
    "\n",
    "#response_dict = {'blood_pressure': {'name': 'blood_pressure', 'responses': [\"Navigating to Blood Pressure module\"]}}\n",
    "\n",
    "#routes=[adverse_drug_route,blood_pressure_route]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "7790c411",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = HuggingFaceEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "9df52f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rl = RouteLayer(encoder=encoder, routes=routes, llm=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "5e9309a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RouteChoice(name='adverse_drug', function_call=None, similarity_score=None)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rl(\"Open adverse drugs module\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "74a97eca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'blood_pressure'"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rl(\"can you search for my blood pressure please\").name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "890bb6aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'response_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[131], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mresponse_dict\u001b[49m[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrl(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcan you search for my blood pressure please\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresponses\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'response_dict' is not defined"
     ]
    }
   ],
   "source": [
    "response_dict[f'{rl(\"can you search for my blood pressure please\").name}']['responses']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f6cc3f-d255-4c78-8038-8fbc674160e9",
   "metadata": {},
   "source": [
    "# NN Intent Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebf33074-4783-4080-8544-078b7cea19fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in ./anaconda3/lib/python3.11/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in ./anaconda3/lib/python3.11/site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in ./anaconda3/lib/python3.11/site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./anaconda3/lib/python3.11/site-packages (from nltk) (2024.5.15)\n",
      "Requirement already satisfied: tqdm in ./anaconda3/lib/python3.11/site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: flask in ./anaconda3/lib/python3.11/site-packages (2.2.2)\n",
      "Collecting flask\n",
      "  Obtaining dependency information for flask from https://files.pythonhosted.org/packages/61/80/ffe1da13ad9300f87c93af113edd0638c75138c42a0994becfacac078c06/flask-3.0.3-py3-none-any.whl.metadata\n",
      "  Downloading flask-3.0.3-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting Werkzeug>=3.0.0 (from flask)\n",
      "  Obtaining dependency information for Werkzeug>=3.0.0 from https://files.pythonhosted.org/packages/9d/6e/e792999e816d19d7fcbfa94c730936750036d65656a76a5a688b57a656c4/werkzeug-3.0.3-py3-none-any.whl.metadata\n",
      "  Downloading werkzeug-3.0.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in ./anaconda3/lib/python3.11/site-packages (from flask) (3.1.4)\n",
      "Collecting itsdangerous>=2.1.2 (from flask)\n",
      "  Obtaining dependency information for itsdangerous>=2.1.2 from https://files.pythonhosted.org/packages/04/96/92447566d16df59b2a776c0fb82dbc4d9e07cd95062562af01e408583fc4/itsdangerous-2.2.0-py3-none-any.whl.metadata\n",
      "  Downloading itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting click>=8.1.3 (from flask)\n",
      "  Obtaining dependency information for click>=8.1.3 from https://files.pythonhosted.org/packages/00/2e/d53fa4befbf2cfa713304affc7ca780ce4fc1fd8710527771b58311a3229/click-8.1.7-py3-none-any.whl.metadata\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting blinker>=1.6.2 (from flask)\n",
      "  Obtaining dependency information for blinker>=1.6.2 from https://files.pythonhosted.org/packages/bb/2a/10164ed1f31196a2f7f3799368a821765c62851ead0e630ab52b8e14b4d0/blinker-1.8.2-py3-none-any.whl.metadata\n",
      "  Downloading blinker-1.8.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./anaconda3/lib/python3.11/site-packages (from Jinja2>=3.1.2->flask) (2.1.5)\n",
      "Downloading flask-3.0.3-py3-none-any.whl (101 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading blinker-1.8.2-py3-none-any.whl (9.5 kB)\n",
      "Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "Downloading werkzeug-3.0.3-py3-none-any.whl (227 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.3/227.3 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: Werkzeug, itsdangerous, click, blinker, flask\n",
      "  Attempting uninstall: Werkzeug\n",
      "    Found existing installation: Werkzeug 2.2.3\n",
      "    Uninstalling Werkzeug-2.2.3:\n",
      "      Successfully uninstalled Werkzeug-2.2.3\n",
      "  Attempting uninstall: itsdangerous\n",
      "    Found existing installation: itsdangerous 2.0.1\n",
      "    Uninstalling itsdangerous-2.0.1:\n",
      "      Successfully uninstalled itsdangerous-2.0.1\n",
      "  Attempting uninstall: click\n",
      "    Found existing installation: click 8.0.4\n",
      "    Uninstalling click-8.0.4:\n",
      "      Successfully uninstalled click-8.0.4\n",
      "  Attempting uninstall: flask\n",
      "    Found existing installation: Flask 2.2.2\n",
      "    Uninstalling Flask-2.2.2:\n",
      "      Successfully uninstalled Flask-2.2.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "python-lsp-black 1.2.1 requires black>=22.3.0, but you have black 0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Werkzeug-3.0.3 blinker-1.8.2 click-8.1.7 flask-3.0.3 itsdangerous-2.2.0\n",
      "Requirement already satisfied: flask_cors in ./anaconda3/lib/python3.11/site-packages (4.0.1)\n",
      "Requirement already satisfied: Flask>=0.9 in ./anaconda3/lib/python3.11/site-packages (from flask_cors) (3.0.3)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in ./anaconda3/lib/python3.11/site-packages (from Flask>=0.9->flask_cors) (3.0.3)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in ./anaconda3/lib/python3.11/site-packages (from Flask>=0.9->flask_cors) (3.1.4)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in ./anaconda3/lib/python3.11/site-packages (from Flask>=0.9->flask_cors) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in ./anaconda3/lib/python3.11/site-packages (from Flask>=0.9->flask_cors) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in ./anaconda3/lib/python3.11/site-packages (from Flask>=0.9->flask_cors) (1.8.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./anaconda3/lib/python3.11/site-packages (from Jinja2>=3.1.2->Flask>=0.9->flask_cors) (2.1.5)\n",
      "Requirement already satisfied: keras in ./anaconda3/lib/python3.11/site-packages (3.3.3)\n",
      "Requirement already satisfied: absl-py in ./anaconda3/lib/python3.11/site-packages (from keras) (2.1.0)\n",
      "Requirement already satisfied: numpy in ./anaconda3/lib/python3.11/site-packages (from keras) (1.26.4)\n",
      "Requirement already satisfied: rich in ./anaconda3/lib/python3.11/site-packages (from keras) (13.7.1)\n",
      "Requirement already satisfied: namex in ./anaconda3/lib/python3.11/site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: h5py in ./anaconda3/lib/python3.11/site-packages (from keras) (3.11.0)\n",
      "Requirement already satisfied: optree in ./anaconda3/lib/python3.11/site-packages (from keras) (0.11.0)\n",
      "Requirement already satisfied: ml-dtypes in ./anaconda3/lib/python3.11/site-packages (from keras) (0.3.2)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in ./anaconda3/lib/python3.11/site-packages (from optree->keras) (4.12.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./anaconda3/lib/python3.11/site-packages (from rich->keras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./anaconda3/lib/python3.11/site-packages (from rich->keras) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./anaconda3/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.0)\n",
      "Requirement already satisfied: tensorflow in ./anaconda3/lib/python3.11/site-packages (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in ./anaconda3/lib/python3.11/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./anaconda3/lib/python3.11/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in ./anaconda3/lib/python3.11/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./anaconda3/lib/python3.11/site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in ./anaconda3/lib/python3.11/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in ./anaconda3/lib/python3.11/site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./anaconda3/lib/python3.11/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in ./anaconda3/lib/python3.11/site-packages (from tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./anaconda3/lib/python3.11/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in ./anaconda3/lib/python3.11/site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in ./anaconda3/lib/python3.11/site-packages (from tensorflow) (4.21.12)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./anaconda3/lib/python3.11/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in ./anaconda3/lib/python3.11/site-packages (from tensorflow) (70.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in ./anaconda3/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./anaconda3/lib/python3.11/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in ./anaconda3/lib/python3.11/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in ./anaconda3/lib/python3.11/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./anaconda3/lib/python3.11/site-packages (from tensorflow) (1.64.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in ./anaconda3/lib/python3.11/site-packages (from tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in ./anaconda3/lib/python3.11/site-packages (from tensorflow) (3.3.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in ./anaconda3/lib/python3.11/site-packages (from tensorflow) (0.37.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in ./anaconda3/lib/python3.11/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./anaconda3/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: rich in ./anaconda3/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in ./anaconda3/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in ./anaconda3/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.6.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./anaconda3/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./anaconda3/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./anaconda3/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./anaconda3/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./anaconda3/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./anaconda3/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./anaconda3/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U nltk\n",
    "!pip install -U flask\n",
    "!pip install -U flask_cors\n",
    "!pip install -U keras\n",
    "!pip install -U tensorflow\n",
    "# Note that, currently, this is stolen wholesale from https://github.com/katanaml/katana-assistant/blob/master/mlmodels/katana-assistant-model.ipynb\n",
    "# It will be modified later to suit our purposes, I just want to see if I can get what they have to work!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "899dd2fd-d64f-469f-a4c3-d20d57345c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-20 17:48:01.405530: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-20 17:48:01.697316: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-20 17:48:02.508240: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Note that, currently, this is stolen wholesale from https://github.com/katanaml/katana-assistant/blob/master/mlmodels/katana-assistant-model.ipynb\n",
    "# It will be modified later to suit our purposes, I just want to see if I can get what they have to work\n",
    "\n",
    "import nltk\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "stemmer = LancasterStemmer()\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.optimizers import SGD # NOTE: this was originally written with an older version of SGD, so I'm using the legacy version just to implement what they had as they had it\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "from flask import Flask, jsonify, request\n",
    "from flask_cors import CORS, cross_origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "0d9ab86d-70b5-42c1-8538-e6b648f99ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/mist861/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "d11fd030-1247-4284-92ef-93b6f12ad477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164 documents\n",
      "9 classes ['adverse_drug', 'blood_pressure', 'blood_pressure_search', 'goodbye', 'greeting', 'hospital_search', 'options', 'pharmacy_search', 'thanks']\n",
      "257 unique stemmed words ['!', \"''\", \"'m\", \"'re\", \"'s\", \"'ve\", '(', ')', ',', '.', '24/7', '[', ']', '``', 'a', 'abl', 'about', 'acceiv', 'adio', 'advers', 'afternoon', 'al', 'an', 'anticip', 'any', 'anyon', 'apprecy', 'ar', 'area', 'around', 'assocy', 'at', 'aw', 'awesom', 'be', 'been', 'behavy', 'blood', 'bp', 'bring', 'bunch', 'buy', 'by', 'bye', 'bye-by', 'ca', 'can', 'cap', 'car', 'cardiolog', 'catch', 'caus', 'cent', 'chant', 'chat', 'check', 'city/town', 'clos', 'common', 'comp', 'compet', 'comply', 'concern', 'consequ', 'contribut', 'could', 'covid-19', 'cur', 'dat', 'day', 'describ', 'detail', 'do', 'doe', 'doing', 'dont', 'downsid', 'drawback', 'drive-thru', 'drug', 'drugst', 'e.g.', 'easy', 'effect', 'emerg', 'encount', 'enough', 'entry', 'ev', 'excel', 'expect', 'expert', 'expery', 'explain', 'fac', 'facil', 'farewel', 'fil', 'find', 'flu', 'for', 'from', 'gest', 'giv', 'going', 'good', 'goodby', 'grat', 'gre', 'greet', 'hav', 'hello', 'help', 'her', 'hey', 'hi', 'hiy', 'hospit', 'how', 'howdy', 'i', 'icu', 'id', 'in', 'ins', 'intend', 'is', 'it', 'kind', 'know', 'known', 'lat', 'latest', 'let', 'level', 'lifesav', 'list', 'load', 'loc', 'log', 'long', 'look', 'lookup', 'lot', 'man', 'many', 'me', 'mean', 'med', 'medicin', 'met', 'might', 'mil', 'mod', 'morn', 'much', 'must', 'my', \"n't\", 'near', 'nearby', 'nearest', 'neighb', 'nic', 'norm', 'now', 'numb', 'oblig', 'occ', 'of', 'off', 'on', 'op', 'or', 'outcom', 'outlin', 'over-the-count', 'overal', 'ow', 'paty', 'pedy', 'pharm', 'pleas', 'point', 'poss', 'pot', 'prescrib', 'press', 'profess', 'proficy', 'project', 'provid', 'react', 'read', 'real', 'rec', 'rel', 'report', 'result', 'right', 'risk', 'room', 'salut', 'search', 'see', 'serv', 'shot', 'should', 'show', 'sid', 'skil', 'so', 'spec', 'special', 'stabl', 'stat', 'strengths', 'strong', 'suit', 'support', 'surgery', 'systolic/diastol', 'tabl', 'tak', 'tal', 'task', 'techn', 'tel', 'term', 'thank', 'that', 'the', 'ther', 'thi', 'to', 'today', 'transf', 'tre', 'undesir', 'unintend', 'unit', 'unw', 'up', 'upd', 'urg', 'us', 'vaccin', 'want', 'wel', 'welcom', 'what', 'wher', 'which', 'whil', 'with', 'yo', 'you']\n"
     ]
    }
   ],
   "source": [
    "words = []\n",
    "classes = []\n",
    "documents = []\n",
    "ignore_words = ['?']\n",
    "intents = train_df['intent'].unique()\n",
    "# loop through each sentence in our intents patterns\n",
    "for intent in intents:\n",
    "    temp_df = train_df.loc[train_df['intent'] == intent]\n",
    "    temp_utterances = temp_df['utterance'].tolist()\n",
    "    for pattern in temp_utterances:\n",
    "        # tokenize each word in the sentence\n",
    "        w = nltk.word_tokenize(pattern)\n",
    "        # add to our words list\n",
    "        words.extend(w)\n",
    "        # add to documents in our corpus\n",
    "        documents.append((w, intent))\n",
    "        # add to our classes list\n",
    "        if intent not in classes:\n",
    "            classes.append(intent)\n",
    "\n",
    "# stem and lower each word and remove duplicates\n",
    "words = [stemmer.stem(w.lower()) for w in words if w not in ignore_words]\n",
    "words = sorted(list(set(words)))\n",
    "\n",
    "# sort classes\n",
    "classes = sorted(list(set(classes)))\n",
    "\n",
    "# documents = combination between patterns and intents\n",
    "print (len(documents), \"documents\")\n",
    "# classes = intents\n",
    "print (len(classes), \"classes\", classes)\n",
    "# words = all words, vocabulary\n",
    "print (len(words), \"unique stemmed words\", words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "610f78cd-9a27-4ee2-a730-19124fe32d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create our training data\n",
    "training = []\n",
    "# create an empty array for our output\n",
    "output_empty = [0] * len(classes)\n",
    "\n",
    "# training set, bag of words for each sentence\n",
    "for doc in documents:\n",
    "    # initialize our bag of words\n",
    "    bag = []\n",
    "    # list of tokenized words for the pattern\n",
    "    pattern_words = doc[0]\n",
    "    # stem each word - create base word, in attempt to represent related words\n",
    "    pattern_words = [stemmer.stem(word.lower()) for word in pattern_words]\n",
    "    # create our bag of words array with 1, if word match found in current pattern\n",
    "    for w in words:\n",
    "        bag.append(1) if w in pattern_words else bag.append(0)\n",
    "\n",
    "    # output is a '0' for each tag and '1' for current tag (for each pattern)\n",
    "    output_row = list(output_empty)\n",
    "    output_row[classes.index(doc[1])] = 1\n",
    "\n",
    "    training.append([bag, output_row])\n",
    "\n",
    "# shuffle our features and turn into np.array\n",
    "random.shuffle(training)\n",
    "#training = np.array(training) # This doesn't work with our version of numpy, boo, it doesn't like the 2d array having arrays of different sizes\n",
    "\n",
    "# create train and test lists. X - patterns, Y - intents\n",
    "#train_x = list(training[:,0]) # Same as above, doesn't work\n",
    "#train_y = list(training[:,1]) # Save as above, doesn't work\n",
    "\n",
    "train_x, train_y = zip(*training) # So instead of converting to a np array and slicing, we'll split the list then\n",
    "train_x = np.array(train_x) # Convert the lists, separately, into arrays\n",
    "train_y = np.array(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "554ba040-1233-4b70-88af-188bd84e396a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mist861/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-06-20 17:48:32.838892: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-20 17:48:32.839197: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "# Create model - 3 layers. First layer 128 neurons, second layer 64 neurons and 3rd output layer contains number of neurons\n",
    "# equal to number of intents to predict output intent with softmax\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(len(train_x[0]),), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(train_y[0]), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "fbb7e186-5e4f-4195-bf18-8a102d66dbc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mist861/anaconda3/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py:33: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Compile model. Stochastic gradient descent with Nesterov accelerated gradient gives good results for this model\n",
    "sgd = SGD(learning_rate=0.01, decay=1e-6, momentum=0.9, nesterov=True) # I had to tweak this slightly, because even using the legacy SGD this was somehow too new?\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "17112444-0877-4d05-8a92-91cdb500c08c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step - accuracy: 0.1552 - loss: 2.1762     \n",
      "Epoch 2/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - accuracy: 0.2696 - loss: 1.9673\n",
      "Epoch 3/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752us/step - accuracy: 0.4518 - loss: 1.6830\n",
      "Epoch 4/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - accuracy: 0.4652 - loss: 1.4252\n",
      "Epoch 5/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - accuracy: 0.5939 - loss: 1.1567\n",
      "Epoch 6/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step - accuracy: 0.7116 - loss: 0.8779\n",
      "Epoch 7/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - accuracy: 0.7865 - loss: 0.6518\n",
      "Epoch 8/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - accuracy: 0.7922 - loss: 0.6171\n",
      "Epoch 9/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - accuracy: 0.7631 - loss: 0.5842\n",
      "Epoch 10/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 680us/step - accuracy: 0.7825 - loss: 0.5551\n",
      "Epoch 11/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step - accuracy: 0.8534 - loss: 0.4298\n",
      "Epoch 12/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - accuracy: 0.8556 - loss: 0.4360\n",
      "Epoch 13/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - accuracy: 0.8230 - loss: 0.4686\n",
      "Epoch 14/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step - accuracy: 0.9058 - loss: 0.3058\n",
      "Epoch 15/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622us/step - accuracy: 0.9162 - loss: 0.3233\n",
      "Epoch 16/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621us/step - accuracy: 0.8975 - loss: 0.3286\n",
      "Epoch 17/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step - accuracy: 0.9545 - loss: 0.2041\n",
      "Epoch 18/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step - accuracy: 0.9128 - loss: 0.2352\n",
      "Epoch 19/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - accuracy: 0.9305 - loss: 0.2278\n",
      "Epoch 20/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 616us/step - accuracy: 0.9480 - loss: 0.1702\n",
      "Epoch 21/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - accuracy: 0.9579 - loss: 0.1738\n",
      "Epoch 22/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.9711 - loss: 0.1249\n",
      "Epoch 23/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - accuracy: 0.9509 - loss: 0.1544\n",
      "Epoch 24/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step - accuracy: 0.9779 - loss: 0.1289\n",
      "Epoch 25/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623us/step - accuracy: 0.9544 - loss: 0.1804\n",
      "Epoch 26/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 656us/step - accuracy: 0.9352 - loss: 0.2065\n",
      "Epoch 27/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 666us/step - accuracy: 0.9431 - loss: 0.1418\n",
      "Epoch 28/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - accuracy: 0.9213 - loss: 0.1713\n",
      "Epoch 29/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step - accuracy: 0.9396 - loss: 0.1254\n",
      "Epoch 30/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step - accuracy: 0.9736 - loss: 0.1087\n",
      "Epoch 31/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - accuracy: 0.9600 - loss: 0.0863\n",
      "Epoch 32/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step - accuracy: 1.0000 - loss: 0.0451\n",
      "Epoch 33/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 635us/step - accuracy: 0.9657 - loss: 0.0944\n",
      "Epoch 34/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 653us/step - accuracy: 0.9843 - loss: 0.0487\n",
      "Epoch 35/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step - accuracy: 0.9630 - loss: 0.1554\n",
      "Epoch 36/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step - accuracy: 0.9872 - loss: 0.0800\n",
      "Epoch 37/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 655us/step - accuracy: 0.9762 - loss: 0.0881\n",
      "Epoch 38/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 666us/step - accuracy: 0.9834 - loss: 0.0801\n",
      "Epoch 39/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625us/step - accuracy: 1.0000 - loss: 0.0496\n",
      "Epoch 40/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - accuracy: 0.9855 - loss: 0.0542\n",
      "Epoch 41/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.9853 - loss: 0.0487\n",
      "Epoch 42/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 670us/step - accuracy: 0.9899 - loss: 0.0402\n",
      "Epoch 43/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - accuracy: 0.9966 - loss: 0.0366\n",
      "Epoch 44/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 661us/step - accuracy: 0.9746 - loss: 0.0580\n",
      "Epoch 45/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 626us/step - accuracy: 0.9972 - loss: 0.0239\n",
      "Epoch 46/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 661us/step - accuracy: 0.9852 - loss: 0.0688   \n",
      "Epoch 47/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - accuracy: 0.9847 - loss: 0.0518\n",
      "Epoch 48/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 653us/step - accuracy: 0.9795 - loss: 0.0612\n",
      "Epoch 49/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 669us/step - accuracy: 0.9984 - loss: 0.0371\n",
      "Epoch 50/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667us/step - accuracy: 0.9924 - loss: 0.0292\n",
      "Epoch 51/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - accuracy: 0.9936 - loss: 0.0416\n",
      "Epoch 52/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - accuracy: 0.9817 - loss: 0.0691\n",
      "Epoch 53/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 680us/step - accuracy: 1.0000 - loss: 0.0517\n",
      "Epoch 54/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - accuracy: 0.9989 - loss: 0.0168   \n",
      "Epoch 55/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step - accuracy: 0.9910 - loss: 0.0362\n",
      "Epoch 56/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step - accuracy: 1.0000 - loss: 0.0301\n",
      "Epoch 57/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 658us/step - accuracy: 1.0000 - loss: 0.0342\n",
      "Epoch 58/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step - accuracy: 0.9702 - loss: 0.0625\n",
      "Epoch 59/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608us/step - accuracy: 0.9675 - loss: 0.0788\n",
      "Epoch 60/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - accuracy: 0.9896 - loss: 0.0404\n",
      "Epoch 61/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608us/step - accuracy: 0.9919 - loss: 0.0295\n",
      "Epoch 62/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.9679 - loss: 0.0564\n",
      "Epoch 63/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 636us/step - accuracy: 0.9957 - loss: 0.0277   \n",
      "Epoch 64/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 636us/step - accuracy: 0.9949 - loss: 0.0330\n",
      "Epoch 65/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - accuracy: 0.9949 - loss: 0.0305   \n",
      "Epoch 66/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - accuracy: 0.9935 - loss: 0.0264   \n",
      "Epoch 67/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step - accuracy: 0.9852 - loss: 0.0385\n",
      "Epoch 68/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - accuracy: 0.9892 - loss: 0.0427   \n",
      "Epoch 69/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639us/step - accuracy: 0.9935 - loss: 0.0426   \n",
      "Epoch 70/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622us/step - accuracy: 0.9940 - loss: 0.0292\n",
      "Epoch 71/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - accuracy: 1.0000 - loss: 0.0252\n",
      "Epoch 72/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - accuracy: 0.9953 - loss: 0.0292\n",
      "Epoch 73/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 636us/step - accuracy: 0.9935 - loss: 0.0199\n",
      "Epoch 74/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - accuracy: 0.9971 - loss: 0.0141\n",
      "Epoch 75/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 655us/step - accuracy: 0.9794 - loss: 0.0691   \n",
      "Epoch 76/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - accuracy: 0.9804 - loss: 0.0363\n",
      "Epoch 77/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 676us/step - accuracy: 1.0000 - loss: 0.0160\n",
      "Epoch 78/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667us/step - accuracy: 0.9584 - loss: 0.0560\n",
      "Epoch 79/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628us/step - accuracy: 0.9963 - loss: 0.0185   \n",
      "Epoch 80/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - accuracy: 0.9880 - loss: 0.0315\n",
      "Epoch 81/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 666us/step - accuracy: 0.9983 - loss: 0.0163\n",
      "Epoch 82/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0077 \n",
      "Epoch 83/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - accuracy: 0.9953 - loss: 0.0333\n",
      "Epoch 84/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 713us/step - accuracy: 1.0000 - loss: 0.0134   \n",
      "Epoch 85/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 670us/step - accuracy: 0.9945 - loss: 0.0170\n",
      "Epoch 86/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - accuracy: 1.0000 - loss: 0.0085   \n",
      "Epoch 87/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 632us/step - accuracy: 0.9980 - loss: 0.0071   \n",
      "Epoch 88/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - accuracy: 0.9966 - loss: 0.0123\n",
      "Epoch 89/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 677us/step - accuracy: 0.9539 - loss: 0.0686\n",
      "Epoch 90/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - accuracy: 1.0000 - loss: 0.0163\n",
      "Epoch 91/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 626us/step - accuracy: 0.9963 - loss: 0.0273   \n",
      "Epoch 92/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step - accuracy: 0.9977 - loss: 0.0171\n",
      "Epoch 93/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 675us/step - accuracy: 0.9963 - loss: 0.0168\n",
      "Epoch 94/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 636us/step - accuracy: 1.0000 - loss: 0.0127   \n",
      "Epoch 95/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627us/step - accuracy: 0.9924 - loss: 0.0267   \n",
      "Epoch 96/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - accuracy: 1.0000 - loss: 0.0101   \n",
      "Epoch 97/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.9890 - loss: 0.0350\n",
      "Epoch 98/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - accuracy: 0.9945 - loss: 0.0166\n",
      "Epoch 99/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step - accuracy: 0.9786 - loss: 0.0701\n",
      "Epoch 100/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - accuracy: 0.9969 - loss: 0.0316\n",
      "Epoch 101/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 672us/step - accuracy: 0.9893 - loss: 0.0226\n",
      "Epoch 102/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665us/step - accuracy: 0.9846 - loss: 0.0230   \n",
      "Epoch 103/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 734us/step - accuracy: 0.9960 - loss: 0.0161   \n",
      "Epoch 104/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - accuracy: 0.9995 - loss: 0.0074   \n",
      "Epoch 105/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 664us/step - accuracy: 0.9884 - loss: 0.0434   \n",
      "Epoch 106/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - accuracy: 0.9926 - loss: 0.0216\n",
      "Epoch 107/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step - accuracy: 1.0000 - loss: 0.0092   \n",
      "Epoch 108/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 664us/step - accuracy: 1.0000 - loss: 0.0228\n",
      "Epoch 109/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - accuracy: 1.0000 - loss: 0.0114\n",
      "Epoch 110/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610us/step - accuracy: 1.0000 - loss: 0.0141   \n",
      "Epoch 111/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 626us/step - accuracy: 0.9987 - loss: 0.0164   \n",
      "Epoch 112/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 661us/step - accuracy: 1.0000 - loss: 0.0131\n",
      "Epoch 113/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640us/step - accuracy: 1.0000 - loss: 0.0314\n",
      "Epoch 114/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step - accuracy: 0.9991 - loss: 0.0146\n",
      "Epoch 115/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 661us/step - accuracy: 1.0000 - loss: 0.0076\n",
      "Epoch 116/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - accuracy: 1.0000 - loss: 0.0128   \n",
      "Epoch 117/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - accuracy: 1.0000 - loss: 0.0375\n",
      "Epoch 118/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 664us/step - accuracy: 0.9718 - loss: 0.0924\n",
      "Epoch 119/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639us/step - accuracy: 1.0000 - loss: 0.0085   \n",
      "Epoch 120/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625us/step - accuracy: 0.9877 - loss: 0.0307   \n",
      "Epoch 121/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 1.0000 - loss: 0.0071\n",
      "Epoch 122/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0057     \n",
      "Epoch 123/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 731us/step - accuracy: 0.9993 - loss: 0.0095   \n",
      "Epoch 124/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743us/step - accuracy: 0.9953 - loss: 0.0277   \n",
      "Epoch 125/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 672us/step - accuracy: 1.0000 - loss: 0.0088   \n",
      "Epoch 126/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 633us/step - accuracy: 1.0000 - loss: 0.0154   \n",
      "Epoch 127/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.9993 - loss: 0.0169\n",
      "Epoch 128/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - accuracy: 0.9991 - loss: 0.0080\n",
      "Epoch 129/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 655us/step - accuracy: 0.9744 - loss: 0.0498\n",
      "Epoch 130/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step - accuracy: 1.0000 - loss: 0.0163   \n",
      "Epoch 131/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639us/step - accuracy: 1.0000 - loss: 0.0055   \n",
      "Epoch 132/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 669us/step - accuracy: 1.0000 - loss: 0.0094\n",
      "Epoch 133/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step - accuracy: 1.0000 - loss: 0.0025\n",
      "Epoch 134/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629us/step - accuracy: 0.9960 - loss: 0.0126   \n",
      "Epoch 135/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 678us/step - accuracy: 0.9940 - loss: 0.0123\n",
      "Epoch 136/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 632us/step - accuracy: 0.9982 - loss: 0.0073   \n",
      "Epoch 137/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step - accuracy: 1.0000 - loss: 0.0055   \n",
      "Epoch 138/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 669us/step - accuracy: 1.0000 - loss: 0.0073   \n",
      "Epoch 139/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 633us/step - accuracy: 1.0000 - loss: 0.0082\n",
      "Epoch 140/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 666us/step - accuracy: 0.9871 - loss: 0.0208   \n",
      "Epoch 141/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 670us/step - accuracy: 1.0000 - loss: 0.0047   \n",
      "Epoch 142/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - accuracy: 0.9991 - loss: 0.0169\n",
      "Epoch 143/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - accuracy: 1.0000 - loss: 0.0069\n",
      "Epoch 144/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - accuracy: 0.9982 - loss: 0.0031   \n",
      "Epoch 145/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 636us/step - accuracy: 1.0000 - loss: 0.0090\n",
      "Epoch 146/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - accuracy: 1.0000 - loss: 0.0197   \n",
      "Epoch 147/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 672us/step - accuracy: 1.0000 - loss: 0.0170\n",
      "Epoch 148/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624us/step - accuracy: 1.0000 - loss: 0.0034   \n",
      "Epoch 149/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 664us/step - accuracy: 1.0000 - loss: 0.0034\n",
      "Epoch 150/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step - accuracy: 1.0000 - loss: 0.0050\n",
      "Epoch 151/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - accuracy: 1.0000 - loss: 0.0092   \n",
      "Epoch 152/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667us/step - accuracy: 0.9935 - loss: 0.0103   \n",
      "Epoch 153/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.9758 - loss: 0.0423\n",
      "Epoch 154/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step - accuracy: 0.9989 - loss: 0.0152   \n",
      "Epoch 155/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0101     \n",
      "Epoch 156/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 680us/step - accuracy: 0.9980 - loss: 0.0077\n",
      "Epoch 157/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step - accuracy: 0.9938 - loss: 0.0212\n",
      "Epoch 158/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step - accuracy: 0.9975 - loss: 0.0142\n",
      "Epoch 159/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - accuracy: 0.9970 - loss: 0.0084   \n",
      "Epoch 160/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 664us/step - accuracy: 1.0000 - loss: 0.0075\n",
      "Epoch 161/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - accuracy: 0.9984 - loss: 0.0076   \n",
      "Epoch 162/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step - accuracy: 0.9987 - loss: 0.0187   \n",
      "Epoch 163/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 728us/step - accuracy: 0.9924 - loss: 0.0164\n",
      "Epoch 164/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 666us/step - accuracy: 1.0000 - loss: 0.0048\n",
      "Epoch 165/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - accuracy: 0.9926 - loss: 0.0138\n",
      "Epoch 166/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - accuracy: 0.9930 - loss: 0.0139\n",
      "Epoch 167/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 1.0000 - loss: 0.0092   \n",
      "Epoch 168/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 658us/step - accuracy: 0.9949 - loss: 0.0180\n",
      "Epoch 169/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665us/step - accuracy: 0.9817 - loss: 0.0437   \n",
      "Epoch 170/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - accuracy: 1.0000 - loss: 0.0055   \n",
      "Epoch 171/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 661us/step - accuracy: 1.0000 - loss: 0.0071\n",
      "Epoch 172/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.9980 - loss: 0.0090\n",
      "Epoch 173/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 656us/step - accuracy: 0.9924 - loss: 0.0288\n",
      "Epoch 174/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - accuracy: 0.9797 - loss: 0.0495   \n",
      "Epoch 175/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step - accuracy: 0.9817 - loss: 0.0269\n",
      "Epoch 176/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - accuracy: 0.9901 - loss: 0.0357\n",
      "Epoch 177/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640us/step - accuracy: 1.0000 - loss: 0.0080\n",
      "Epoch 178/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 664us/step - accuracy: 1.0000 - loss: 0.0078\n",
      "Epoch 179/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 678us/step - accuracy: 1.0000 - loss: 0.0087\n",
      "Epoch 180/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - accuracy: 1.0000 - loss: 0.0148\n",
      "Epoch 181/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9980 - loss: 0.0115 \n",
      "Epoch 182/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - accuracy: 1.0000 - loss: 0.0031   \n",
      "Epoch 183/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - accuracy: 0.9866 - loss: 0.0318   \n",
      "Epoch 184/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - accuracy: 0.9949 - loss: 0.0229\n",
      "Epoch 185/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 722us/step - accuracy: 1.0000 - loss: 0.0040   \n",
      "Epoch 186/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - accuracy: 1.0000 - loss: 0.0040\n",
      "Epoch 187/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - accuracy: 0.9817 - loss: 0.0435   \n",
      "Epoch 188/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - accuracy: 1.0000 - loss: 0.0025\n",
      "Epoch 189/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665us/step - accuracy: 1.0000 - loss: 0.0023   \n",
      "Epoch 190/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - accuracy: 0.9918 - loss: 0.0163   \n",
      "Epoch 191/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 635us/step - accuracy: 0.9957 - loss: 0.0094   \n",
      "Epoch 192/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - accuracy: 0.9918 - loss: 0.0159\n",
      "Epoch 193/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9940 - loss: 0.0101     \n",
      "Epoch 194/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9805 - loss: 0.0203     \n",
      "Epoch 195/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - accuracy: 0.9975 - loss: 0.0176\n",
      "Epoch 196/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667us/step - accuracy: 0.9960 - loss: 0.0103\n",
      "Epoch 197/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 658us/step - accuracy: 0.9935 - loss: 0.0094\n",
      "Epoch 198/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665us/step - accuracy: 1.0000 - loss: 0.0017\n",
      "Epoch 199/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - accuracy: 1.0000 - loss: 0.0032   \n",
      "Epoch 200/200\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step - accuracy: 1.0000 - loss: 0.0037   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f74a22db6d0>"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(train_x, train_y, epochs=200, batch_size=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "ce670531-6aaa-43f7-a4e9-f97f5efb616a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up_sentence(sentence):\n",
    "    # tokenize the pattern - split words into array\n",
    "    sentence_words = nltk.word_tokenize(sentence)\n",
    "    # stem each word - create short form for word\n",
    "    sentence_words = [stemmer.stem(word.lower()) for word in sentence_words]\n",
    "    return sentence_words\n",
    "\n",
    "# return bag of words array: 0 or 1 for each word in the bag that exists in the sentence\n",
    "def bow(sentence, words, show_details=True):\n",
    "    # tokenize the pattern\n",
    "    sentence_words = clean_up_sentence(sentence)\n",
    "    # bag of words - matrix of N words, vocabulary matrix\n",
    "    bag = [0]*len(words)\n",
    "    for s in sentence_words:\n",
    "        for i,w in enumerate(words):\n",
    "            if w == s:\n",
    "                # assign 1 if current word is in the vocabulary position\n",
    "                bag[i] = 1\n",
    "                if show_details:\n",
    "                    print (\"found in bag: %s\" % w)\n",
    "\n",
    "    return(np.array(bag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "e328198b-a8e9-4edd-94a4-82398c83611c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_local(sentence):\n",
    "    ERROR_THRESHOLD = 0.25\n",
    "\n",
    "    # generate probabilities from the model\n",
    "    input_data = pd.DataFrame([bow(sentence, words)], dtype=float, index=['input'])\n",
    "    results = model.predict([input_data])[0]\n",
    "    # filter out predictions below a threshold, and provide intent index\n",
    "    results = [[i,r] for i,r in enumerate(results) if r>ERROR_THRESHOLD]\n",
    "    # sort by strength of probability\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return_list = []\n",
    "    for r in results:\n",
    "        return_list.append((classes[r[0]], str(r[1])))\n",
    "    # return tuple of intent and probability\n",
    "\n",
    "    return return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "5bab6409-848d-48f6-b6d4-7f1bf272c99b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found in bag: load\n",
      "found in bag: blood\n",
      "found in bag: for\n",
      "found in bag: paty\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'blood_pressure_search'"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_local(\"Load blood pessure for patient\")[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ea3846-5151-4c72-95c0-4359e2b86256",
   "metadata": {},
   "source": [
    "# Comparing NN and RAG Intent Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "41dfbb32-22e2-44cc-9e52-b5b41cbbb9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['options', 'noanswer', 'thanks', 'adverse_drug', 'greeting', 'thanks', 'blood_pressure', 'blood_pressure', 'blood_pressure', 'pharmacy_search', 'hospital_search', 'blood_pressure', 'goodbye', 'pharmacy_search', 'goodbye', 'blood_pressure', 'options', 'greeting', 'thanks', 'adverse_drug', 'greeting', 'thanks', 'thanks', 'blood_pressure', 'blood_pressure', 'options', 'pharmacy_search', 'hospital_search', 'thanks', 'hospital_search', 'goodbye', 'options', 'blood_pressure', 'hospital_search', 'goodbye', 'thanks', 'blood_pressure', 'greeting', 'greeting', 'goodbye', 'blood_pressure']\n"
     ]
    }
   ],
   "source": [
    "rag_results = []\n",
    "for utterance in X_test_df:\n",
    "    result = rl(utterance).name\n",
    "    if result == None:\n",
    "        result = 'noanswer'\n",
    "    rag_results.append(result)\n",
    "\n",
    "print(rag_results)\n",
    "    \n",
    "#    result = rl(utterance).name\n",
    "#    rag_results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "f271b01e-a478-45c9-9c73-546e960798f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found in bag: ``\n",
      "found in bag: how\n",
      "found in bag: you\n",
      "found in bag: could\n",
      "found in bag: help\n",
      "found in bag: me\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "found in bag: ``\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: you\n",
      "found in bag: hav\n",
      "found in bag: my\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: ar\n",
      "found in bag: ther\n",
      "found in bag: any\n",
      "found in bag: effect\n",
      "found in bag: i\n",
      "found in bag: should\n",
      "found in bag: for\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: see\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: apprecy\n",
      "found in bag: yo\n",
      "found in bag: help\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: 's\n",
      "found in bag: the\n",
      "found in bag: on\n",
      "found in bag: my\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: today\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: can\n",
      "found in bag: you\n",
      "found in bag: provid\n",
      "found in bag: me\n",
      "found in bag: with\n",
      "found in bag: my\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "found in bag: ``\n",
      "found in bag: how\n",
      "found in bag: is\n",
      "found in bag: my\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: look\n",
      "found in bag: today\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: search\n",
      "found in bag: for\n",
      "found in bag: pharm\n",
      "found in bag: that\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: find\n",
      "found in bag: a\n",
      "found in bag: hospit\n",
      "found in bag: in\n",
      "found in bag: [\n",
      "found in bag: city/town\n",
      "found in bag: ]\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: should\n",
      "found in bag: i\n",
      "found in bag: know\n",
      "found in bag: about\n",
      "found in bag: my\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: level\n",
      "found in bag: right\n",
      "found in bag: now\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: goodby\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: find\n",
      "found in bag: a\n",
      "found in bag: pharm\n",
      "found in bag: near\n",
      "found in bag: me\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: is\n",
      "found in bag: my\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: a\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: how\n",
      "found in bag: you\n",
      "found in bag: can\n",
      "found in bag: be\n",
      "found in bag: help\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: thank\n",
      "found in bag: a\n",
      "found in bag: lot\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: kind\n",
      "found in bag: of\n",
      "found in bag: react\n",
      "found in bag: should\n",
      "found in bag: i\n",
      "found in bag: be\n",
      "found in bag: for\n",
      "found in bag: with\n",
      "found in bag: thi\n",
      "found in bag: drug\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: hi\n",
      "found in bag: ,\n",
      "found in bag: how\n",
      "found in bag: hav\n",
      "found in bag: you\n",
      "found in bag: been\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: 'm\n",
      "found in bag: thank\n",
      "found in bag: for\n",
      "found in bag: yo\n",
      "found in bag: support\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: 'm\n",
      "found in bag: grat\n",
      "found in bag: for\n",
      "found in bag: yo\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: want\n",
      "found in bag: to\n",
      "found in bag: search\n",
      "found in bag: for\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: result\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: op\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: mod\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: you\n",
      "found in bag: can\n",
      "found in bag: do\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: pharm\n",
      "found in bag: clos\n",
      "found in bag: to\n",
      "found in bag: my\n",
      "found in bag: loc\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: find\n",
      "found in bag: an\n",
      "found in bag: emerg\n",
      "found in bag: hospit\n",
      "found in bag: near\n",
      "found in bag: me\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: i\n",
      "found in bag: 'm\n",
      "found in bag: thank\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: nearby\n",
      "found in bag: hospit\n",
      "found in bag: op\n",
      "found in bag: now\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: see\n",
      "found in bag: you\n",
      "found in bag: lat\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: ar\n",
      "found in bag: yo\n",
      "found in bag: tal\n",
      "found in bag: skil\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: could\n",
      "found in bag: you\n",
      "found in bag: me\n",
      "found in bag: of\n",
      "found in bag: my\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: result\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: search\n",
      "found in bag: for\n",
      "found in bag: hospit\n",
      "found in bag: that\n",
      "found in bag: off\n",
      "found in bag: serv\n",
      "found in bag: .\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: see\n",
      "found in bag: you\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: tak\n",
      "found in bag: car\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: what\n",
      "found in bag: is\n",
      "found in bag: my\n",
      "found in bag: cur\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: read\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: yo\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "found in bag: ``\n",
      "found in bag: hello\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: !\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "found in bag: ``\n",
      "found in bag: can\n",
      "found in bag: you\n",
      "found in bag: tel\n",
      "found in bag: me\n",
      "found in bag: what\n",
      "found in bag: my\n",
      "found in bag: blood\n",
      "found in bag: press\n",
      "found in bag: numb\n",
      "found in bag: ar\n",
      "found in bag: ''\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "['thanks', 'greeting', 'thanks', 'adverse_drug', 'goodbye', 'thanks', 'blood_pressure', 'blood_pressure', 'blood_pressure', 'pharmacy_search', 'hospital_search', 'blood_pressure', 'goodbye', 'pharmacy_search', 'greeting', 'blood_pressure', 'greeting', 'greeting', 'thanks', 'adverse_drug', 'greeting', 'thanks', 'thanks', 'blood_pressure', 'blood_pressure', 'options', 'pharmacy_search', 'hospital_search', 'thanks', 'hospital_search', 'goodbye', 'options', 'blood_pressure', 'hospital_search', 'goodbye', 'goodbye', 'blood_pressure', 'options', 'greeting', 'greeting', 'blood_pressure']\n"
     ]
    }
   ],
   "source": [
    "nn_results = []\n",
    "for utterance in X_test_df:\n",
    "    result = classify_local(utterance)[0][0]\n",
    "    nn_results.append(result)\n",
    "\n",
    "print(nn_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "1fabbade-1731-41c5-9cbb-728120934d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,  silhouette_score, multilabel_confusion_matrix as mcm) # Importing sklearn metrics for supervised model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "023368df-b1d6-4188-8efa-eb0d668385b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN Accuracy: 0.8048780487804879, NN Recall: 0.7469135802469135, NN Precision: 0.7455026455026454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mist861/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "nn_accuracy = accuracy_score(y_test, nn_results)\n",
    "nn_recall = recall_score(y_test, nn_results, average='macro')\n",
    "nn_precision = precision_score(y_test, nn_results, average='macro')\n",
    "print(f'NN Accuracy: {nn_accuracy}, NN Recall: {nn_recall}, NN Precision: {nn_precision}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "34f3aa90-51ed-4a5d-a48c-cc58f41e9b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Accuracy: 0.8780487804878049, RAG Recall: 0.7555555555555555, RAG Precision: 0.7357142857142857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mist861/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mist861/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "rag_accuracy = accuracy_score(y_test, rag_results)\n",
    "rag_recall = recall_score(y_test, rag_results, average='macro')\n",
    "rag_precision = precision_score(y_test, rag_results, average='macro')\n",
    "print(f'RAG Accuracy: {rag_accuracy}, RAG Recall: {rag_recall}, RAG Precision: {rag_precision}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdaf44e3-b094-47b4-935d-1e6f7e5abc1c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# LLM Integration (in progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "838b6936",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_core in ./anaconda3/lib/python3.11/site-packages (0.2.7)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./anaconda3/lib/python3.11/site-packages (from langchain_core) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./anaconda3/lib/python3.11/site-packages (from langchain_core) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in ./anaconda3/lib/python3.11/site-packages (from langchain_core) (0.1.77)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./anaconda3/lib/python3.11/site-packages (from langchain_core) (24.1)\n",
      "Requirement already satisfied: pydantic<3,>=1 in ./anaconda3/lib/python3.11/site-packages (from langchain_core) (2.7.4)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in ./anaconda3/lib/python3.11/site-packages (from langchain_core) (8.2.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./anaconda3/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain_core) (2.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./anaconda3/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.75->langchain_core) (3.10.5)\n",
      "Requirement already satisfied: requests<3,>=2 in ./anaconda3/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.75->langchain_core) (2.31.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./anaconda3/lib/python3.11/site-packages (from pydantic<3,>=1->langchain_core) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in ./anaconda3/lib/python3.11/site-packages (from pydantic<3,>=1->langchain_core) (2.18.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in ./anaconda3/lib/python3.11/site-packages (from pydantic<3,>=1->langchain_core) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain_core) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain_core) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain_core) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain_core) (2023.7.22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in ./anaconda3/lib/python3.11/site-packages (0.2.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./anaconda3/lib/python3.11/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./anaconda3/lib/python3.11/site-packages (from langchain) (1.4.39)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./anaconda3/lib/python3.11/site-packages (from langchain) (3.9.5)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.7 in ./anaconda3/lib/python3.11/site-packages (from langchain) (0.2.7)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in ./anaconda3/lib/python3.11/site-packages (from langchain) (0.2.1)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in ./anaconda3/lib/python3.11/site-packages (from langchain) (0.1.77)\n",
      "Requirement already satisfied: numpy<2,>=1 in ./anaconda3/lib/python3.11/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in ./anaconda3/lib/python3.11/site-packages (from langchain) (2.7.4)\n",
      "Requirement already satisfied: requests<3,>=2 in ./anaconda3/lib/python3.11/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in ./anaconda3/lib/python3.11/site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./anaconda3/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.7->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./anaconda3/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.7->langchain) (24.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./anaconda3/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.5)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./anaconda3/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in ./anaconda3/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (2.18.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in ./anaconda3/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./anaconda3/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./anaconda3/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.7->langchain) (2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_core\n",
    "!pip install langchain\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "3510450e",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use one of the following answers to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n Question: {question}\"\n",
    "    \"\\n Answer: {answer}\"\n",
    ")\n",
    "\n",
    "prompt = PromptTemplate(template=system_prompt, input_variables=[\"context\",\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "66e512fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context(question):\n",
    "    output = str(rl(f\"{question}\").name)\n",
    "    if output in response_dict:\n",
    "        response = {'responses':response_dict[f'{output}']['responses']}\n",
    "    else:\n",
    "        response = {'responses':[\"I'm sorry, but I do not have a response to that question\"]}\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c7f977b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'responses': ['Navigating to Blood Pressure module']}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_context('what is my blood pressure like today')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "affab35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "#    prompt\n",
    "    model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8393585b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'StringPromptValue' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[106], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m response \u001b[38;5;241m=\u001b[39m rag_chain\u001b[38;5;241m.\u001b[39minvoke({\n\u001b[1;32m      2\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m: response_dict[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrl(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcan you search for my blood pressure please\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresponses\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m      3\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcan you search for my blood pressure please\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m            })\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_core/runnables/base.py:2504\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2502\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   2503\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2504\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n\u001b[1;32m   2505\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   2506\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_core/runnables/base.py:3976\u001b[0m, in \u001b[0;36mRunnableLambda.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3974\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Invoke this runnable synchronously.\"\"\"\u001b[39;00m\n\u001b[1;32m   3975\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunc\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 3976\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[1;32m   3977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_invoke,\n\u001b[1;32m   3978\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   3979\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config(config, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc),\n\u001b[1;32m   3980\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3981\u001b[0m     )\n\u001b[1;32m   3982\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3983\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   3984\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot invoke a coroutine function synchronously.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse `ainvoke` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3986\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_core/runnables/base.py:1598\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[0;34m(self, func, input, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1594\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[1;32m   1595\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, child_config)\n\u001b[1;32m   1596\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[1;32m   1597\u001b[0m         Output,\n\u001b[0;32m-> 1598\u001b[0m         context\u001b[38;5;241m.\u001b[39mrun(\n\u001b[1;32m   1599\u001b[0m             call_func_with_variable_args,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m             func,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m   1601\u001b[0m             \u001b[38;5;28minput\u001b[39m,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m   1602\u001b[0m             config,\n\u001b[1;32m   1603\u001b[0m             run_manager,\n\u001b[1;32m   1604\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1605\u001b[0m         ),\n\u001b[1;32m   1606\u001b[0m     )\n\u001b[1;32m   1607\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1608\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_core/runnables/config.py:380\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    379\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[0;32m--> 380\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_core/runnables/base.py:3844\u001b[0m, in \u001b[0;36mRunnableLambda._invoke\u001b[0;34m(self, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[1;32m   3842\u001b[0m                 output \u001b[38;5;241m=\u001b[39m chunk\n\u001b[1;32m   3843\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3844\u001b[0m     output \u001b[38;5;241m=\u001b[39m call_func_with_variable_args(\n\u001b[1;32m   3845\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc, \u001b[38;5;28minput\u001b[39m, config, run_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m   3846\u001b[0m     )\n\u001b[1;32m   3847\u001b[0m \u001b[38;5;66;03m# If the output is a runnable, invoke it\u001b[39;00m\n\u001b[1;32m   3848\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, Runnable):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_core/runnables/config.py:380\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    379\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[0;32m--> 380\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/models/phi/modeling_phi.py:1166\u001b[0m, in \u001b[0;36mPhiForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1163\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1165\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1166\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\n\u001b[1;32m   1167\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1168\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m   1169\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m   1170\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[1;32m   1171\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[1;32m   1172\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[1;32m   1173\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m   1174\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[1;32m   1175\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m   1176\u001b[0m )\n\u001b[1;32m   1178\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1179\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(hidden_states)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/models/phi/modeling_phi.py:974\u001b[0m, in \u001b[0;36mPhiModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    972\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot specify both input_ids and inputs_embeds at the same time\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 974\u001b[0m     batch_size, seq_length \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    975\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    976\u001b[0m     batch_size, seq_length \u001b[38;5;241m=\u001b[39m inputs_embeds\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'StringPromptValue' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\n",
    "           \"context\": response_dict[f'{rl(\"can you search for my blood pressure please\").name}']['responses'], \n",
    "           \"question\": \"can you search for my blood pressure please\"\n",
    "           }) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "045b988c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(question):\n",
    "    context = response_dict[f'{rl(f\"{question}\").name}']['responses']\n",
    "    input_prompt = prompt.invoke({\"answer\": context, \"question\": question})\n",
    "    inputs = tokenizer(str(input_prompt), return_tensors=\"pt\", return_attention_mask=False)\n",
    "    outputs = model.generate(**inputs, max_length=200)\n",
    "    text = tokenizer.batch_decode(outputs)[0]\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "f7574e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text=\"You are an assistant for question-answering tasks. Use one of the following answers to answer the question. If you don't know the answer, say that you don't know. Use three sentences maximum and keep the answer concise.\\n Question: can you search for my blood pressure please\\n Answer: ['Navigating to Blood Pressure module']\"\n",
      "    )\n",
      "    return render_template(\"blood_pressure.html\", question=question, answer=answer)\n",
      "\n",
      "@app.route(\"/blood_pressure/<int:question_id>\")\n",
      "def blood_pressure(question_id):\n",
      "    # get the blood pressure data from the database\n",
      "    blood_pressure_data = BloodPressure.query.filter_by(id=question_id).first()\n",
      "    \n",
      "    # render the blood pressure data in a table\n",
      "    return render_template(\"blood_pressure.html\", question=question_id, data=\n"
     ]
    }
   ],
   "source": [
    "get_results('can you search for my blood pressure please')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430208df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
